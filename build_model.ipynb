{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from: https://www.kaggle.com/code/nnikolay/diabetes-classification-recall-78\n",
    "def summary(df):\n",
    "    summary = pd.DataFrame(df.dtypes, columns=['dtypes'])\n",
    "    summary = summary.reset_index()\n",
    "    summary['Missing'] = df.isnull().sum().values    \n",
    "    summary['Uniques'] = df.nunique().values\n",
    "    return summary  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import the dataset\n",
    "## reading the texts comprehension csv file \n",
    "df = pd.read_csv(\"merged_comp_data.csv\")\n",
    "\n",
    "# leave out the columns that are not going to be investigated\n",
    "df = df.drop(columns=['nrun',\n",
    "    'blink',\n",
    "    'reg.out', \n",
    "    'firstrun.skip',\n",
    "    'firstrun.nfix',\n",
    "    'firstrun.refix',\n",
    "    'firstrun.reg.in',\n",
    "    'firstrun.reg.out',\n",
    "    'firstrun.gopast',\n",
    "    'firstrun.gopast.sel',\n",
    "    'firstfix.sac.in',\n",
    "    'firstfix.sac.out',\n",
    "    'firstfix.launch',\n",
    "    'firstfix.land',\n",
    "    'firstfix.cland',\n",
    "    'singlefix',\n",
    "    'singlefix.sac.in',\n",
    "    'singlefix.sac.out',\n",
    "    'singlefix.launch',\n",
    "    'singlefix.land',\n",
    "    'singlefix.cland',\n",
    "    'singlefix.dur'   \n",
    " ])\n",
    "\n",
    "# Repalce NaN values with zero's on all columns \n",
    "# the words that have been skipped (not looked at) have been annotated NA. \n",
    "# Since they were skipped, their gaze duration is equal or very close to 0\n",
    "df = df.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform PoS categorical variables to numerical based on their occurence count\n",
    "PoS_num = df['PoS'].value_counts()\n",
    "df['PoS_num'] = df['PoS'].map(PoS_num)\n",
    "\n",
    "## transform lang categorical varibles - encode the languages from strings to integers\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df[\"lang\"])\n",
    "df[\"lang_num\"] = le.transform(df[\"lang\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 502873 entries, 0 to 502872\n",
      "Data columns (total 18 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   index.data    502873 non-null  int64  \n",
      " 1   uniform_id    502873 non-null  object \n",
      " 2   itemid        502873 non-null  int64  \n",
      " 3   sentnum       502873 non-null  int64  \n",
      " 4   ianum         502873 non-null  int64  \n",
      " 5   ia            502873 non-null  object \n",
      " 6   PoS           502873 non-null  object \n",
      " 7   skip          502873 non-null  int64  \n",
      " 8   reread        502873 non-null  float64\n",
      " 9   nfix          502873 non-null  float64\n",
      " 10  refix         502873 non-null  float64\n",
      " 11  reg.in        502873 non-null  float64\n",
      " 12  dur           502873 non-null  float64\n",
      " 13  firstrun.dur  502873 non-null  float64\n",
      " 14  firstfix.dur  502873 non-null  float64\n",
      " 15  lang          502873 non-null  object \n",
      " 16  PoS_num       502873 non-null  int64  \n",
      " 17  lang_num      502873 non-null  int32  \n",
      "dtypes: float64(7), int32(1), int64(6), object(4)\n",
      "memory usage: 67.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# remove the English speakers from the dataset\n",
    "df = df.drop(df[df['lang'] == 'en'].index)\n",
    "df = df.reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>dtypes</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Uniques</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>index.data</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>502873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uniform_id</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>itemid</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentnum</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ianum</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ia</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PoS</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>skip</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reread</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nfix</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>refix</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>reg.in</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dur</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>3107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>firstrun.dur</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>2034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>firstfix.dur</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lang</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PoS_Dict</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index   dtypes  Missing  Uniques\n",
       "0     index.data    int64        0   502873\n",
       "1     uniform_id   object        0      410\n",
       "2         itemid    int64        0       12\n",
       "3        sentnum    int64        0       11\n",
       "4          ianum    int64        0      187\n",
       "5             ia   object        0      793\n",
       "6            PoS   object        0       31\n",
       "7           skip    int64        0        2\n",
       "8         reread  float64        0        2\n",
       "9           nfix  float64        0       32\n",
       "10         refix  float64        0        2\n",
       "11        reg.in  float64        0        2\n",
       "12           dur  float64        0     3107\n",
       "13  firstrun.dur  float64        0     2034\n",
       "14  firstfix.dur  float64        0     1130\n",
       "15          lang   object        0       11\n",
       "16      PoS_Dict    int64        0       31"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the features and target variables\n",
    "Note: the following code has been adapted from the Introduction to Machine Learning course jupyter notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the features and the targets of the model\n",
    "feature_names = ['PoS_num', 'firstfix.dur', 'firstrun.dur', 'dur']\n",
    "target_name = ['lang_num']\n",
    "\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df[['PoS_num', 'firstfix.dur', 'firstrun.dur', 'dur']]  # feature columns\n",
    "y = df['lang_num']  # target variable column\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At depth of 4\n",
      "Depth: 4\n",
      "Accuracy on training set: 0.168\n",
      "Accuracy on test set: 0.165\n",
      "At depth of 5\n",
      "Depth: 5\n",
      "Accuracy on training set: 0.169\n",
      "Accuracy on test set: 0.167\n",
      "At depth of 6\n",
      "Depth: 6\n",
      "Accuracy on training set: 0.171\n",
      "Accuracy on test set: 0.166\n",
      "At depth of 7\n",
      "Depth: 7\n",
      "Accuracy on training set: 0.171\n",
      "Accuracy on test set: 0.168\n",
      "At depth of 8\n",
      "Depth: 8\n",
      "Accuracy on training set: 0.172\n",
      "Accuracy on test set: 0.167\n",
      "At depth of 9\n",
      "Depth: 9\n",
      "Accuracy on training set: 0.173\n",
      "Accuracy on test set: 0.167\n",
      "At depth of 10\n",
      "Depth: 10\n",
      "Accuracy on training set: 0.175\n",
      "Accuracy on test set: 0.167\n"
     ]
    }
   ],
   "source": [
    "### DECISION TREE CLASSIFIER at different depths\n",
    "max_depths = [4, 5, 6, 7, 8, 9, 10]\n",
    "for depth in max_depths:\n",
    "    tree = DecisionTreeClassifier(random_state=0, max_depth=depth)\n",
    "    print(\"At depth of\", depth)\n",
    "    tree.fit(X_train, y_train)\n",
    "    print(\"Depth:\", tree.get_depth())\n",
    "    print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "    print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Maximum Depth DecisionTreeClassifier: 7\n",
      "Best Cross-Validation Score: 0.16984423912915236\n"
     ]
    }
   ],
   "source": [
    "### CROSS VALIDATION DECISION TREE CLASSIFIER\n",
    "\n",
    "# Define the range of maximum depths to try\n",
    "max_depths = range(1, 10)\n",
    "\n",
    "# Create an empty list to store the mean cross-validation scores\n",
    "cv_scores = []\n",
    "\n",
    "# Iterate over each maximum depth value\n",
    "for depth in max_depths:\n",
    "    # Create a decision tree classifier with the current maximum depth\n",
    "    tree = DecisionTreeClassifier(max_depth=depth)\n",
    "    \n",
    "    # Perform cross-validation and calculate the mean accuracy score\n",
    "    scores = cross_val_score(tree, X_train, y_train, cv=5)\n",
    "    mean_score = np.mean(scores)\n",
    "    \n",
    "    # Append the mean score to the list of scores\n",
    "    cv_scores.append(mean_score)\n",
    "    \n",
    "# Find the optimal maximum depth with the highest cross-validation score\n",
    "optimal_depth = max_depths[np.argmax(cv_scores)]\n",
    "best_score = max(cv_scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"Optimal Maximum Depth DecisionTreeClassifier:\", optimal_depth)\n",
    "print(\"Best Cross-Validation Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.16226528593231881\n",
      "Accuracy: 0.160795426298782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a Logistic Regression model with L-BFGS solver\n",
    "lgr = LogisticRegression(solver='lbfgs', multi_class='multinomial',  max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "lgr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = lgr.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on training data\n",
    "accuracy_train = lgr.score(X_train, y_train)\n",
    "print(\"Accuracy on training data:\", accuracy_train)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = lgr.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use only 4 languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index.data</th>\n",
       "      <th>uniform_id</th>\n",
       "      <th>itemid</th>\n",
       "      <th>sentnum</th>\n",
       "      <th>ianum</th>\n",
       "      <th>ia</th>\n",
       "      <th>PoS</th>\n",
       "      <th>skip</th>\n",
       "      <th>reread</th>\n",
       "      <th>nfix</th>\n",
       "      <th>refix</th>\n",
       "      <th>reg.in</th>\n",
       "      <th>dur</th>\n",
       "      <th>firstrun.dur</th>\n",
       "      <th>firstfix.dur</th>\n",
       "      <th>lang</th>\n",
       "      <th>PoS_num</th>\n",
       "      <th>lang_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>du_4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Samuel</td>\n",
       "      <td>NNP</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>du</td>\n",
       "      <td>10021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>du_4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Morse,</td>\n",
       "      <td>NNP</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>du</td>\n",
       "      <td>10021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>du_4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>best</td>\n",
       "      <td>JJS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>du</td>\n",
       "      <td>1654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>du_4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>known</td>\n",
       "      <td>VBN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>du</td>\n",
       "      <td>18155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>du_4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>today</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>du</td>\n",
       "      <td>76382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400802</th>\n",
       "      <td>261814</td>\n",
       "      <td>ge_55</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>112</td>\n",
       "      <td>while</td>\n",
       "      <td>IN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>ge</td>\n",
       "      <td>64601</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400803</th>\n",
       "      <td>261815</td>\n",
       "      <td>ge_55</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>113</td>\n",
       "      <td>it</td>\n",
       "      <td>PRP</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ge</td>\n",
       "      <td>13857</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400804</th>\n",
       "      <td>261816</td>\n",
       "      <td>ge_55</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>114</td>\n",
       "      <td>is</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>ge</td>\n",
       "      <td>14178</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400805</th>\n",
       "      <td>261817</td>\n",
       "      <td>ge_55</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>115</td>\n",
       "      <td>being</td>\n",
       "      <td>VBG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>ge</td>\n",
       "      <td>12202</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400806</th>\n",
       "      <td>261818</td>\n",
       "      <td>ge_55</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>116</td>\n",
       "      <td>drained.</td>\n",
       "      <td>VBN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>ge</td>\n",
       "      <td>18155</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136096 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index.data uniform_id  itemid  sentnum  ianum        ia  PoS  skip   \n",
       "0               34       du_4       1        1      1    Samuel  NNP     0  \\\n",
       "1               35       du_4       1        1      2    Morse,  NNP     0   \n",
       "2               36       du_4       1        1      3      best  JJS     0   \n",
       "3               37       du_4       1        1      4     known  VBN     0   \n",
       "4               38       du_4       1        1      5     today   NN     0   \n",
       "...            ...        ...     ...      ...    ...       ...  ...   ...   \n",
       "400802      261814      ge_55       9        6    112     while   IN     0   \n",
       "400803      261815      ge_55       9        6    113        it  PRP     1   \n",
       "400804      261816      ge_55       9        6    114        is  VBZ     0   \n",
       "400805      261817      ge_55       9        6    115     being  VBG     0   \n",
       "400806      261818      ge_55       9        6    116  drained.  VBN     0   \n",
       "\n",
       "        reread  nfix  refix  reg.in    dur  firstrun.dur  firstfix.dur lang   \n",
       "0          1.0   2.0    0.0     1.0  312.0          48.0          48.0   du  \\\n",
       "1          0.0   3.0    1.0     1.0  408.0         408.0         117.0   du   \n",
       "2          0.0   1.0    0.0     0.0   96.0          96.0          96.0   du   \n",
       "3          0.0   1.0    0.0     0.0  216.0         216.0         216.0   du   \n",
       "4          0.0   1.0    0.0     0.0  164.0         164.0         164.0   du   \n",
       "...        ...   ...    ...     ...    ...           ...           ...  ...   \n",
       "400802     1.0   3.0    1.0     0.0  466.0         288.0         207.0   ge   \n",
       "400803     0.0   0.0    0.0     0.0    0.0           0.0           0.0   ge   \n",
       "400804     0.0   1.0    0.0     0.0  202.0         202.0         202.0   ge   \n",
       "400805     0.0   1.0    0.0     0.0  164.0         164.0         164.0   ge   \n",
       "400806     0.0   1.0    0.0     0.0  261.0         261.0         261.0   ge   \n",
       "\n",
       "        PoS_num  lang_num  \n",
       "0         10021         0  \n",
       "1         10021         0  \n",
       "2          1654         0  \n",
       "3         18155         0  \n",
       "4         76382         0  \n",
       "...         ...       ...  \n",
       "400802    64601         4  \n",
       "400803    13857         4  \n",
       "400804    14178         4  \n",
       "400805    12202         4  \n",
       "400806    18155         4  \n",
       "\n",
       "[136096 rows x 18 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dataframe by rows in Estonian, Spanish, Italian, and Finnish\n",
    "split_values = ['du', 'ge','no']\n",
    "\n",
    "# Split the DataFrame using loc\n",
    "celer_similar = df.loc[df['lang'].isin(split_values)]\n",
    "celer_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target variable (y)\n",
    "X = celer_similar[['PoS_num', 'firstfix.dur', 'firstrun.dur', 'dur']]  # feature columns\n",
    "y = celer_similar['lang_num']  # target variable column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Maximum Depth DecisionTreeClassifier: 7\n",
      "Best Cross-Validation Score: 0.4351739607788222\n"
     ]
    }
   ],
   "source": [
    "# Define the range of maximum depths to try\n",
    "max_depths = range(1, 10)\n",
    "\n",
    "# Create an empty list to store the mean cross-validation scores\n",
    "cv_scores = []\n",
    "\n",
    "# Iterate over each maximum depth value\n",
    "for depth in max_depths:\n",
    "    # Create a decision tree classifier with the current maximum depth\n",
    "    tree = DecisionTreeClassifier(max_depth=depth)\n",
    "    \n",
    "    # Perform cross-validation and calculate the mean accuracy score\n",
    "    scores = cross_val_score(tree, X_train, y_train, cv=5)\n",
    "    mean_score = np.mean(scores)\n",
    "    \n",
    "    # Append the mean score to the list of scores\n",
    "    cv_scores.append(mean_score)\n",
    "    \n",
    "# Find the optimal maximum depth with the highest cross-validation score\n",
    "optimal_depth = max_depths[np.argmax(cv_scores)]\n",
    "best_score = max(cv_scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"Optimal Maximum Depth DecisionTreeClassifier:\", optimal_depth)\n",
    "print(\"Best Cross-Validation Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.40791358977185055\n",
      "Accuracy: 0.4034900808229243\n"
     ]
    }
   ],
   "source": [
    "# Create a Logistic Regression model with L-BFGS solver\n",
    "lgr = LogisticRegression(solver='lbfgs', multi_class='multinomial',  max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "lgr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = lgr.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate accuracy on training data\n",
    "accuracy_train = lgr.score(X_train, y_train)\n",
    "print(\"Accuracy on training data:\", accuracy_train)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = lgr.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "#### There seems to be an improvement when reducing the number of languages and grouping them into \n",
    "# groups of 2 unrelated languages of the same family -> it-sp vs. est-fin\n",
    "# du-ge vs. tr-fi\n",
    "# for 11 languages -> 0.16 accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
