{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deacef26-a87e-4991-8e86-ed31c5c3de75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing neccessary libraries\n",
    "from nltk.tag import DefaultTagger\n",
    "from nltk.corpus import wordnet\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bdd00f-27ca-45c5-89b2-3fb51c4bfc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad001fb4-8495-4ee8-824e-a91d3a593dbc",
   "metadata": {},
   "source": [
    "## Import the texts in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a61f0b4-3b87-4b47-aaa1-450199193da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samuel Morse, best known today as the inventor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leonardo da Vinci is not only one of the most ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Amazon Rainforest is one of the most impor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Howard Gardner was a psychologist best known f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Internet has made life a whole lot easier ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Many people fail to realize just how crucial g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A bird's feathers are extremely important, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hibernation in animals is an extremely fascina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>At one time, the use of leeches to treat medic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>When online file-sharing programs emerged, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The pencil is a modern-day version of a centur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Technology is rapidly expanding the scope of c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   Samuel Morse, best known today as the inventor...\n",
       "1   Leonardo da Vinci is not only one of the most ...\n",
       "2   The Amazon Rainforest is one of the most impor...\n",
       "3   Howard Gardner was a psychologist best known f...\n",
       "4   The Internet has made life a whole lot easier ...\n",
       "5   Many people fail to realize just how crucial g...\n",
       "6   A bird's feathers are extremely important, and...\n",
       "7   Hibernation in animals is an extremely fascina...\n",
       "8   At one time, the use of leeches to treat medic...\n",
       "9   When online file-sharing programs emerged, the...\n",
       "10  The pencil is a modern-day version of a centur...\n",
       "11  Technology is rapidly expanding the scope of c..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading used texts csv file \n",
    "texts_questions = pd.read_csv(\"texts.csv\")\n",
    "texts = pd.read_csv(\"texts.csv\", usecols = [2])\n",
    "\n",
    "texts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b090b60-76a4-4b9e-9edd-8e7c38088be0",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b17f2f-a5de-47b6-ac18-7c51acb5cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Edit the texts functions\n",
    "\n",
    "### count the number of words in text\n",
    "def word_count(text):\n",
    "    num_of_words = len(text.split())\n",
    "    return num_of_words\n",
    "\n",
    "### remove the punctuation in text\n",
    "def remove_punct(text):\n",
    "    \n",
    "    # remove the commas\n",
    "    text = text.replace(',', '')\n",
    "    \n",
    "    # remove the punctuation marks\n",
    "    text = text.replace('.', '')\n",
    "    \n",
    "    # remove the colons \n",
    "    text = text.replace(\":\", \"\")\n",
    "    \n",
    "    # remove the semicolons\n",
    "    text = text.replace(\";\", \"\")\n",
    "    \n",
    "    # remove the apostrophe\n",
    "    text = text.replace(\"’\", '')\n",
    "    \n",
    "    # remove the apostrophe\n",
    "    text = text.replace(\"'\", '')\n",
    "    \n",
    "    # remove the beginning quotation mark\n",
    "    text = text.replace(\"“\", '')\n",
    "    \n",
    "    # remove the ending quotation mark\n",
    "    text = text.replace(\"”\", '')\n",
    "    \n",
    "    #split the concatenated words into parts\n",
    "    text = text.replace(\"-\", \"- \")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10f6a9a1-0dcf-492b-af3e-3bb6184ece43",
   "metadata": {},
   "source": [
    "## First text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be574e9f-beb1-4bb6-92b0-3d6ec7918d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 160\n",
      "\n",
      "ORGINAL TEXT: \n",
      " Samuel Morse, best known today as the inventor of Morse Code and one of the inventors of the telegraph, was originally a prominent painter. While he was always interested in technology and studied electrical engineering in college, Morse went to Paris to learn from famous artists of his day and later painted many pictures that now hang in museums, including a portrait of former President John Adams. In 1825, Morse was in Washington, D.C., painting a portrait of the Marquis de Lafayette when a messenger arrived on horseback to tell him that his wife was gravely ill back at his home in Connecticut. The message had taken several days to reach him because of the distance. Morse rushed to his home as fast as he could, but his wife had already passed away by the time he arrived. Grief-stricken, he gave up painting and devoted the rest of his life to finding ways to transmit messages over long distances faster.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " Samuel Morse best known today as the inventor of Morse Code and one of the inventors of the telegraph was originally a prominent painter While he was always interested in technology and studied electrical engineering in college Morse went to Paris to learn from famous artists of his day and later painted many pictures that now hang in museums including a portrait of former President John Adams In 1825 Morse was in Washington DC painting a portrait of the Marquis de Lafayette when a messenger arrived on horseback to tell him that his wife was gravely ill back at his home in Connecticut The message had taken several days to reach him because of the distance Morse rushed to his home as fast as he could but his wife had already passed away by the time he arrived Grief- stricken he gave up painting and devoted the rest of his life to finding ways to transmit messages over long distances faster\n"
     ]
    }
   ],
   "source": [
    "### save the FIRST TEXT out of 12\n",
    "text0 =  texts['text'].iat[0]\n",
    "\n",
    "## remove punctuation from text0:\n",
    "text0_word_count = word_count(text0)\n",
    "text0_remove_punct = remove_punct(text0)\n",
    "print(\"Number of words in this text:\", text0_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text0)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text0_remove_punct)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "706e2b4a-8c5a-44d5-84bd-fd190c1d99b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text0_tokens = nltk.word_tokenize(text0_remove_punct)\n",
    "\n",
    "# print(text0_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a30f54eb-1d7f-4394-b603-a78a53fada2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text0_tagged_tokens = nltk.pos_tag(text0_tokens)\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text0_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfe7aed7-60e6-409c-8476-384b520bd20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            word   PoS\n",
      "0         Samuel   NNP\n",
      "1          Morse   NNP\n",
      "2           best   JJS\n",
      "3          known   VBN\n",
      "4          today    NN\n",
      "5             as    IN\n",
      "6            the    DT\n",
      "7       inventor    NN\n",
      "8             of    IN\n",
      "9          Morse   NNP\n",
      "10          Code   NNP\n",
      "11           and    CC\n",
      "12           one    CD\n",
      "13            of    IN\n",
      "14           the    DT\n",
      "15     inventors   NNS\n",
      "16            of    IN\n",
      "17           the    DT\n",
      "18     telegraph    NN\n",
      "19           was   VBD\n",
      "20    originally    RB\n",
      "21             a    DT\n",
      "22     prominent    JJ\n",
      "23       painter    NN\n",
      "24         While    IN\n",
      "25            he   PRP\n",
      "26           was   VBD\n",
      "27        always    RB\n",
      "28    interested    JJ\n",
      "29            in    IN\n",
      "30    technology    NN\n",
      "31           and    CC\n",
      "32       studied    JJ\n",
      "33    electrical    JJ\n",
      "34   engineering    NN\n",
      "35            in    IN\n",
      "36       college    NN\n",
      "37         Morse   NNP\n",
      "38          went   VBD\n",
      "39            to    TO\n",
      "40         Paris   NNP\n",
      "41            to    TO\n",
      "42         learn    VB\n",
      "43          from    IN\n",
      "44        famous    JJ\n",
      "45       artists   NNS\n",
      "46            of    IN\n",
      "47           his  PRP$\n",
      "48           day    NN\n",
      "49           and    CC\n",
      "50         later    RB\n",
      "51       painted   VBD\n",
      "52          many    JJ\n",
      "53      pictures   NNS\n",
      "54          that   WDT\n",
      "55           now    RB\n",
      "56          hang   VBZ\n",
      "57            in    IN\n",
      "58       museums   NNS\n",
      "59     including   VBG\n",
      "60             a    DT\n",
      "61      portrait    NN\n",
      "62            of    IN\n",
      "63        former    JJ\n",
      "64     President   NNP\n",
      "65          John   NNP\n",
      "66         Adams   NNP\n",
      "67            In    IN\n",
      "68          1825    CD\n",
      "69         Morse   NNP\n",
      "70           was   VBD\n",
      "71            in    IN\n",
      "72    Washington   NNP\n",
      "73            DC   NNP\n",
      "74      painting   VBG\n",
      "75             a    DT\n",
      "76      portrait    NN\n",
      "77            of    IN\n",
      "78           the    DT\n",
      "79       Marquis   NNP\n",
      "80            de    FW\n",
      "81     Lafayette   NNP\n",
      "82          when   WRB\n",
      "83             a    DT\n",
      "84     messenger    NN\n",
      "85       arrived   VBN\n",
      "86            on    IN\n",
      "87     horseback    NN\n",
      "88            to    TO\n",
      "89          tell    VB\n",
      "90           him   PRP\n",
      "91          that    IN\n",
      "92           his  PRP$\n",
      "93          wife    NN\n",
      "94           was   VBD\n",
      "95       gravely    RB\n",
      "96           ill    JJ\n",
      "97          back    RB\n",
      "98            at    IN\n",
      "99           his  PRP$\n",
      "100         home    NN\n",
      "101           in    IN\n",
      "102  Connecticut   NNP\n",
      "103          The    DT\n",
      "104      message    NN\n",
      "105          had   VBD\n",
      "106        taken   VBN\n",
      "107      several    JJ\n",
      "108         days   NNS\n",
      "109           to    TO\n",
      "110        reach    VB\n",
      "111          him   PRP\n",
      "112      because    IN\n",
      "113           of    IN\n",
      "114          the    DT\n",
      "115     distance    NN\n",
      "116        Morse   NNP\n",
      "117       rushed   VBD\n",
      "118           to    TO\n",
      "119          his  PRP$\n",
      "120         home    NN\n",
      "121           as    RB\n",
      "122         fast    RB\n",
      "123           as    IN\n",
      "124           he   PRP\n",
      "125        could    MD\n",
      "126          but    CC\n",
      "127          his  PRP$\n",
      "128         wife    NN\n",
      "129          had   VBD\n",
      "130      already    RB\n",
      "131       passed   VBN\n",
      "132         away    RB\n",
      "133           by    IN\n",
      "134          the    DT\n",
      "135         time    NN\n",
      "136           he   PRP\n",
      "137      arrived   VBD\n",
      "138       Grief-    JJ\n",
      "139     stricken    JJ\n",
      "140           he   PRP\n",
      "141         gave   VBD\n",
      "142           up    RP\n",
      "143     painting    NN\n",
      "144          and    CC\n",
      "145      devoted   VBD\n",
      "146          the    DT\n",
      "147         rest    NN\n",
      "148           of    IN\n",
      "149          his  PRP$\n",
      "150         life    NN\n",
      "151           to    TO\n",
      "152      finding   VBG\n",
      "153         ways   NNS\n",
      "154           to    TO\n",
      "155     transmit    VB\n",
      "156     messages   NNS\n",
      "157         over    IN\n",
      "158         long    JJ\n",
      "159    distances   NNS\n",
      "160       faster   RBR\n"
     ]
    }
   ],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text0_df_tagged = pd.DataFrame(text0_tagged_tokens, columns=['word', 'PoS'])\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "# for Grief-stricken\n",
    "# the adjective has been separated into two word parts: Grief- (NNP) and stricken (NN) and incorrectly tagged as Personal Noun and Noun\n",
    "# change the tags of \"Grief-\" and \"stricken\" to adjective\n",
    "text0_df_tagged.loc[138:139,'PoS'] = \"JJ\"\n",
    "\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(text0_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8fbf601-ffe2-4a54-a3b5-5bb9c65ddd91",
   "metadata": {},
   "source": [
    "## Second text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02e09f14-9832-4194-92df-3e4f21684274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 98\n",
      "\n",
      "ORGINAL TEXT: \n",
      " Leonardo da Vinci is not only one of the most famous artists in history, but he was also a botanist, a writer, and an inventor. Even though most of his inventions were not actually built in his lifetime, many of today’s modern machines can be traced back to some of his original designs. The parachute, the military tank, the bicycle, and even the airplane were foretold in the imaginative drawings that can still be seen in the fragments of da Vinci’s notebooks. Over five hundred years ago, this man conceived ideas that were far ahead of his time.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " Leonardo da Vinci is not only one of the most famous artists in history but he was also a botanist a writer and an inventor Even though most of his inventions were not actually built in his lifetime many of todays modern machines can be traced back to some of his original designs The parachute the military tank the bicycle and even the airplane were foretold in the imaginative drawings that can still be seen in the fragments of da Vincis notebooks Over five hundred years ago this man conceived ideas that were far ahead of his time\n"
     ]
    }
   ],
   "source": [
    "### save the SECOND TEXT out of 12\n",
    "text1 =  texts['text'].iat[1]\n",
    "\n",
    "## remove punctuation from text0:\n",
    "text1_word_count = word_count(text1)\n",
    "text1_remove_punct = remove_punct(text1)\n",
    "print(\"Number of words in this text:\", text1_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text1)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text1_remove_punct)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ec36c1f-eecf-4bef-aa1a-e835abdb0531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text1_tokens = nltk.word_tokenize(text1_remove_punct)\n",
    "\n",
    "# print(text1_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b702428-7ace-4f41-b3dc-fa72884a94db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text1_tagged_tokens = nltk.pos_tag(text1_tokens)\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text1_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fd6190bb-06d5-47c8-9bc5-7a8eb1c1e60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           word   PoS\n",
      "0      Leonardo   NNP\n",
      "1            da    NN\n",
      "2         Vinci   NNP\n",
      "3            is   VBZ\n",
      "4           not    RB\n",
      "5          only    RB\n",
      "6           one    CD\n",
      "7            of    IN\n",
      "8           the    DT\n",
      "9          most   RBS\n",
      "10       famous    JJ\n",
      "11      artists   NNS\n",
      "12           in    IN\n",
      "13      history    NN\n",
      "14          but    CC\n",
      "15           he   PRP\n",
      "16          was   VBD\n",
      "17         also    RB\n",
      "18            a    DT\n",
      "19     botanist    NN\n",
      "20            a    DT\n",
      "21       writer    NN\n",
      "22          and    CC\n",
      "23           an    DT\n",
      "24     inventor    NN\n",
      "25         Even    RB\n",
      "26       though    IN\n",
      "27         most   JJS\n",
      "28           of    IN\n",
      "29          his  PRP$\n",
      "30   inventions   NNS\n",
      "31         were   VBD\n",
      "32          not    RB\n",
      "33     actually    RB\n",
      "34        built   VBN\n",
      "35           in    IN\n",
      "36          his  PRP$\n",
      "37     lifetime    NN\n",
      "38         many    JJ\n",
      "39           of    IN\n",
      "40       todays   POS\n",
      "41       modern    JJ\n",
      "42     machines   NNS\n",
      "43          can    MD\n",
      "44           be    VB\n",
      "45       traced   VBN\n",
      "46         back    RB\n",
      "47           to    TO\n",
      "48         some    DT\n",
      "49           of    IN\n",
      "50          his  PRP$\n",
      "51     original    JJ\n",
      "52      designs   NNS\n",
      "53          The    DT\n",
      "54    parachute    NN\n",
      "55          the    DT\n",
      "56     military    JJ\n",
      "57         tank    NN\n",
      "58          the    DT\n",
      "59      bicycle    NN\n",
      "60          and    CC\n",
      "61         even    RB\n",
      "62          the    DT\n",
      "63     airplane    NN\n",
      "64         were   VBD\n",
      "65     foretold   VBN\n",
      "66           in    IN\n",
      "67          the    DT\n",
      "68  imaginative    JJ\n",
      "69     drawings   NNS\n",
      "70         that   WDT\n",
      "71          can    MD\n",
      "72        still    RB\n",
      "73           be    VB\n",
      "74         seen   VBN\n",
      "75           in    IN\n",
      "76          the    DT\n",
      "77    fragments   NNS\n",
      "78           of    IN\n",
      "79           da    NN\n",
      "80       Vincis   POS\n",
      "81    notebooks   VBZ\n",
      "82         Over    IN\n",
      "83         five    CD\n",
      "84      hundred    CD\n",
      "85        years   NNS\n",
      "86          ago    RB\n",
      "87         this    DT\n",
      "88          man    NN\n",
      "89    conceived   VBD\n",
      "90        ideas   NNS\n",
      "91         that   WDT\n",
      "92         were   VBD\n",
      "93          far    RB\n",
      "94        ahead    RB\n",
      "95           of    IN\n",
      "96          his  PRP$\n",
      "97         time    NN\n"
     ]
    }
   ],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text1_df_tagged = pd.DataFrame(text1_tagged_tokens, columns=['word', 'PoS'])\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# for today's and Vinci's\n",
    "# \"today's\" is composed of two word parts: today- (NN) and 's (POS) and incorrectly tagged as NN + NN, \n",
    "    # and when written together as \"todays\", the word is incorrectly tagged as noun plural (NNS)\n",
    "# change the tags of \"todays\" to Possesive ending (POS)\n",
    "text1_df_tagged.loc[40,'PoS'] = \"POS\"\n",
    "\n",
    "# \"Vinci's\" is composed of two word parts: Vinci- (NNP) and 's (POS) and incorrectly tagged as NN + VBD (verb past tense), \n",
    "    # and when written together as \"todays\", the word is incorrectly tagged as noun plural (NNS)\n",
    "# change the tags of \"Vincis\" to Possesive ending (POS)\n",
    "text1_df_tagged.loc[80,'PoS'] = \"POS\"\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(text1_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28265c27-89f1-4787-bfda-82992cce9389",
   "metadata": {},
   "source": [
    "## Third text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "487b5a86-5bba-4337-9013-4b60129cb647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 107\n",
      "\n",
      "ORGINAL TEXT: \n",
      " The Amazon Rainforest is one of the most important ecosystems in the world. However, it is slowly being destroyed. Areas of the rainforest are being cleared for farms and roads, and much of the wood is also being harvested and sold. There are several compelling reasons to protect this area. First, a significant number of pharmaceuticals are made from plants that have been discovered in the rainforest, and it's quite possible there are still important plants that have not yet been discovered. Secondly, the rainforest provides a significant portion of the world's oxygen and also absorbs great amounts of carbon dioxide. Without rainforests, global warming could accelerate.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " The Amazon Rainforest is one of the most important ecosystems in the world However it is slowly being destroyed Areas of the rainforest are being cleared for farms and roads and much of the wood is also being harvested and sold There are several compelling reasons to protect this area First a significant number of pharmaceuticals are made from plants that have been discovered in the rainforest and its quite possible there are still important plants that have not yet been discovered Secondly the rainforest provides a significant portion of the worlds oxygen and also absorbs great amounts of carbon dioxide Without rainforests global warming could accelerate\n"
     ]
    }
   ],
   "source": [
    "### save the THIRD TEXT out of 12\n",
    "text2 =  texts['text'].iat[2]\n",
    "\n",
    "## remove punctuation from text2:\n",
    "text2_word_count = word_count(text2)\n",
    "text2_remove_punct = remove_punct(text2)\n",
    "print(\"Number of words in this text:\", text2_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text2)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text2_remove_punct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "641cc0b6-1668-4431-9640-7f8481e63fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text2_tokens = nltk.word_tokenize(text2_remove_punct)\n",
    "\n",
    "# print(text2_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0aea51ef-09ff-484b-bc39-6ccd92e08a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text2_tokens = nltk.word_tokenize(text2_remove_punct)\n",
    "\n",
    "# print(text2_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cd67a18c-7fc4-4282-b5db-a4b698d3361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text2_tagged_tokens = nltk.pos_tag(text2_tokens)\n",
    "\n",
    "# Print the tagged tokens\n",
    "\n",
    "# print(text2_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "38edbafc-e2ae-450b-a912-5151b9f291d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                word  PoS\n",
      "0                The   DT\n",
      "1             Amazon  NNP\n",
      "2         Rainforest  NNP\n",
      "3                 is  VBZ\n",
      "4                one   CD\n",
      "5                 of   IN\n",
      "6                the   DT\n",
      "7               most  RBS\n",
      "8          important   JJ\n",
      "9         ecosystems  NNS\n",
      "10                in   IN\n",
      "11               the   DT\n",
      "12             world   NN\n",
      "13           However   RB\n",
      "14                it  PRP\n",
      "15                is  VBZ\n",
      "16            slowly   RB\n",
      "17             being  VBG\n",
      "18         destroyed  VBN\n",
      "19             Areas  NNS\n",
      "20                of   IN\n",
      "21               the   DT\n",
      "22        rainforest   NN\n",
      "23               are  VBP\n",
      "24             being  VBG\n",
      "25           cleared  VBN\n",
      "26               for   IN\n",
      "27             farms  NNS\n",
      "28               and   CC\n",
      "29             roads  NNS\n",
      "30               and   CC\n",
      "31              much   JJ\n",
      "32                of   IN\n",
      "33               the   DT\n",
      "34              wood   NN\n",
      "35                is  VBZ\n",
      "36              also   RB\n",
      "37             being  VBG\n",
      "38         harvested  VBN\n",
      "39               and   CC\n",
      "40              sold  VBN\n",
      "41             There   EX\n",
      "42               are  VBP\n",
      "43           several   JJ\n",
      "44        compelling   JJ\n",
      "45           reasons  NNS\n",
      "46                to   TO\n",
      "47           protect   VB\n",
      "48              this   DT\n",
      "49              area   NN\n",
      "50             First   RB\n",
      "51                 a   DT\n",
      "52       significant   JJ\n",
      "53            number   NN\n",
      "54                of   IN\n",
      "55   pharmaceuticals  NNS\n",
      "56               are  VBP\n",
      "57              made  VBN\n",
      "58              from   IN\n",
      "59            plants  NNS\n",
      "60              that  WDT\n",
      "61              have  VBP\n",
      "62              been  VBN\n",
      "63        discovered  VBN\n",
      "64                in   IN\n",
      "65               the   DT\n",
      "66        rainforest   NN\n",
      "67               and   CC\n",
      "68               its  VBZ\n",
      "69             quite   NN\n",
      "70          possible   JJ\n",
      "71             there   EX\n",
      "72               are  VBP\n",
      "73             still   RB\n",
      "74         important   JJ\n",
      "75            plants  NNS\n",
      "76              that  WDT\n",
      "77              have  VBP\n",
      "78               not   RB\n",
      "79               yet   RB\n",
      "80              been  VBN\n",
      "81        discovered  VBN\n",
      "82          Secondly   RB\n",
      "83               the   DT\n",
      "84        rainforest   NN\n",
      "85          provides  VBZ\n",
      "86                 a   DT\n",
      "87       significant   JJ\n",
      "88           portion   NN\n",
      "89                of   IN\n",
      "90               the   DT\n",
      "91            worlds  POS\n",
      "92            oxygen   NN\n",
      "93               and   CC\n",
      "94              also   RB\n",
      "95           absorbs   RB\n",
      "96             great   JJ\n",
      "97           amounts  NNS\n",
      "98                of   IN\n",
      "99            carbon   NN\n",
      "100          dioxide   NN\n",
      "101          Without   IN\n",
      "102      rainforests  NNS\n",
      "103           global   JJ\n",
      "104          warming   NN\n",
      "105            could   MD\n",
      "106       accelerate   VB\n"
     ]
    }
   ],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text2_df_tagged = pd.DataFrame(text2_tagged_tokens, columns=['word', 'PoS'])\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# for it's and world's\n",
    "# \"it's\" is composed of two word parts: it- (PRP) and 's (VBZ)\n",
    "    # and when written together as \"its\", the word is incorrectly tagged as possessive pronoun  (PRP$)\n",
    "# change the tags of \"its\" to verb, present tense, 3rd person singular (VBZ)\n",
    "text2_df_tagged.loc[68,'PoS'] = \"VBZ\"\n",
    "\n",
    "# \"world's\" is composed of two word parts: world- (NN) and 's (POS)\n",
    "    # and when written together as \"worlds\", the word is incorrectly tagged as noun plural (NNS)\n",
    "# change the tags of \"worlds\" to Possesive ending (POS)\n",
    "text2_df_tagged.loc[91,'PoS'] = \"POS\"\n",
    "\n",
    "# for Areas\n",
    "# \"Areas\" is incorrectly tagged as proper noun (NNP), instead of noun plural (NNS)\n",
    "# change the tags of \"Areas\" to noun plural (NNS)\n",
    "text2_df_tagged.loc[19,'PoS'] = \"NNS\"\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(text2_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6958dda-34fb-4612-83ed-d3646dad80a2",
   "metadata": {},
   "source": [
    "## Fourth text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "05d44038-6e69-4373-a772-ee433fb93a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 142\n",
      "\n",
      "ORGINAL TEXT: \n",
      " Howard Gardner was a psychologist best known for developing the theory of multiple intelligences. Basically, the theory states that the idea of general intelligence or overall intelligence is somewhat inaccurate. This is because people often show intelligence in different areas. He argued that there are actually different types of intelligence. One type of intelligence that Gardner identified was interpersonal intelligence. People who possess this type of intelligence relate and interact well with others. Intrapersonal intelligence, on the other hand, implies that people are in touch with their own feelings. They enjoy thinking about theories and developing their own thoughts and ideas. People who have linguistic intelligence learn best by taking notes and reading textbooks. These people usually excel in traditional academic environments, as many academic subjects stress these types of activities. The other types of intelligence are kinesthetic, musical, spatial, and logical.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " Howard Gardner was a psychologist best known for developing the theory of multiple intelligences Basically the theory states that the idea of general intelligence or overall intelligence is somewhat inaccurate This is because people often show intelligence in different areas He argued that there are actually different types of intelligence One type of intelligence that Gardner identified was interpersonal intelligence People who possess this type of intelligence relate and interact well with others Intrapersonal intelligence on the other hand implies that people are in touch with their own feelings They enjoy thinking about theories and developing their own thoughts and ideas People who have linguistic intelligence learn best by taking notes and reading textbooks These people usually excel in traditional academic environments as many academic subjects stress these types of activities The other types of intelligence are kinesthetic musical spatial and logical\n"
     ]
    }
   ],
   "source": [
    "### save the FOURTH TEXT out of 12\n",
    "text3 =  texts['text'].iat[3]\n",
    "\n",
    "## remove punctuation from text2:\n",
    "text3_word_count = word_count(text3)\n",
    "text3_remove_punct = remove_punct(text3)\n",
    "print(\"Number of words in this text:\", text3_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text3)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text3_remove_punct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "81518931-e65b-42cc-9aba-3fbb211bd592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text3_tokens = nltk.word_tokenize(text3_remove_punct)\n",
    "\n",
    "# print(text3_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "31f38e26-1fc0-4a39-80ee-f9b79b65dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text3_tokens = nltk.word_tokenize(text3_remove_punct)\n",
    "\n",
    "# print(text3_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "028fc094-21d7-40f9-8c8b-3c0b32d22c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text3_tagged_tokens = nltk.pos_tag(text3_tokens)\n",
    "\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text3_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6f29b0b0-4324-43bd-8e7c-2966c892799d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              word   PoS\n",
      "0           Howard   NNP\n",
      "1          Gardner   NNP\n",
      "2              was   VBD\n",
      "3                a    DT\n",
      "4     psychologist    JJ\n",
      "5             best   RBS\n",
      "6            known   VBN\n",
      "7              for    IN\n",
      "8       developing   VBG\n",
      "9              the    DT\n",
      "10          theory    NN\n",
      "11              of    IN\n",
      "12        multiple    JJ\n",
      "13   intelligences   NNS\n",
      "14       Basically    RB\n",
      "15             the    DT\n",
      "16          theory    NN\n",
      "17          states   VBZ\n",
      "18            that    IN\n",
      "19             the    DT\n",
      "20            idea    NN\n",
      "21              of    IN\n",
      "22         general    JJ\n",
      "23    intelligence    NN\n",
      "24              or    CC\n",
      "25         overall    JJ\n",
      "26    intelligence    NN\n",
      "27              is   VBZ\n",
      "28        somewhat    RB\n",
      "29      inaccurate    JJ\n",
      "30            This    DT\n",
      "31              is   VBZ\n",
      "32         because    IN\n",
      "33          people   NNS\n",
      "34           often    RB\n",
      "35            show   VBP\n",
      "36    intelligence    NN\n",
      "37              in    IN\n",
      "38       different    JJ\n",
      "39           areas   NNS\n",
      "40              He   PRP\n",
      "41          argued   VBD\n",
      "42            that    IN\n",
      "43           there    EX\n",
      "44             are   VBP\n",
      "45        actually    RB\n",
      "46       different    JJ\n",
      "47           types   NNS\n",
      "48              of    IN\n",
      "49    intelligence    NN\n",
      "50             One    CD\n",
      "51            type    NN\n",
      "52              of    IN\n",
      "53    intelligence    NN\n",
      "54            that    IN\n",
      "55         Gardner   NNP\n",
      "56      identified   VBD\n",
      "57             was   VBD\n",
      "58   interpersonal    JJ\n",
      "59    intelligence    NN\n",
      "60          People   NNS\n",
      "61             who    WP\n",
      "62         possess   VBP\n",
      "63            this    DT\n",
      "64            type    NN\n",
      "65              of    IN\n",
      "66    intelligence    NN\n",
      "67          relate    NN\n",
      "68             and    CC\n",
      "69        interact    NN\n",
      "70            well    RB\n",
      "71            with    IN\n",
      "72          others   NNS\n",
      "73   Intrapersonal    JJ\n",
      "74    intelligence    NN\n",
      "75              on    IN\n",
      "76             the    DT\n",
      "77           other    JJ\n",
      "78            hand    NN\n",
      "79         implies   NNS\n",
      "80            that    IN\n",
      "81          people   NNS\n",
      "82             are   VBP\n",
      "83              in    IN\n",
      "84           touch    NN\n",
      "85            with    IN\n",
      "86           their  PRP$\n",
      "87             own    JJ\n",
      "88        feelings   NNS\n",
      "89            They   PRP\n",
      "90           enjoy   VBP\n",
      "91        thinking   VBG\n",
      "92           about    IN\n",
      "93        theories   NNS\n",
      "94             and    CC\n",
      "95      developing   VBG\n",
      "96           their  PRP$\n",
      "97             own    JJ\n",
      "98        thoughts   NNS\n",
      "99             and    CC\n",
      "100          ideas   NNS\n",
      "101         People   NNS\n",
      "102            who    WP\n",
      "103           have   VBP\n",
      "104     linguistic    JJ\n",
      "105   intelligence    NN\n",
      "106          learn    NN\n",
      "107           best   RBS\n",
      "108             by    IN\n",
      "109         taking   VBG\n",
      "110          notes   NNS\n",
      "111            and    CC\n",
      "112        reading   VBG\n",
      "113      textbooks   NNS\n",
      "114          These    DT\n",
      "115         people   NNS\n",
      "116        usually    RB\n",
      "117          excel   VBP\n",
      "118             in    IN\n",
      "119    traditional    JJ\n",
      "120       academic    JJ\n",
      "121   environments   NNS\n",
      "122             as    IN\n",
      "123           many    JJ\n",
      "124       academic    JJ\n",
      "125       subjects   NNS\n",
      "126         stress    JJ\n",
      "127          these    DT\n",
      "128          types   NNS\n",
      "129             of    IN\n",
      "130     activities   NNS\n",
      "131            The    DT\n",
      "132          other    JJ\n",
      "133          types   NNS\n",
      "134             of    IN\n",
      "135   intelligence    NN\n",
      "136            are   VBP\n",
      "137    kinesthetic    JJ\n",
      "138        musical    JJ\n",
      "139        spatial    JJ\n",
      "140            and    CC\n",
      "141        logical    JJ\n"
     ]
    }
   ],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text3_df_tagged = pd.DataFrame(text3_tagged_tokens, columns=['word', 'PoS'])\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# for Intrapersonal and spatial\n",
    "# \"Intrapersonal\" is incorrectly tagged as proper noun (NNP), instead of adjective (JJ)\n",
    "# change the tags of \"Intrapersonal\" to adjective (JJ)\n",
    "text3_df_tagged.loc[73,'PoS'] = \"JJ\"\n",
    "\n",
    "# \"spatial\" is incorrectly tagged as noun (NN), instead of adjective (JJ)\n",
    "# change the tags of \"spatial\" to adjective (JJ)\n",
    "text3_df_tagged.loc[139,'PoS'] = \"JJ\"\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(text3_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44bc08ad-4b95-44fc-a4ce-106cd49c6d22",
   "metadata": {},
   "source": [
    "## Fifth text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "67f60824-c351-4328-9607-80d159aec273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 185\n",
      "\n",
      "ORGINAL TEXT: \n",
      " The Internet has made life a whole lot easier for many people, but being online also brings with it very real risks. Hackers can steal personal and financial information. There are several precautions that computer users can take to minimize the level of risk that is involved with being online. One of the most obvious safety precautions is to purchase a good anti-virus and anti-spyware program. Passwords are also a very important part of online security, and several tips can help users create more secure passwords. First, they should be something that can easily be remembered, but they should not be something others can guess easily. Your first or last name, phone number, or the name of your street are all bad choices, as people could learn this information quite easily. Longer passwords are more secure, and those that use a mixture of upper and lower case letters and a combination of letters and numbers are more secure than those that do not. Finally, passwords should be changed often. This can make remembering them more difficult, but the extra effort is worth the added security.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " The Internet has made life a whole lot easier for many people but being online also brings with it very real risks Hackers can steal personal and financial information There are several precautions that computer users can take to minimize the level of risk that is involved with being online One of the most obvious safety precautions is to purchase a good anti- virus and anti- spyware program Passwords are also a very important part of online security and several tips can help users create more secure passwords First they should be something that can easily be remembered but they should not be something others can guess easily Your first or last name phone number or the name of your street are all bad choices as people could learn this information quite easily Longer passwords are more secure and those that use a mixture of upper and lower case letters and a combination of letters and numbers are more secure than those that do not Finally passwords should be changed often This can make remembering them more difficult but the extra effort is worth the added security\n"
     ]
    }
   ],
   "source": [
    "### save the FIFTH TEXT out of 12\n",
    "text4 =  texts['text'].iat[4]\n",
    "\n",
    "## remove punctuation from text2:\n",
    "text4_word_count = word_count(text4)\n",
    "text4_remove_punct = remove_punct(text4)\n",
    "print(\"Number of words in this text:\", text4_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text4)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text4_remove_punct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e7dfad48-a584-4e95-8af8-e7a3adb73797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text4_tokens = nltk.word_tokenize(text4_remove_punct)\n",
    "\n",
    "# print(text4_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "51cdd7ba-f075-411d-a178-faa75515d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text4_tokens = nltk.word_tokenize(text4_remove_punct)\n",
    "\n",
    "# print(text4_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6001daf6-bf32-4844-9fcc-950cae88a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text4_tagged_tokens = nltk.pos_tag(text4_tokens)\n",
    "\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text4_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4e5691ea-6cff-4aa7-8ca6-7bf89a88d61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            word   PoS\n",
      "0            The    DT\n",
      "1       Internet   NNP\n",
      "2            has   VBZ\n",
      "3           made   VBN\n",
      "4           life    NN\n",
      "5              a    DT\n",
      "6          whole    JJ\n",
      "7            lot    NN\n",
      "8         easier   JJR\n",
      "9            for    IN\n",
      "10          many    JJ\n",
      "11        people   NNS\n",
      "12           but    CC\n",
      "13         being   VBG\n",
      "14        online    NN\n",
      "15          also    RB\n",
      "16        brings   VBZ\n",
      "17          with    IN\n",
      "18            it   PRP\n",
      "19          very    RB\n",
      "20          real    JJ\n",
      "21         risks   NNS\n",
      "22       Hackers   NNS\n",
      "23           can    MD\n",
      "24         steal    VB\n",
      "25      personal    JJ\n",
      "26           and    CC\n",
      "27     financial    JJ\n",
      "28   information    NN\n",
      "29         There    EX\n",
      "30           are   VBP\n",
      "31       several    JJ\n",
      "32   precautions   NNS\n",
      "33          that   WDT\n",
      "34      computer    NN\n",
      "35         users   NNS\n",
      "36           can    MD\n",
      "37          take    VB\n",
      "38            to    TO\n",
      "39      minimize    VB\n",
      "40           the    DT\n",
      "41         level    NN\n",
      "42            of    IN\n",
      "43          risk    NN\n",
      "44          that   WDT\n",
      "45            is   VBZ\n",
      "46      involved   VBN\n",
      "47          with    IN\n",
      "48         being   VBG\n",
      "49        online    JJ\n",
      "50           One    CD\n",
      "51            of    IN\n",
      "52           the    DT\n",
      "53          most   RBS\n",
      "54       obvious    JJ\n",
      "55        safety    NN\n",
      "56   precautions   NNS\n",
      "57            is   VBZ\n",
      "58            to    TO\n",
      "59      purchase    VB\n",
      "60             a    DT\n",
      "61          good    JJ\n",
      "62         anti-    JJ\n",
      "63         virus    JJ\n",
      "64           and    CC\n",
      "65         anti-    JJ\n",
      "66       spyware    JJ\n",
      "67       program    NN\n",
      "68     Passwords   NNS\n",
      "69           are   VBP\n",
      "70          also    RB\n",
      "71             a    DT\n",
      "72          very    RB\n",
      "73     important    JJ\n",
      "74          part    NN\n",
      "75            of    IN\n",
      "76        online    JJ\n",
      "77      security    NN\n",
      "78           and    CC\n",
      "79       several    JJ\n",
      "80          tips   NNS\n",
      "81           can    MD\n",
      "82          help    VB\n",
      "83         users   NNS\n",
      "84        create    VB\n",
      "85          more   RBR\n",
      "86        secure    JJ\n",
      "87     passwords   NNS\n",
      "88         First   NNP\n",
      "89          they   PRP\n",
      "90        should    MD\n",
      "91            be    VB\n",
      "92     something    NN\n",
      "93          that   WDT\n",
      "94           can    MD\n",
      "95        easily    RB\n",
      "96            be    VB\n",
      "97    remembered   VBN\n",
      "98           but    CC\n",
      "99          they   PRP\n",
      "100       should    MD\n",
      "101          not    RB\n",
      "102           be    VB\n",
      "103    something    NN\n",
      "104       others   NNS\n",
      "105          can    MD\n",
      "106        guess    VB\n",
      "107       easily    RB\n",
      "108         Your  PRP$\n",
      "109        first    JJ\n",
      "110           or    CC\n",
      "111         last    JJ\n",
      "112         name    NN\n",
      "113        phone    NN\n",
      "114       number    NN\n",
      "115           or    CC\n",
      "116          the    DT\n",
      "117         name    NN\n",
      "118           of    IN\n",
      "119         your  PRP$\n",
      "120       street    NN\n",
      "121          are   VBP\n",
      "122          all    DT\n",
      "123          bad    JJ\n",
      "124      choices   NNS\n",
      "125           as    IN\n",
      "126       people   NNS\n",
      "127        could    MD\n",
      "128        learn    VB\n",
      "129         this    DT\n",
      "130  information    NN\n",
      "131        quite    RB\n",
      "132       easily    RB\n",
      "133       Longer   JJR\n",
      "134    passwords   NNS\n",
      "135          are   VBP\n",
      "136         more   JJR\n",
      "137       secure    JJ\n",
      "138          and    CC\n",
      "139        those    DT\n",
      "140         that   WDT\n",
      "141          use   VBP\n",
      "142            a    DT\n",
      "143      mixture    NN\n",
      "144           of    IN\n",
      "145        upper   JJR\n",
      "146          and    CC\n",
      "147        lower   JJR\n",
      "148         case    NN\n",
      "149      letters   NNS\n",
      "150          and    CC\n",
      "151            a    DT\n",
      "152  combination    NN\n",
      "153           of    IN\n",
      "154      letters   NNS\n",
      "155          and    CC\n",
      "156      numbers   NNS\n",
      "157          are   VBP\n",
      "158         more   JJR\n",
      "159       secure    JJ\n",
      "160         than    IN\n",
      "161        those    DT\n",
      "162         that   WDT\n",
      "163           do   VBP\n",
      "164          not    RB\n",
      "165      Finally    RB\n",
      "166    passwords   NNS\n",
      "167       should    MD\n",
      "168           be    VB\n",
      "169      changed   VBN\n",
      "170        often    RB\n",
      "171         This    DT\n",
      "172          can    MD\n",
      "173         make    VB\n",
      "174  remembering   VBG\n",
      "175         them   PRP\n",
      "176         more   RBR\n",
      "177    difficult    JJ\n",
      "178          but    CC\n",
      "179          the    DT\n",
      "180        extra    JJ\n",
      "181       effort    NN\n",
      "182           is   VBZ\n",
      "183        worth    IN\n",
      "184          the    DT\n",
      "185        added    JJ\n",
      "186     security    NN\n"
     ]
    }
   ],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text4_df_tagged = pd.DataFrame(text4_tagged_tokens, columns=['word', 'PoS'])\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# for anti-virus\n",
    "# the adjective has been separated into two word parts: anti- (JJ) and virus (NN), but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"anti-\" and \"virus\" to adjective\n",
    "text4_df_tagged.loc[62:63,'PoS'] = \"JJ\"\n",
    "\n",
    "# for anti-spyware\n",
    "# the adjective has been separated into two word parts: anti- (JJ) and spyware (NN), but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"anti-\" and \"spyware\" to adjective\n",
    "text4_df_tagged.loc[65:66,'PoS'] = \"JJ\"\n",
    "\n",
    "# # \"Longer\" is incorrectly tagged as proper noun (NNP), instead of adjective, comparative (JJR)\n",
    "# # change the tags of \"Longer\" to adjective, comparative (JJR)\n",
    "text4_df_tagged.loc[133,'PoS'] = \"JJR\"\n",
    "\n",
    "# # \"upper\" is incorrectly tagged as adjective (JJ), instead of adjective, comparative (JJR)\n",
    "# # change the tags of \"upper\" to adjective, comparative (JJR)\n",
    "text4_df_tagged.loc[145,'PoS'] = \"JJR\"\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(text4_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3917d92e-b6cc-43be-b636-32b926102cde",
   "metadata": {},
   "source": [
    "## Sixth Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ef20debf-59ac-4f93-92a2-e0237085ccef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 147\n",
      "\n",
      "ORGINAL TEXT: \n",
      " Many people fail to realize just how crucial getting a good night's sleep actually is. It is usually suggested that adults get about seven hours of sleep every night, and younger children should get even more. Sleep has several benefits. First, it is believed to improve memory. This is one reason why it is always preferable to sleep the night before a test rather than stay up for the entire night to review the information. On a related note, sleep also improves concentration and mental alertness. Those who get sufficient sleep are able to concentrate on work tasks better and also react faster when they are driving a car, for example. Finally, people who get enough sleep have better immunity against illness. The reason for this is not fully understood, but researchers believe that an increase in the production of growth hormone and melatonin plays a role.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " Many people fail to realize just how crucial getting a good nights sleep actually is It is usually suggested that adults get about seven hours of sleep every night and younger children should get even more Sleep has several benefits First it is believed to improve memory This is one reason why it is always preferable to sleep the night before a test rather than stay up for the entire night to review the information On a related note sleep also improves concentration and mental alertness Those who get sufficient sleep are able to concentrate on work tasks better and also react faster when they are driving a car for example Finally people who get enough sleep have better immunity against illness The reason for this is not fully understood but researchers believe that an increase in the production of growth hormone and melatonin plays a role\n"
     ]
    }
   ],
   "source": [
    "### save the SIXTH TEXT out of 12\n",
    "text5 =  texts['text'].iat[5]\n",
    "\n",
    "## remove punctuation from text5:\n",
    "text5_word_count = word_count(text5)\n",
    "text5_remove_punct = remove_punct(text5)\n",
    "print(\"Number of words in this text:\", text5_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text5)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text5_remove_punct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7e021459-1581-494e-8d45-400bc07d3587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text5_tokens = nltk.word_tokenize(text5_remove_punct)\n",
    "\n",
    "# print(text5_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d03326fb-4072-4ae3-9569-c67e1d39e810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text5_tokens = nltk.word_tokenize(text5_remove_punct)\n",
    "\n",
    "# print(text5_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "713ebd2e-d2ac-4754-9744-d6fa18d8bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text5_tagged_tokens = nltk.pos_tag(text5_tokens)\n",
    "\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text5_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9728ba6b-4909-4114-97bc-c1ea4ccba76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              word  PoS\n",
      "0             Many   JJ\n",
      "1           people  NNS\n",
      "2             fail  VBP\n",
      "3               to   TO\n",
      "4          realize   VB\n",
      "5             just   RB\n",
      "6              how  WRB\n",
      "7          crucial   JJ\n",
      "8          getting  VBG\n",
      "9                a   DT\n",
      "10            good   JJ\n",
      "11          nights  NNS\n",
      "12           sleep  VBP\n",
      "13        actually   RB\n",
      "14              is  VBZ\n",
      "15              It  PRP\n",
      "16              is  VBZ\n",
      "17         usually   RB\n",
      "18       suggested  VBN\n",
      "19            that   IN\n",
      "20          adults  NNS\n",
      "21             get  VBP\n",
      "22           about   IN\n",
      "23           seven   CD\n",
      "24           hours  NNS\n",
      "25              of   IN\n",
      "26           sleep   JJ\n",
      "27           every   DT\n",
      "28           night   NN\n",
      "29             and   CC\n",
      "30         younger  JJR\n",
      "31        children  NNS\n",
      "32          should   MD\n",
      "33             get   VB\n",
      "34            even   RB\n",
      "35            more  RBR\n",
      "36           Sleep   NN\n",
      "37             has  VBZ\n",
      "38         several   JJ\n",
      "39        benefits  NNS\n",
      "40           First   RB\n",
      "41              it  PRP\n",
      "42              is  VBZ\n",
      "43        believed  VBN\n",
      "44              to   TO\n",
      "45         improve   VB\n",
      "46          memory   NN\n",
      "47            This   DT\n",
      "48              is  VBZ\n",
      "49             one   CD\n",
      "50          reason   NN\n",
      "51             why  WRB\n",
      "52              it  PRP\n",
      "53              is  VBZ\n",
      "54          always   RB\n",
      "55      preferable   JJ\n",
      "56              to   TO\n",
      "57           sleep   VB\n",
      "58             the   DT\n",
      "59           night   NN\n",
      "60          before   IN\n",
      "61               a   DT\n",
      "62            test   NN\n",
      "63          rather   RB\n",
      "64            than   IN\n",
      "65            stay   VB\n",
      "66              up   IN\n",
      "67             for   IN\n",
      "68             the   DT\n",
      "69          entire   JJ\n",
      "70           night   NN\n",
      "71              to   TO\n",
      "72          review   VB\n",
      "73             the   DT\n",
      "74     information   NN\n",
      "75              On   IN\n",
      "76               a   DT\n",
      "77         related   JJ\n",
      "78            note   NN\n",
      "79           sleep   NN\n",
      "80            also   RB\n",
      "81        improves  VBZ\n",
      "82   concentration   NN\n",
      "83             and   CC\n",
      "84          mental   JJ\n",
      "85       alertness   NN\n",
      "86           Those   DT\n",
      "87             who   WP\n",
      "88             get  VBP\n",
      "89      sufficient   JJ\n",
      "90           sleep   NN\n",
      "91             are  VBP\n",
      "92            able   JJ\n",
      "93              to   TO\n",
      "94     concentrate   VB\n",
      "95              on   IN\n",
      "96            work   NN\n",
      "97           tasks  NNS\n",
      "98          better  RBR\n",
      "99             and   CC\n",
      "100           also   RB\n",
      "101          react  VBP\n",
      "102         faster  RBR\n",
      "103           when  WRB\n",
      "104           they  PRP\n",
      "105            are  VBP\n",
      "106        driving  VBG\n",
      "107              a   DT\n",
      "108            car   NN\n",
      "109            for   IN\n",
      "110        example   NN\n",
      "111        Finally   RB\n",
      "112         people  NNS\n",
      "113            who   WP\n",
      "114            get  VBP\n",
      "115         enough   JJ\n",
      "116          sleep   NN\n",
      "117           have  VBP\n",
      "118         better  JJR\n",
      "119       immunity   NN\n",
      "120        against   IN\n",
      "121        illness   NN\n",
      "122            The   DT\n",
      "123         reason   NN\n",
      "124            for   IN\n",
      "125           this   DT\n",
      "126             is  VBZ\n",
      "127            not   RB\n",
      "128          fully   RB\n",
      "129     understood   JJ\n",
      "130            but   CC\n",
      "131    researchers  NNS\n",
      "132        believe  VBP\n",
      "133           that   IN\n",
      "134             an   DT\n",
      "135       increase   NN\n",
      "136             in   IN\n",
      "137            the   DT\n",
      "138     production   NN\n",
      "139             of   IN\n",
      "140         growth   NN\n",
      "141        hormone   NN\n",
      "142            and   CC\n",
      "143      melatonin   NN\n",
      "144          plays  VBZ\n",
      "145              a   DT\n",
      "146           role   NN\n"
     ]
    }
   ],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text5_df_tagged = pd.DataFrame(text5_tagged_tokens, columns=['word', 'PoS'])\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# # \"Sleep\" is incorrectly tagged as proper noun (NNP), instead of noun (NN)\n",
    "# # change the tags of \"Sleep\" to noun (NN)\n",
    "text5_df_tagged.loc[36,'PoS'] = \"NN\"\n",
    "\n",
    "# # \"First\" is incorrectly tagged as proper noun, singular (NNP), instead of adverb (RB)\n",
    "# # change the tags of \"First\" to adverb (RB)\n",
    "text5_df_tagged.loc[40,'PoS'] = \"RB\"\n",
    "\n",
    "# # \"Finally\" is incorrectly tagged as proper noun, singular (NNP), instead of adverb (RB)\n",
    "# # change the tags of \"Finally\" to adverb (RB)\n",
    "text5_df_tagged.loc[111,'PoS'] = \"RB\"\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(text5_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fd63da6-3503-4db5-847e-0ea0014eca0c",
   "metadata": {},
   "source": [
    "## Seventh text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2ffa89a8-95b0-45a5-abf6-1539eeca9314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 173\n",
      "\n",
      "ORGINAL TEXT: \n",
      " A bird's feathers are extremely important, and when they clean and smooth them, it is known as preening. Birds in the wild preen their feathers on a regular basis. This is true of most captive birds as well, but not all. For example, some birds do not preen their feathers at all. This problem is most common in birds that are taken from their mothers at a very young age. Presumably, the absence of preening is due to the fact that they were never shown how to do it properly. A more common problem among captive birds is excessive preening. Some birds may pull out large numbers of their feathers or bite them down to the skin. It should be noted that wild birds never exhibit this kind of behavior. There are several suggestions about how the problem of excessive preening can be solved, such as giving birds baths or placing them in an area that has more activity to prevent boredom. However, these measures are often not sufficient to solve the problem.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " A birds feathers are extremely important and when they clean and smooth them it is known as preening Birds in the wild preen their feathers on a regular basis This is true of most captive birds as well but not all For example some birds do not preen their feathers at all This problem is most common in birds that are taken from their mothers at a very young age Presumably the absence of preening is due to the fact that they were never shown how to do it properly A more common problem among captive birds is excessive preening Some birds may pull out large numbers of their feathers or bite them down to the skin It should be noted that wild birds never exhibit this kind of behavior There are several suggestions about how the problem of excessive preening can be solved such as giving birds baths or placing them in an area that has more activity to prevent boredom However these measures are often not sufficient to solve the problem\n"
     ]
    }
   ],
   "source": [
    "### save the SEVENTH TEXT out of 12\n",
    "text6 =  texts['text'].iat[6]\n",
    "\n",
    "## remove punctuation from text6:\n",
    "text6_word_count = word_count(text6)\n",
    "text6_remove_punct = remove_punct(text6)\n",
    "print(\"Number of words in this text:\", text6_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text6)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text6_remove_punct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f10393ca-3c8c-45bc-acc2-30768308527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text6_tokens = nltk.word_tokenize(text6_remove_punct)\n",
    "\n",
    "# print(text6_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "22c90b7c-0df2-4b95-abb8-9520cdcae9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text6_tokens = nltk.word_tokenize(text6_remove_punct)\n",
    "\n",
    "# print(text6_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cb40d40e-486d-4ffa-a274-04409ccd4c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text6_tagged_tokens = nltk.pos_tag(text6_tokens)\n",
    "\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text6_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "282d115b-0321-416e-8040-a4f423395b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            word   PoS\n",
      "0              A    DT\n",
      "1          birds   NNS\n",
      "2       feathers   NNS\n",
      "3            are   VBP\n",
      "4      extremely    RB\n",
      "5      important    JJ\n",
      "6            and    CC\n",
      "7           when   WRB\n",
      "8           they   PRP\n",
      "9          clean   VBP\n",
      "10           and    CC\n",
      "11        smooth   VBP\n",
      "12          them   PRP\n",
      "13            it   PRP\n",
      "14            is   VBZ\n",
      "15         known   VBN\n",
      "16            as    IN\n",
      "17      preening    NN\n",
      "18         Birds   NNS\n",
      "19            in    IN\n",
      "20           the    DT\n",
      "21          wild    JJ\n",
      "22         preen   VBP\n",
      "23         their  PRP$\n",
      "24      feathers   NNS\n",
      "25            on    IN\n",
      "26             a    DT\n",
      "27       regular    JJ\n",
      "28         basis    NN\n",
      "29          This    DT\n",
      "30            is   VBZ\n",
      "31          true    JJ\n",
      "32            of    IN\n",
      "33          most   JJS\n",
      "34       captive    JJ\n",
      "35         birds   NNS\n",
      "36            as    IN\n",
      "37          well    RB\n",
      "38           but    CC\n",
      "39           not    RB\n",
      "40           all    DT\n",
      "41           For    IN\n",
      "42       example    NN\n",
      "43          some    DT\n",
      "44         birds   NNS\n",
      "45            do   VBP\n",
      "46           not    RB\n",
      "47         preen    VB\n",
      "48         their  PRP$\n",
      "49      feathers   NNS\n",
      "50            at    IN\n",
      "51           all   PDT\n",
      "52          This    DT\n",
      "53       problem    NN\n",
      "54            is   VBZ\n",
      "55          most   RBS\n",
      "56        common    JJ\n",
      "57            in    IN\n",
      "58         birds   NNS\n",
      "59          that   WDT\n",
      "60           are   VBP\n",
      "61         taken   VBN\n",
      "62          from    IN\n",
      "63         their  PRP$\n",
      "64       mothers   NNS\n",
      "65            at    IN\n",
      "66             a    DT\n",
      "67          very    RB\n",
      "68         young    JJ\n",
      "69           age    NN\n",
      "70    Presumably    RB\n",
      "71           the    DT\n",
      "72       absence    NN\n",
      "73            of    IN\n",
      "74      preening    NN\n",
      "75            is   VBZ\n",
      "76           due    JJ\n",
      "77            to    TO\n",
      "78           the    DT\n",
      "79          fact    NN\n",
      "80          that    IN\n",
      "81          they   PRP\n",
      "82          were   VBD\n",
      "83         never    RB\n",
      "84         shown   VBN\n",
      "85           how   WRB\n",
      "86            to    TO\n",
      "87            do    VB\n",
      "88            it   PRP\n",
      "89      properly    VB\n",
      "90             A    DT\n",
      "91          more   RBR\n",
      "92        common    JJ\n",
      "93       problem    NN\n",
      "94         among    IN\n",
      "95       captive    JJ\n",
      "96         birds   NNS\n",
      "97            is   VBZ\n",
      "98     excessive    JJ\n",
      "99      preening   VBG\n",
      "100         Some    DT\n",
      "101        birds   NNS\n",
      "102          may    MD\n",
      "103         pull    VB\n",
      "104          out    RP\n",
      "105        large    JJ\n",
      "106      numbers   NNS\n",
      "107           of    IN\n",
      "108        their  PRP$\n",
      "109     feathers   NNS\n",
      "110           or    CC\n",
      "111         bite    VB\n",
      "112         them   PRP\n",
      "113         down    RP\n",
      "114           to    TO\n",
      "115          the    DT\n",
      "116         skin    NN\n",
      "117           It   PRP\n",
      "118       should    MD\n",
      "119           be    VB\n",
      "120        noted   VBN\n",
      "121         that    IN\n",
      "122         wild    JJ\n",
      "123        birds   NNS\n",
      "124        never    RB\n",
      "125      exhibit   VBP\n",
      "126         this    DT\n",
      "127         kind    NN\n",
      "128           of    IN\n",
      "129     behavior    NN\n",
      "130        There    EX\n",
      "131          are   VBP\n",
      "132      several    JJ\n",
      "133  suggestions   NNS\n",
      "134        about    IN\n",
      "135          how   WRB\n",
      "136          the    DT\n",
      "137      problem    NN\n",
      "138           of    IN\n",
      "139    excessive    JJ\n",
      "140     preening    NN\n",
      "141          can    MD\n",
      "142           be    VB\n",
      "143       solved   VBN\n",
      "144         such    JJ\n",
      "145           as    IN\n",
      "146       giving   VBG\n",
      "147        birds   NNS\n",
      "148        baths   NNS\n",
      "149           or    CC\n",
      "150      placing   VBG\n",
      "151         them   PRP\n",
      "152           in    IN\n",
      "153           an    DT\n",
      "154         area    NN\n",
      "155         that   WDT\n",
      "156          has   VBZ\n",
      "157         more   JJR\n",
      "158     activity    NN\n",
      "159           to    TO\n",
      "160      prevent    VB\n",
      "161      boredom    NN\n",
      "162      However    RB\n",
      "163        these    DT\n",
      "164     measures   NNS\n",
      "165          are   VBP\n",
      "166        often    RB\n",
      "167          not    RB\n",
      "168   sufficient    JJ\n",
      "169           to    TO\n",
      "170        solve    VB\n",
      "171          the    DT\n",
      "172      problem    NN\n"
     ]
    }
   ],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text6_df_tagged = pd.DataFrame(text6_tagged_tokens, columns=['word', 'PoS'])\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# # \"Presumably\" is incorrectly tagged as verb past tense (VBD), instead of adverb (RB)\n",
    "# # change the tags of \"Presumably\" to adverb (RB)\n",
    "text6_df_tagged.loc[70,'PoS'] = \"RB\"\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(text6_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30f078d9-9939-461f-95ac-0250ef608aec",
   "metadata": {},
   "source": [
    "## Eighth text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "03b3b51d-2f57-453f-a987-0df13438dbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 133\n",
      "\n",
      "ORGINAL TEXT: \n",
      " Hibernation in animals is an extremely fascinating phenomenon, one that biologists are not yet close to understanding fully. However, it is quite easy to understand why animals hibernate during the cold winter months. Usually, it is because their food is quite scarce during this time. Animals that are herbivores will find the winters extremely tough, because all of the vegetation will have died off by the time winter arrives. Hibernation is essentially a way of dealing with this food shortage. Animals like birds rely on seeds and small insects for sustenance. Obviously, these will also be quite scarce in the winter when the ground becomes covered and frozen. Many birds address their upcoming food shortage in quite a different way: they migrate to warmer areas where their sources of food will be plentiful.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " Hibernation in animals is an extremely fascinating phenomenon one that biologists are not yet close to understanding fully However it is quite easy to understand why animals hibernate during the cold winter months Usually it is because their food is quite scarce during this time Animals that are herbivores will find the winters extremely tough because all of the vegetation will have died off by the time winter arrives Hibernation is essentially a way of dealing with this food shortage Animals like birds rely on seeds and small insects for sustenance Obviously these will also be quite scarce in the winter when the ground becomes covered and frozen Many birds address their upcoming food shortage in quite a different way they migrate to warmer areas where their sources of food will be plentiful\n"
     ]
    }
   ],
   "source": [
    "### save the EIGHTH TEXT out of 12\n",
    "text7 =  texts['text'].iat[7]\n",
    "\n",
    "## remove punctuation from text7:\n",
    "text7_word_count = word_count(text7)\n",
    "text7_remove_punct = remove_punct(text7)\n",
    "print(\"Number of words in this text:\", text7_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text7)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text7_remove_punct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "234f944f-96fa-4ead-a7c9-9540b3ef3e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text7_tokens = nltk.word_tokenize(text7_remove_punct)\n",
    "\n",
    "# print(text7_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5156d2c7-af6e-4ea1-8fe1-22033ecf94aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text7_tokens = nltk.word_tokenize(text7_remove_punct)\n",
    "\n",
    "# print(text7_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "51525360-fd3d-42d4-bef0-31c59283bc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text7_tagged_tokens = nltk.pos_tag(text7_tokens)\n",
    "\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text7_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d6c52676-161f-4881-8123-aef69a5eae94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              word   PoS\n",
      "0      Hibernation    NN\n",
      "1               in    IN\n",
      "2          animals   NNS\n",
      "3               is   VBZ\n",
      "4               an    DT\n",
      "5        extremely    RB\n",
      "6      fascinating    JJ\n",
      "7       phenomenon    NN\n",
      "8              one    CD\n",
      "9             that   WDT\n",
      "10      biologists   NNS\n",
      "11             are   VBP\n",
      "12             not    RB\n",
      "13             yet    RB\n",
      "14           close    JJ\n",
      "15              to    TO\n",
      "16   understanding   VBG\n",
      "17           fully    RB\n",
      "18         However    RB\n",
      "19              it   PRP\n",
      "20              is   VBZ\n",
      "21           quite    RB\n",
      "22            easy    JJ\n",
      "23              to    TO\n",
      "24      understand    VB\n",
      "25             why   WRB\n",
      "26         animals   NNS\n",
      "27       hibernate   VBP\n",
      "28          during    IN\n",
      "29             the    DT\n",
      "30            cold    JJ\n",
      "31          winter    NN\n",
      "32          months   NNS\n",
      "33         Usually    IN\n",
      "34              it   PRP\n",
      "35              is   VBZ\n",
      "36         because    IN\n",
      "37           their  PRP$\n",
      "38            food    NN\n",
      "39              is   VBZ\n",
      "40           quite    RB\n",
      "41          scarce    JJ\n",
      "42          during    IN\n",
      "43            this    DT\n",
      "44            time    NN\n",
      "45         Animals   NNS\n",
      "46            that   WDT\n",
      "47             are   VBP\n",
      "48      herbivores   NNS\n",
      "49            will    MD\n",
      "50            find    VB\n",
      "51             the    DT\n",
      "52         winters   NNS\n",
      "53       extremely    RB\n",
      "54           tough    JJ\n",
      "55         because    IN\n",
      "56             all    DT\n",
      "57              of    IN\n",
      "58             the    DT\n",
      "59      vegetation    NN\n",
      "60            will    MD\n",
      "61            have    VB\n",
      "62            died   VBN\n",
      "63             off    RP\n",
      "64              by    IN\n",
      "65             the    DT\n",
      "66            time    NN\n",
      "67          winter    NN\n",
      "68         arrives   NNS\n",
      "69     Hibernation    NN\n",
      "70              is   VBZ\n",
      "71     essentially    RB\n",
      "72               a    DT\n",
      "73             way    NN\n",
      "74              of    IN\n",
      "75         dealing   VBG\n",
      "76            with    IN\n",
      "77            this    DT\n",
      "78            food    NN\n",
      "79        shortage    NN\n",
      "80         Animals   NNS\n",
      "81            like    IN\n",
      "82           birds   NNS\n",
      "83            rely    RB\n",
      "84              on    IN\n",
      "85           seeds   NNS\n",
      "86             and    CC\n",
      "87           small    JJ\n",
      "88         insects   NNS\n",
      "89             for    IN\n",
      "90      sustenance    NN\n",
      "91       Obviously    RB\n",
      "92           these    DT\n",
      "93            will    MD\n",
      "94            also    RB\n",
      "95              be    VB\n",
      "96           quite    RB\n",
      "97          scarce    JJ\n",
      "98              in    IN\n",
      "99             the    DT\n",
      "100         winter    NN\n",
      "101           when   WRB\n",
      "102            the    DT\n",
      "103         ground    NN\n",
      "104        becomes   VBZ\n",
      "105        covered   VBN\n",
      "106            and    CC\n",
      "107         frozen    JJ\n",
      "108           Many    JJ\n",
      "109          birds   NNS\n",
      "110        address   VBP\n",
      "111          their  PRP$\n",
      "112       upcoming    JJ\n",
      "113           food    NN\n",
      "114       shortage    NN\n",
      "115             in    IN\n",
      "116          quite    RB\n",
      "117              a    DT\n",
      "118      different    JJ\n",
      "119            way    NN\n",
      "120           they   PRP\n",
      "121        migrate   VBP\n",
      "122             to    TO\n",
      "123         warmer   JJR\n",
      "124          areas   NNS\n",
      "125          where   WRB\n",
      "126          their  PRP$\n",
      "127        sources   NNS\n",
      "128             of    IN\n",
      "129           food    NN\n",
      "130           will    MD\n",
      "131             be    VB\n",
      "132      plentiful    JJ\n"
     ]
    }
   ],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text7_df_tagged = pd.DataFrame(text7_tagged_tokens, columns=['word', 'PoS'])\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# # \"Animals\" is incorrectly tagged as verb, present tense with 3rd person singular (VBZ), instead of noun plural (NNS)\n",
    "# # change the tags of \"Animals\" to noun plural (NNS)\n",
    "text7_df_tagged.loc[45,'PoS'] = \"NNS\"\n",
    "\n",
    "# # \"Hibernation\" is incorrectly tagged as verb past tense (VBD), instead of noun (NN)\n",
    "# # change the tags of \"Hibernation\" to noun (NN)\n",
    "text7_df_tagged.loc[69,'PoS'] = \"NN\"\n",
    "\n",
    "# # \"Obviously\" is incorrectly tagged as proper noun, singular (NNP), instead of adverb (RB)\n",
    "# # change the tags of \"Obviously\" to adverb (RB)\n",
    "text7_df_tagged.loc[91,'PoS'] = \"RB\"\n",
    "\n",
    "# # \"Many\" is incorrectly tagged as proper noun, singular (NNP), instead of adjective (JJ)\n",
    "# # change the tags of \"Many\" to adjective (JJ)\n",
    "text7_df_tagged.loc[108,'PoS'] = \"JJ\"\n",
    "\n",
    "# # \"warmer\" is incorrectly tagged as verb (VB), instead of adjective, comparative (JJR)\n",
    "# # change the tags of \"warmer\" to adjective, comparative (JJR)\n",
    "text7_df_tagged.loc[123,'PoS'] = \"JJR\"\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(text7_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7cab73f6-1adc-49eb-ab9c-6abb85a04ecb",
   "metadata": {},
   "source": [
    "## Ninth text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c5b046cd-0c62-4218-844a-2b955a52635d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 115\n",
      "\n",
      "ORGINAL TEXT: \n",
      " At one time, the use of leeches to treat medical problems was quite common. If a person suffered from a snake bite or a bee sting, leeches were believed to be capable of removing the poison from the body if they were placed on top of the wound. They have also been used for blood letting and to stop hemorrhages, although neither of these leech treatments would be considered acceptable by present-day physicians. Today, leeches are still used on a limited basis. Most often, leeches are used to drain blood from clogged veins. This results in little pain for the patient and also ensures the patient's blood will not clot while it is being drained.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " At one time the use of leeches to treat medical problems was quite common If a person suffered from a snake bite or a bee sting leeches were believed to be capable of removing the poison from the body if they were placed on top of the wound They have also been used for blood letting and to stop hemorrhages although neither of these leech treatments would be considered acceptable by present- day physicians Today leeches are still used on a limited basis Most often leeches are used to drain blood from clogged veins This results in little pain for the patient and also ensures the patients blood will not clot while it is being drained\n"
     ]
    }
   ],
   "source": [
    "### save the NINTH TEXT out of 12\n",
    "text8 =  texts['text'].iat[8]\n",
    "\n",
    "## remove punctuation from text8:\n",
    "text8_word_count = word_count(text8)\n",
    "text8_remove_punct = remove_punct(text8)\n",
    "print(\"Number of words in this text:\", text8_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text8)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text8_remove_punct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "987c6217-cffb-4314-91ed-f171eb1b628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text8_tokens = nltk.word_tokenize(text8_remove_punct)\n",
    "\n",
    "# print(text8_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8c60369a-111a-4286-ab56-f17ae12edb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text8_tokens = nltk.word_tokenize(text8_remove_punct)\n",
    "\n",
    "# print(text8_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "170032f4-aa58-49ac-97fd-b75c1c3ede0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text8_tagged_tokens = nltk.pos_tag(text8_tokens)\n",
    "\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text8_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b13b1a17-fcc1-4b46-95db-36530b7be75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            word  PoS\n",
      "0             At   IN\n",
      "1            one   CD\n",
      "2           time   NN\n",
      "3            the   DT\n",
      "4            use   NN\n",
      "5             of   IN\n",
      "6        leeches  NNS\n",
      "7             to   TO\n",
      "8          treat   VB\n",
      "9        medical   JJ\n",
      "10      problems  NNS\n",
      "11           was  VBD\n",
      "12         quite   RB\n",
      "13        common   JJ\n",
      "14            If   IN\n",
      "15             a   DT\n",
      "16        person   NN\n",
      "17      suffered  VBN\n",
      "18          from   IN\n",
      "19             a   DT\n",
      "20         snake   JJ\n",
      "21          bite   NN\n",
      "22            or   CC\n",
      "23             a   DT\n",
      "24           bee   JJ\n",
      "25         sting   NN\n",
      "26       leeches  NNS\n",
      "27          were  VBD\n",
      "28      believed  VBN\n",
      "29            to   TO\n",
      "30            be   VB\n",
      "31       capable   JJ\n",
      "32            of   IN\n",
      "33      removing  VBG\n",
      "34           the   DT\n",
      "35        poison   NN\n",
      "36          from   IN\n",
      "37           the   DT\n",
      "38          body   NN\n",
      "39            if   IN\n",
      "40          they  PRP\n",
      "41          were  VBD\n",
      "42        placed  VBN\n",
      "43            on   IN\n",
      "44           top   NN\n",
      "45            of   IN\n",
      "46           the   DT\n",
      "47         wound   NN\n",
      "48          They  PRP\n",
      "49          have  VBP\n",
      "50          also   RB\n",
      "51          been  VBN\n",
      "52          used  VBN\n",
      "53           for   IN\n",
      "54         blood   NN\n",
      "55       letting   NN\n",
      "56           and   CC\n",
      "57            to   TO\n",
      "58          stop   VB\n",
      "59   hemorrhages  NNS\n",
      "60      although   IN\n",
      "61       neither   DT\n",
      "62            of   IN\n",
      "63         these   DT\n",
      "64         leech   JJ\n",
      "65    treatments  NNS\n",
      "66         would   MD\n",
      "67            be   VB\n",
      "68    considered  VBN\n",
      "69    acceptable   JJ\n",
      "70            by   IN\n",
      "71      present-   JJ\n",
      "72           day   JJ\n",
      "73    physicians  NNS\n",
      "74         Today   RB\n",
      "75       leeches  NNS\n",
      "76           are  VBP\n",
      "77         still   RB\n",
      "78          used  VBN\n",
      "79            on   IN\n",
      "80             a   DT\n",
      "81       limited   JJ\n",
      "82         basis   NN\n",
      "83          Most   RB\n",
      "84         often   RB\n",
      "85       leeches  NNS\n",
      "86           are  VBP\n",
      "87          used  VBN\n",
      "88            to   TO\n",
      "89         drain   VB\n",
      "90         blood   NN\n",
      "91          from   IN\n",
      "92       clogged   JJ\n",
      "93         veins  NNS\n",
      "94          This   DT\n",
      "95       results  NNS\n",
      "96            in   IN\n",
      "97        little   JJ\n",
      "98          pain   NN\n",
      "99           for   IN\n",
      "100          the   DT\n",
      "101      patient   NN\n",
      "102          and   CC\n",
      "103         also   RB\n",
      "104      ensures  VBZ\n",
      "105          the   DT\n",
      "106     patients  NNS\n",
      "107        blood   NN\n",
      "108         will   MD\n",
      "109          not   RB\n",
      "110         clot   VB\n",
      "111        while   IN\n",
      "112           it  PRP\n",
      "113           is  VBZ\n",
      "114        being  VBG\n",
      "115      drained  VBN\n"
     ]
    }
   ],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text8_df_tagged = pd.DataFrame(text8_tagged_tokens, columns=['word', 'PoS'])\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# for present-day\n",
    "# the adjective has been separated into two word parts: present- (JJ) and day (NN), but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"present-\" and \"day\" to adjective\n",
    "text8_df_tagged.loc[72,'PoS'] = \"JJ\"\n",
    "\n",
    "# # \"Today\" is incorrectly tagged as verb, present tense not 3rd person singular (VBP), instead of adverb (RB)\n",
    "# # change the tags of \"Today\" to adverb (RB)\n",
    "text8_df_tagged.loc[74,'PoS'] = \"RB\"\n",
    "\n",
    "# # \"Most\" is incorrectly tagged as proper noun, singular (NNP), instead of adverb (RB)\n",
    "# # change the tags of \"Today\" to adverb (RB)\n",
    "text8_df_tagged.loc[83,'PoS'] = \"RB\"\n",
    "\n",
    "# # \"leeches\" is incorrectly tagged as verb, present tense with 3rd person singular (VBZ), instead of noun plural (NNS)\n",
    "# # change the tags of \"leeches\" to noun plural (NNS)\n",
    "text8_df_tagged.loc[85,'PoS'] = \"NNS\"\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(text8_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8439003e-d3c4-40a4-a5f9-a2d9ee7aebbc",
   "metadata": {},
   "source": [
    "## Tenth text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c35cb711-90bb-4448-95bc-4835d066e3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 123\n",
      "\n",
      "ORGINAL TEXT: \n",
      " When online file-sharing programs emerged, the music industry changed forever. Perhaps the first widely-used music file sharing program was Napster. It allowed users to sign up to use the service at no charge. Then, they could download music files from other users all over the world by simply typing in what song or album they wanted. Obviously, this was bad news for music artists and record labels because they were not making any profits from downloaded music. Eventually, Napster was shut down. While it later reinvented itself as a paying service, other free music-sharing sites cropped up almost immediately. Even though several sites and individual users have been charged, there are still countless individuals who log onto these sites to obtain free music.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " When online file- sharing programs emerged the music industry changed forever Perhaps the first widely- used music file sharing program was Napster It allowed users to sign up to use the service at no charge Then they could download music files from other users all over the world by simply typing in what song or album they wanted Obviously this was bad news for music artists and record labels because they were not making any profits from downloaded music Eventually Napster was shut down While it later reinvented itself as a paying service other free music- sharing sites cropped up almost immediately Even though several sites and individual users have been charged there are still countless individuals who log onto these sites to obtain free music\n"
     ]
    }
   ],
   "source": [
    "### save the TENTH TEXT out of 12\n",
    "text9 =  texts['text'].iat[9]\n",
    "\n",
    "## remove punctuation from text9:\n",
    "text9_word_count = word_count(text9)\n",
    "text9_remove_punct = remove_punct(text9)\n",
    "print(\"Number of words in this text:\", text9_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text9)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text9_remove_punct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "14720da3-86c9-420c-972f-8225e529a377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text9_tokens = nltk.word_tokenize(text9_remove_punct)\n",
    "\n",
    "# print(text9_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "86b2ba25-1c0b-4e9c-864c-c7bbc771ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text9_tokens = nltk.word_tokenize(text9_remove_punct)\n",
    "\n",
    "# print(text9_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "7e9455f6-5b80-4f9f-826b-b823dfcdee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text9_tagged_tokens = nltk.pos_tag(text9_tokens)\n",
    "\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text9_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "9f5abf1a-cfde-4d12-94b7-8cc767156774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            word  PoS\n",
      "0           When  WRB\n",
      "1         online   JJ\n",
      "2          file-   JJ\n",
      "3        sharing   JJ\n",
      "4       programs  NNS\n",
      "5        emerged  VBD\n",
      "6            the   DT\n",
      "7          music   NN\n",
      "8       industry   NN\n",
      "9        changed  VBD\n",
      "10       forever   RB\n",
      "11       Perhaps   RB\n",
      "12           the   DT\n",
      "13         first   JJ\n",
      "14       widely-   JJ\n",
      "15          used   JJ\n",
      "16         music   NN\n",
      "17          file   NN\n",
      "18       sharing  VBG\n",
      "19       program   NN\n",
      "20           was  VBD\n",
      "21       Napster  NNP\n",
      "22            It  PRP\n",
      "23       allowed  VBD\n",
      "24         users  NNS\n",
      "25            to   TO\n",
      "26          sign   VB\n",
      "27            up   RP\n",
      "28            to   TO\n",
      "29           use   VB\n",
      "30           the   DT\n",
      "31       service   NN\n",
      "32            at   IN\n",
      "33            no   DT\n",
      "34        charge   NN\n",
      "35          Then   RB\n",
      "36          they  PRP\n",
      "37         could   MD\n",
      "38      download   VB\n",
      "39         music   NN\n",
      "40         files  NNS\n",
      "41          from   IN\n",
      "42         other   JJ\n",
      "43         users  NNS\n",
      "44           all   DT\n",
      "45          over   IN\n",
      "46           the   DT\n",
      "47         world   NN\n",
      "48            by   IN\n",
      "49        simply   RB\n",
      "50        typing  VBG\n",
      "51            in   IN\n",
      "52          what   WP\n",
      "53          song   NN\n",
      "54            or   CC\n",
      "55         album   NN\n",
      "56          they  PRP\n",
      "57        wanted  VBD\n",
      "58     Obviously   RB\n",
      "59          this   DT\n",
      "60           was  VBD\n",
      "61           bad   JJ\n",
      "62          news   NN\n",
      "63           for   IN\n",
      "64         music   NN\n",
      "65       artists  NNS\n",
      "66           and   CC\n",
      "67        record   NN\n",
      "68        labels  NNS\n",
      "69       because   IN\n",
      "70          they  PRP\n",
      "71          were  VBD\n",
      "72           not   RB\n",
      "73        making  VBG\n",
      "74           any   DT\n",
      "75       profits  NNS\n",
      "76          from   IN\n",
      "77    downloaded  VBN\n",
      "78         music   NN\n",
      "79    Eventually   RB\n",
      "80       Napster  NNP\n",
      "81           was  VBD\n",
      "82          shut  VBN\n",
      "83          down   RP\n",
      "84         While   IN\n",
      "85            it  PRP\n",
      "86         later   RB\n",
      "87    reinvented  VBD\n",
      "88        itself  PRP\n",
      "89            as   IN\n",
      "90             a   DT\n",
      "91        paying  VBG\n",
      "92       service   NN\n",
      "93         other   JJ\n",
      "94          free   JJ\n",
      "95        music-   JJ\n",
      "96       sharing   JJ\n",
      "97         sites  NNS\n",
      "98       cropped  VBD\n",
      "99            up   RP\n",
      "100       almost   RB\n",
      "101  immediately   RB\n",
      "102         Even   RB\n",
      "103       though   IN\n",
      "104      several   JJ\n",
      "105        sites  NNS\n",
      "106          and   CC\n",
      "107   individual   JJ\n",
      "108        users  NNS\n",
      "109         have  VBP\n",
      "110         been  VBN\n",
      "111      charged  VBN\n",
      "112        there   EX\n",
      "113          are  VBP\n",
      "114        still   RB\n",
      "115    countless   JJ\n",
      "116  individuals  NNS\n",
      "117          who   WP\n",
      "118          log  VBP\n",
      "119         onto   IN\n",
      "120        these   DT\n",
      "121        sites  NNS\n",
      "122           to   TO\n",
      "123       obtain   VB\n",
      "124         free   JJ\n",
      "125        music   NN\n"
     ]
    }
   ],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text9_df_tagged = pd.DataFrame(text9_tagged_tokens, columns=['word', 'PoS'])\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# for file-sharing\n",
    "# the adjective has been separated into two word parts: file- (JJ) and sharing (NN), but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"file-\" and \"sharing\" to adjective (JJ)\n",
    "text9_df_tagged.loc[3,'PoS'] = \"JJ\"\n",
    "\n",
    "# for widely-used\n",
    "# the adjective has been separated into two word parts: widely- (RB) and used (JJ) and incorrectly tagged as Noun (NN) and verb past participle (VBN)\n",
    "# but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"widely-\" and \"stricken\" to adjective (JJ)\n",
    "text9_df_tagged.loc[14:15,'PoS'] = \"JJ\"\n",
    "\n",
    "# for music-sharing\n",
    "# the adjective has been separated into two word parts: music- (NN) and sharing (VBG) and music incorrectly tagged as noun plural (NNS)\n",
    "# but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"music-\" and \"sharing\" to adjective (JJ)\n",
    "text9_df_tagged.loc[95:96,'PoS'] = \"JJ\"\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(text9_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f24af256-d5bd-4d97-a427-1b657a648921",
   "metadata": {},
   "source": [
    "## Eleventh text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "e820845c-3f64-4012-beb7-2953b07554f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 116\n",
      "\n",
      "ORGINAL TEXT: \n",
      " The pencil is a modern-day version of a centuries-old writing implement. Around 1560, an Italian couple designed the modern, wood-encased pencil. Their creation was flatter and more compact than the pencils we use today. Their plan involved hollowing out a stick of wood and inserting a stick of graphite into it. Shortly after, a better technique was discovered: two wooden halves were carved, a graphite stick was inserted, and then the halves were glued together, which is also how pencils are currently made. Although many people refer to the graphite inside pencils as “lead”, they have always been made with graphite; however, the paint on the wood that surrounded the graphite was, at one time, lead-based.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " The pencil is a modern- day version of a centuries- old writing implement Around 1560 an Italian couple designed the modern wood- encased pencil Their creation was flatter and more compact than the pencils we use today Their plan involved hollowing out a stick of wood and inserting a stick of graphite into it Shortly after a better technique was discovered two wooden halves were carved a graphite stick was inserted and then the halves were glued together which is also how pencils are currently made Although many people refer to the graphite inside pencils as lead they have always been made with graphite however the paint on the wood that surrounded the graphite was at one time lead- based\n"
     ]
    }
   ],
   "source": [
    "### save the ELEVENTH TEXT out of 12\n",
    "text10 =  texts['text'].iat[10]\n",
    "\n",
    "## remove punctuation from text10:\n",
    "text10_word_count = word_count(text10)\n",
    "text10_remove_punct = remove_punct(text10)\n",
    "print(\"Number of words in this text:\", text10_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text10)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text10_remove_punct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c1abba9c-6ec2-46dc-bcc7-85b2c71b4da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text10_tokens = nltk.word_tokenize(text10_remove_punct)\n",
    "\n",
    "# print(text10_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "8a6ec7dc-3ab6-4d7b-bc63-cff9584c0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text10_tokens = nltk.word_tokenize(text10_remove_punct)\n",
    "\n",
    "# print(text10_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "86ff72a5-c620-4e98-b8d9-8b8c8687b843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text10_tagged_tokens = nltk.pos_tag(text10_tokens)\n",
    "\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text10_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "2d89b00e-cc31-4f92-a8b6-e10aa0386442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           word   PoS\n",
      "0           The    DT\n",
      "1        pencil    NN\n",
      "2            is   VBZ\n",
      "3             a    DT\n",
      "4       modern-    JJ\n",
      "5           day    JJ\n",
      "6       version    NN\n",
      "7            of    IN\n",
      "8             a    DT\n",
      "9    centuries-    JJ\n",
      "10          old    JJ\n",
      "11      writing    NN\n",
      "12    implement    NN\n",
      "13       Around    IN\n",
      "14         1560    CD\n",
      "15           an    DT\n",
      "16      Italian    JJ\n",
      "17       couple    NN\n",
      "18     designed   VBN\n",
      "19          the    DT\n",
      "20       modern    JJ\n",
      "21        wood-    JJ\n",
      "22      encased    JJ\n",
      "23       pencil   PDT\n",
      "24        Their  PRP$\n",
      "25     creation    NN\n",
      "26          was   VBD\n",
      "27      flatter   JJR\n",
      "28          and    CC\n",
      "29         more   JJR\n",
      "30      compact    JJ\n",
      "31         than    IN\n",
      "32          the    DT\n",
      "33      pencils   NNS\n",
      "34           we   PRP\n",
      "35          use   VBP\n",
      "36        today    RB\n",
      "37        Their   NNP\n",
      "38         plan    NN\n",
      "39     involved   VBN\n",
      "40    hollowing   VBG\n",
      "41          out    RP\n",
      "42            a    DT\n",
      "43        stick    NN\n",
      "44           of    IN\n",
      "45         wood    NN\n",
      "46          and    CC\n",
      "47    inserting   VBG\n",
      "48            a    DT\n",
      "49        stick    NN\n",
      "50           of    IN\n",
      "51     graphite    NN\n",
      "52         into    IN\n",
      "53           it   PRP\n",
      "54      Shortly    RB\n",
      "55        after    IN\n",
      "56            a    DT\n",
      "57       better   JJR\n",
      "58    technique    NN\n",
      "59          was   VBD\n",
      "60   discovered   VBN\n",
      "61          two    CD\n",
      "62       wooden    JJ\n",
      "63       halves   NNS\n",
      "64         were   VBD\n",
      "65       carved   VBN\n",
      "66            a    DT\n",
      "67     graphite    JJ\n",
      "68        stick    NN\n",
      "69          was   VBD\n",
      "70     inserted   VBN\n",
      "71          and    CC\n",
      "72         then    RB\n",
      "73          the    DT\n",
      "74       halves   NNS\n",
      "75         were   VBD\n",
      "76        glued   VBN\n",
      "77     together    RB\n",
      "78        which   WDT\n",
      "79           is   VBZ\n",
      "80         also    RB\n",
      "81          how   WRB\n",
      "82      pencils   NNS\n",
      "83          are   VBP\n",
      "84    currently    RB\n",
      "85         made   VBN\n",
      "86     Although    IN\n",
      "87         many    JJ\n",
      "88       people   NNS\n",
      "89        refer   VBP\n",
      "90           to    TO\n",
      "91          the    DT\n",
      "92     graphite    JJ\n",
      "93       inside    NN\n",
      "94      pencils   NNS\n",
      "95           as    IN\n",
      "96         lead    NN\n",
      "97         they   PRP\n",
      "98         have   VBP\n",
      "99       always    RB\n",
      "100        been   VBN\n",
      "101        made   VBN\n",
      "102        with    IN\n",
      "103    graphite    JJ\n",
      "104     however    RB\n",
      "105         the    DT\n",
      "106       paint    NN\n",
      "107          on    IN\n",
      "108         the    DT\n",
      "109        wood    NN\n",
      "110        that   WDT\n",
      "111  surrounded   VBD\n",
      "112         the    DT\n",
      "113    graphite    NN\n",
      "114         was   VBD\n",
      "115          at    IN\n",
      "116         one    CD\n",
      "117        time    NN\n",
      "118       lead-    JJ\n",
      "119       based    JJ\n"
     ]
    }
   ],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text10_df_tagged = pd.DataFrame(text10_tagged_tokens, columns=['word', 'PoS'])\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# for modern-day\n",
    "# the adjective has been separated into two word parts: modern- (JJ) and day (NN), but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"modern-\" and \"day\" to adjective (JJ)\n",
    "text10_df_tagged.loc[5,'PoS'] = \"JJ\"\n",
    "\n",
    "# for wood-encased\n",
    "# the adjective has been separated into two word parts: wood- (JJ) and encased (VBD), but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"wood-\" and \"encased\" to adjective (JJ)\n",
    "text10_df_tagged.loc[21:22,'PoS'] = \"JJ\"\n",
    "\n",
    "# # \"Their\" is incorrectly tagged as proper noun, singular (NNP), instead of possessive pronoun (PRP$)\n",
    "# # change the tags of \"Their\" to possessive pronoun (PRP$)\n",
    "text10_df_tagged.loc[24,'PoS'] = \"PRP$\"\n",
    "\n",
    "# # \"today\" is incorrectly tagged as noun, singular (NN), instead of adverb (RB)\n",
    "# # change the tags of \"today\" to adverb (RB)\n",
    "text10_df_tagged.loc[36,'PoS'] = \"RB\"\n",
    "\n",
    "# for lead-based\n",
    "# the adjective has been separated into two word parts: lead- (NN) and based (VBN), but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"lead-\" and \"based\" to adjective (JJ)\n",
    "text10_df_tagged.loc[118:119,'PoS'] = \"JJ\"\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(text10_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "303d86b5-25fa-4036-9fb4-166026b915b7",
   "metadata": {},
   "source": [
    "## Twelfth text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "382f38de-fd15-4b92-8c0b-a544dce25537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 146\n",
      "\n",
      "ORGINAL TEXT: \n",
      " Technology is rapidly expanding the scope of capabilities for both professional and personal use; such is the case with smart phones. Professionals now have mobile devices available to them capable of digital media, internet access, phone communication, multi-person scheduling and office tools for documents and presentations. Businesspeople that are often mobile may maximize the use of these critical features on smart phones. Individuals who simply enjoy the luxury of multi-function devices often use these devices for frivolous pursuits such as downloading catchy ring tones, instant messaging about the latest gossip and looking up the world record for most cans crushed on one’s head during the Superbowl. This fusion of capabilities and increased availability of such devices could be a sign of a growing blend in society between work and personal life, or individuals could simply be taking a luxurious approach to their connectivity in personal lives.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " Technology is rapidly expanding the scope of capabilities for both professional and personal use such is the case with smart phones Professionals now have mobile devices available to them capable of digital media internet access phone communication multi- person scheduling and office tools for documents and presentations Businesspeople that are often mobile may maximize the use of these critical features on smart phones Individuals who simply enjoy the luxury of multi- function devices often use these devices for frivolous pursuits such as downloading catchy ring tones instant messaging about the latest gossip and looking up the world record for most cans crushed on ones head during the Superbowl This fusion of capabilities and increased availability of such devices could be a sign of a growing blend in society between work and personal life or individuals could simply be taking a luxurious approach to their connectivity in personal lives\n"
     ]
    }
   ],
   "source": [
    "### save the TWELFTH TEXT out of 12\n",
    "text11 =  texts['text'].iat[11]\n",
    "\n",
    "## remove punctuation from text11:\n",
    "text11_word_count = word_count(text11)\n",
    "text11_remove_punct = remove_punct(text11)\n",
    "print(\"Number of words in this text:\", text11_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text11)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text11_remove_punct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "b26d0f0f-984a-4c65-958e-2fd7614f918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text11_tokens = nltk.word_tokenize(text11_remove_punct)\n",
    "\n",
    "# print(text11_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "3d5af56c-0a91-4ae9-8468-c6bc67a74aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text11_tokens = nltk.word_tokenize(text11_remove_punct)\n",
    "\n",
    "# print(text11_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b61314af-01fb-4c86-b7d1-797e61186c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text11_tagged_tokens = nltk.pos_tag(text11_tokens)\n",
    "\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text11_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e5556e85-32f1-404a-9993-1affa090bd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               word   PoS\n",
      "0        Technology    NN\n",
      "1                is   VBZ\n",
      "2           rapidly    RB\n",
      "3         expanding   VBG\n",
      "4               the    DT\n",
      "5             scope    NN\n",
      "6                of    IN\n",
      "7      capabilities   NNS\n",
      "8               for    IN\n",
      "9              both    DT\n",
      "10     professional    JJ\n",
      "11              and    CC\n",
      "12         personal    JJ\n",
      "13              use    NN\n",
      "14             such    JJ\n",
      "15               is   VBZ\n",
      "16              the    DT\n",
      "17             case    NN\n",
      "18             with    IN\n",
      "19            smart    JJ\n",
      "20           phones   NNS\n",
      "21    Professionals   NNS\n",
      "22              now    RB\n",
      "23             have   VBP\n",
      "24           mobile    JJ\n",
      "25          devices   NNS\n",
      "26        available    JJ\n",
      "27               to    TO\n",
      "28             them   PRP\n",
      "29          capable    JJ\n",
      "30               of    IN\n",
      "31          digital    JJ\n",
      "32            media   NNS\n",
      "33         internet    JJ\n",
      "34           access    NN\n",
      "35            phone    NN\n",
      "36    communication    NN\n",
      "37           multi-    JJ\n",
      "38           person    JJ\n",
      "39       scheduling   VBG\n",
      "40              and    CC\n",
      "41           office    NN\n",
      "42            tools   NNS\n",
      "43              for    IN\n",
      "44        documents   NNS\n",
      "45              and    CC\n",
      "46    presentations   NNS\n",
      "47   Businesspeople   NNS\n",
      "48             that   WDT\n",
      "49              are   VBP\n",
      "50            often    RB\n",
      "51           mobile    JJ\n",
      "52              may    MD\n",
      "53         maximize    VB\n",
      "54              the    DT\n",
      "55              use    NN\n",
      "56               of    IN\n",
      "57            these    DT\n",
      "58         critical    JJ\n",
      "59         features   NNS\n",
      "60               on    IN\n",
      "61            smart    JJ\n",
      "62           phones   NNS\n",
      "63      Individuals   NNS\n",
      "64              who    WP\n",
      "65           simply    RB\n",
      "66            enjoy    VB\n",
      "67              the    DT\n",
      "68           luxury    NN\n",
      "69               of    IN\n",
      "70           multi-    JJ\n",
      "71         function    JJ\n",
      "72          devices   NNS\n",
      "73            often    RB\n",
      "74              use   VBP\n",
      "75            these    DT\n",
      "76          devices   NNS\n",
      "77              for    IN\n",
      "78        frivolous    JJ\n",
      "79         pursuits   NNS\n",
      "80             such    JJ\n",
      "81               as    IN\n",
      "82      downloading   VBG\n",
      "83           catchy    NN\n",
      "84             ring   VBG\n",
      "85            tones   NNS\n",
      "86          instant    JJ\n",
      "87        messaging   VBG\n",
      "88            about    IN\n",
      "89              the    DT\n",
      "90           latest   JJS\n",
      "91           gossip    NN\n",
      "92              and    CC\n",
      "93          looking   VBG\n",
      "94               up    RP\n",
      "95              the    DT\n",
      "96            world    NN\n",
      "97           record    NN\n",
      "98              for    IN\n",
      "99             most   JJS\n",
      "100            cans   NNS\n",
      "101         crushed   VBN\n",
      "102              on    IN\n",
      "103            ones   NNS\n",
      "104            head    NN\n",
      "105          during    IN\n",
      "106             the    DT\n",
      "107       Superbowl   NNP\n",
      "108            This    DT\n",
      "109          fusion    NN\n",
      "110              of    IN\n",
      "111    capabilities   NNS\n",
      "112             and    CC\n",
      "113       increased    JJ\n",
      "114    availability    NN\n",
      "115              of    IN\n",
      "116            such    JJ\n",
      "117         devices   NNS\n",
      "118           could    MD\n",
      "119              be    VB\n",
      "120               a    DT\n",
      "121            sign    NN\n",
      "122              of    IN\n",
      "123               a    DT\n",
      "124         growing   VBG\n",
      "125           blend    NN\n",
      "126              in    IN\n",
      "127         society    NN\n",
      "128         between    IN\n",
      "129            work    NN\n",
      "130             and    CC\n",
      "131        personal    JJ\n",
      "132            life    NN\n",
      "133              or    CC\n",
      "134     individuals   NNS\n",
      "135           could    MD\n",
      "136          simply    RB\n",
      "137              be    VB\n",
      "138          taking   VBG\n",
      "139               a    DT\n",
      "140       luxurious    JJ\n",
      "141        approach    NN\n",
      "142              to    TO\n",
      "143           their  PRP$\n",
      "144    connectivity    NN\n",
      "145              in    IN\n",
      "146        personal    JJ\n",
      "147           lives   NNS\n"
     ]
    }
   ],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text11_df_tagged = pd.DataFrame(text11_tagged_tokens, columns=['word', 'PoS'])\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# for multi-person\n",
    "# the adjective has been separated into two word parts: multi- (JJ) and person (NN), but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"multi-\" and \"person\" to adjective (JJ)\n",
    "text11_df_tagged.loc[38,'PoS'] = \"JJ\"\n",
    "\n",
    "# # \"Businesspeople\" is incorrectly tagged as proper noun, singular (NNP), instead of noun plural (NNS)\n",
    "# # change the tags of \"Businesspeople\" to noun plural (NNS)\n",
    "text11_df_tagged.loc[47,'PoS'] = \"NNS\"\n",
    "\n",
    "# for multi-function\n",
    "# the adjective has been separated into two word parts: multi- (JJ) and function (NN), but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"multi-\" and \"function\" to adjective (JJ)\n",
    "text11_df_tagged.loc[71,'PoS'] = \"JJ\"\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(text11_df_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c5edd8-c9cb-4981-8c92-ba9cc427781b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be24233-9e03-4d35-9dec-3dd8ee546544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79257c1-9797-4b78-ae8e-e7984e5af384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd81bb4-d2d0-42fb-a6d5-acaf2b4bbdba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f975899b-4108-4f7e-9d12-ad7f64bd3dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subid</th>\n",
       "      <th>trialid</th>\n",
       "      <th>trialnum</th>\n",
       "      <th>itemid</th>\n",
       "      <th>cond</th>\n",
       "      <th>sentnum</th>\n",
       "      <th>ianum</th>\n",
       "      <th>ia</th>\n",
       "      <th>blink</th>\n",
       "      <th>...</th>\n",
       "      <th>singlefix</th>\n",
       "      <th>singlefix.sac.in</th>\n",
       "      <th>singlefix.sac.out</th>\n",
       "      <th>singlefix.launch</th>\n",
       "      <th>singlefix.land</th>\n",
       "      <th>singlefix.cland</th>\n",
       "      <th>singlefix.dur</th>\n",
       "      <th>lang</th>\n",
       "      <th>trial</th>\n",
       "      <th>uniform_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>DU_04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Samuel</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>du</td>\n",
       "      <td>NaN</td>\n",
       "      <td>du_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>DU_04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Morse,</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>du</td>\n",
       "      <td>NaN</td>\n",
       "      <td>du_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>DU_04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>best</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>du</td>\n",
       "      <td>NaN</td>\n",
       "      <td>du_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>DU_04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>known</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>du</td>\n",
       "      <td>NaN</td>\n",
       "      <td>du_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>DU_04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>today</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>du</td>\n",
       "      <td>NaN</td>\n",
       "      <td>du_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>17</td>\n",
       "      <td>DU_04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>157</td>\n",
       "      <td>messages</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>258.0</td>\n",
       "      <td>du</td>\n",
       "      <td>NaN</td>\n",
       "      <td>du_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>18</td>\n",
       "      <td>DU_04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>158</td>\n",
       "      <td>over</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>du</td>\n",
       "      <td>NaN</td>\n",
       "      <td>du_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>19</td>\n",
       "      <td>DU_04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>159</td>\n",
       "      <td>long</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>243.0</td>\n",
       "      <td>du</td>\n",
       "      <td>NaN</td>\n",
       "      <td>du_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>20</td>\n",
       "      <td>DU_04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>160</td>\n",
       "      <td>distances</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>du</td>\n",
       "      <td>NaN</td>\n",
       "      <td>du_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>21</td>\n",
       "      <td>DU_04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>161</td>\n",
       "      <td>faster.</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>du</td>\n",
       "      <td>NaN</td>\n",
       "      <td>du_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  subid  trialid  trialnum  itemid  cond  sentnum  ianum   \n",
       "0            34  DU_04        1         1       1     1        1      1  \\\n",
       "1            35  DU_04        1         1       1     1        1      2   \n",
       "2            36  DU_04        1         1       1     1        1      3   \n",
       "3            37  DU_04        1         1       1     1        1      4   \n",
       "4            38  DU_04        1         1       1     1        1      5   \n",
       "..          ...    ...      ...       ...     ...   ...      ...    ...   \n",
       "156          17  DU_04        1         1       1     1        6    157   \n",
       "157          18  DU_04        1         1       1     1        6    158   \n",
       "158          19  DU_04        1         1       1     1        6    159   \n",
       "159          20  DU_04        1         1       1     1        6    160   \n",
       "160          21  DU_04        1         1       1     1        6    161   \n",
       "\n",
       "            ia  blink  ...  singlefix  singlefix.sac.in  singlefix.sac.out   \n",
       "0       Samuel      0  ...          1               NaN               16.0  \\\n",
       "1       Morse,      0  ...          0               NaN                NaN   \n",
       "2         best      0  ...          1              16.0               -7.0   \n",
       "3        known      0  ...          1               8.0                6.0   \n",
       "4        today      0  ...          1               6.0                5.0   \n",
       "..         ...    ...  ...        ...               ...                ...   \n",
       "156   messages      0  ...          1               9.0                9.0   \n",
       "157       over      0  ...          0               NaN                NaN   \n",
       "158       long      0  ...          1               9.0               11.0   \n",
       "159  distances      0  ...          0               NaN                NaN   \n",
       "160    faster.      0  ...          0               NaN                NaN   \n",
       "\n",
       "     singlefix.launch  singlefix.land  singlefix.cland  singlefix.dur  lang   \n",
       "0                 NaN             0.0             -3.5           48.0    du  \\\n",
       "1                 NaN             NaN              NaN            NaN    du   \n",
       "2                13.0             3.0              0.5           96.0    du   \n",
       "3                 7.0             1.0             -2.0          216.0    du   \n",
       "4                 5.0             1.0             -2.0          164.0    du   \n",
       "..                ...             ...              ...            ...   ...   \n",
       "156               4.0             5.0              0.5          258.0    du   \n",
       "157               NaN             NaN              NaN            NaN    du   \n",
       "158               9.0             0.0             -2.5          243.0    du   \n",
       "159               NaN             NaN              NaN            NaN    du   \n",
       "160               NaN             NaN              NaN            NaN    du   \n",
       "\n",
       "     trial  uniform_id  \n",
       "0      NaN        du_4  \n",
       "1      NaN        du_4  \n",
       "2      NaN        du_4  \n",
       "3      NaN        du_4  \n",
       "4      NaN        du_4  \n",
       "..     ...         ...  \n",
       "156    NaN        du_4  \n",
       "157    NaN        du_4  \n",
       "158    NaN        du_4  \n",
       "159    NaN        du_4  \n",
       "160    NaN        du_4  \n",
       "\n",
       "[161 rows x 42 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Import the MAIN DATASET to be analyzed\n",
    "\n",
    "## reading the eye tracking csv file \n",
    "df = pd.read_csv(\"data.csv\", nrows=161)\n",
    "\n",
    "## sort the data frame by sentence sequence number in the text (sentnum)\n",
    "df = df.sort_values('sentnum')\n",
    "\n",
    "\n",
    "## sort the data frame by the word sequence number in the text(ianum)\n",
    "df = df.sort_values('ianum')\n",
    "\n",
    "## reset the index number of the data frame\n",
    "df = df.reset_index(drop=True)\n",
    "## print the data frame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "b1d64eb6-36d4-4786-af79-df422aa297e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PoS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PoS'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[234], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m## Pop out the PoS column from the tagged dataframe\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m col \u001b[39m=\u001b[39m text0_df_tagged\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mPoS\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(col)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:5553\u001b[0m, in \u001b[0;36mDataFrame.pop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   5512\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpop\u001b[39m(\u001b[39mself\u001b[39m, item: Hashable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series:\n\u001b[0;32m   5513\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5514\u001b[0m \u001b[39m    Return item and drop from frame. Raise KeyError if not found.\u001b[39;00m\n\u001b[0;32m   5515\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5551\u001b[0m \u001b[39m    3  monkey        NaN\u001b[39;00m\n\u001b[0;32m   5552\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpop(item\u001b[39m=\u001b[39;49mitem)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:853\u001b[0m, in \u001b[0;36mNDFrame.pop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpop\u001b[39m(\u001b[39mself\u001b[39m, item: Hashable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m Any:\n\u001b[1;32m--> 853\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m[item]\n\u001b[0;32m    854\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m[item]\n\u001b[0;32m    856\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PoS'"
     ]
    }
   ],
   "source": [
    "## Pop out the PoS column from the tagged dataframe\n",
    "col = text0_df_tagged.pop(\"PoS\")\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbab328-eb25-4ebe-880a-94a14dd76eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  subid  trialid  trialnum  itemid  cond  sentnum  ianum   \n",
      "0            34  DU_04        1         1       1     1        1      1  \\\n",
      "1            35  DU_04        1         1       1     1        1      2   \n",
      "2            36  DU_04        1         1       1     1        1      3   \n",
      "3            37  DU_04        1         1       1     1        1      4   \n",
      "4            38  DU_04        1         1       1     1        1      5   \n",
      "..          ...    ...      ...       ...     ...   ...      ...    ...   \n",
      "156          17  DU_04        1         1       1     1        6    157   \n",
      "157          18  DU_04        1         1       1     1        6    158   \n",
      "158          19  DU_04        1         1       1     1        6    159   \n",
      "159          20  DU_04        1         1       1     1        6    160   \n",
      "160          21  DU_04        1         1       1     1        6    161   \n",
      "\n",
      "            ia  PoS  ...  singlefix  singlefix.sac.in  singlefix.sac.out   \n",
      "0       Samuel  NNP  ...          1               NaN               16.0  \\\n",
      "1       Morse,  NNP  ...          0               NaN                NaN   \n",
      "2         best  JJS  ...          1              16.0               -7.0   \n",
      "3        known  VBN  ...          1               8.0                6.0   \n",
      "4        today   NN  ...          1               6.0                5.0   \n",
      "..         ...  ...  ...        ...               ...                ...   \n",
      "156   messages  NNS  ...          1               9.0                9.0   \n",
      "157       over   IN  ...          0               NaN                NaN   \n",
      "158       long   JJ  ...          1               9.0               11.0   \n",
      "159  distances  NNS  ...          0               NaN                NaN   \n",
      "160    faster.  RBR  ...          0               NaN                NaN   \n",
      "\n",
      "     singlefix.launch  singlefix.land  singlefix.cland  singlefix.dur  lang   \n",
      "0                 NaN             0.0             -3.5           48.0    du  \\\n",
      "1                 NaN             NaN              NaN            NaN    du   \n",
      "2                13.0             3.0              0.5           96.0    du   \n",
      "3                 7.0             1.0             -2.0          216.0    du   \n",
      "4                 5.0             1.0             -2.0          164.0    du   \n",
      "..                ...             ...              ...            ...   ...   \n",
      "156               4.0             5.0              0.5          258.0    du   \n",
      "157               NaN             NaN              NaN            NaN    du   \n",
      "158               9.0             0.0             -2.5          243.0    du   \n",
      "159               NaN             NaN              NaN            NaN    du   \n",
      "160               NaN             NaN              NaN            NaN    du   \n",
      "\n",
      "     trial  uniform_id  \n",
      "0      NaN        du_4  \n",
      "1      NaN        du_4  \n",
      "2      NaN        du_4  \n",
      "3      NaN        du_4  \n",
      "4      NaN        du_4  \n",
      "..     ...         ...  \n",
      "156    NaN        du_4  \n",
      "157    NaN        du_4  \n",
      "158    NaN        du_4  \n",
      "159    NaN        du_4  \n",
      "160    NaN        du_4  \n",
      "\n",
      "[161 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "df.insert(loc=9, column='PoS', value=col)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab058d8-4f56-49c4-93c0-02d257afe3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfe03c7-bc96-472b-85b6-eba14c392ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  subid  trialid  trialnum  itemid  cond  sentnum  ianum   \n",
      "0            34  DU_04        1         1       1     1        1      1  \\\n",
      "1            35  DU_04        1         1       1     1        1      2   \n",
      "2            36  DU_04        1         1       1     1        1      3   \n",
      "3            37  DU_04        1         1       1     1        1      4   \n",
      "4            38  DU_04        1         1       1     1        1      5   \n",
      "5            39  DU_04        1         1       1     1        1      6   \n",
      "6            40  DU_04        1         1       1     1        1      7   \n",
      "7            41  DU_04        1         1       1     1        1      8   \n",
      "8            42  DU_04        1         1       1     1        1      9   \n",
      "9            43  DU_04        1         1       1     1        1     10   \n",
      "10           44  DU_04        1         1       1     1        1     11   \n",
      "11           45  DU_04        1         1       1     1        1     12   \n",
      "12           46  DU_04        1         1       1     1        1     13   \n",
      "13           47  DU_04        1         1       1     1        1     14   \n",
      "14           48  DU_04        1         1       1     1        1     15   \n",
      "15           49  DU_04        1         1       1     1        1     16   \n",
      "16           50  DU_04        1         1       1     1        1     17   \n",
      "17           51  DU_04        1         1       1     1        1     18   \n",
      "18           52  DU_04        1         1       1     1        1     19   \n",
      "19           53  DU_04        1         1       1     1        1     20   \n",
      "20           54  DU_04        1         1       1     1        1     21   \n",
      "21           55  DU_04        1         1       1     1        1     22   \n",
      "22           56  DU_04        1         1       1     1        1     23   \n",
      "23           57  DU_04        1         1       1     1        1     24   \n",
      "24           58  DU_04        1         1       1     1        2     25   \n",
      "25           59  DU_04        1         1       1     1        2     26   \n",
      "26           60  DU_04        1         1       1     1        2     27   \n",
      "27           61  DU_04        1         1       1     1        2     28   \n",
      "28           62  DU_04        1         1       1     1        2     29   \n",
      "29           63  DU_04        1         1       1     1        2     30   \n",
      "30           64  DU_04        1         1       1     1        2     31   \n",
      "31           65  DU_04        1         1       1     1        2     32   \n",
      "32           66  DU_04        1         1       1     1        2     33   \n",
      "33           67  DU_04        1         1       1     1        2     34   \n",
      "34           68  DU_04        1         1       1     1        2     35   \n",
      "35           69  DU_04        1         1       1     1        2     36   \n",
      "36           70  DU_04        1         1       1     1        2     37   \n",
      "37           71  DU_04        1         1       1     1        2     38   \n",
      "38           72  DU_04        1         1       1     1        2     39   \n",
      "39           73  DU_04        1         1       1     1        2     40   \n",
      "40           74  DU_04        1         1       1     1        2     41   \n",
      "41           75  DU_04        1         1       1     1        2     42   \n",
      "42           76  DU_04        1         1       1     1        2     43   \n",
      "43           77  DU_04        1         1       1     1        2     44   \n",
      "44           78  DU_04        1         1       1     1        2     45   \n",
      "45           79  DU_04        1         1       1     1        2     46   \n",
      "46           80  DU_04        1         1       1     1        2     47   \n",
      "47           81  DU_04        1         1       1     1        2     48   \n",
      "48           82  DU_04        1         1       1     1        2     49   \n",
      "49           83  DU_04        1         1       1     1        2     50   \n",
      "50           84  DU_04        1         1       1     1        2     51   \n",
      "51           85  DU_04        1         1       1     1        2     52   \n",
      "52           86  DU_04        1         1       1     1        2     53   \n",
      "53           87  DU_04        1         1       1     1        2     54   \n",
      "54           88  DU_04        1         1       1     1        2     55   \n",
      "55           89  DU_04        1         1       1     1        2     56   \n",
      "56           90  DU_04        1         1       1     1        2     57   \n",
      "57           91  DU_04        1         1       1     1        2     58   \n",
      "58           92  DU_04        1         1       1     1        2     59   \n",
      "59           93  DU_04        1         1       1     1        2     60   \n",
      "60           94  DU_04        1         1       1     1        2     61   \n",
      "61           95  DU_04        1         1       1     1        2     62   \n",
      "62           96  DU_04        1         1       1     1        2     63   \n",
      "63           97  DU_04        1         1       1     1        2     64   \n",
      "64           98  DU_04        1         1       1     1        2     65   \n",
      "65           99  DU_04        1         1       1     1        2     66   \n",
      "66          100  DU_04        1         1       1     1        2     67   \n",
      "67          101  DU_04        1         1       1     1        3     68   \n",
      "68          102  DU_04        1         1       1     1        3     69   \n",
      "69          103  DU_04        1         1       1     1        3     70   \n",
      "70          104  DU_04        1         1       1     1        3     71   \n",
      "71          105  DU_04        1         1       1     1        3     72   \n",
      "72          106  DU_04        1         1       1     1        3     73   \n",
      "73          107  DU_04        1         1       1     1        3     74   \n",
      "74          108  DU_04        1         1       1     1        3     75   \n",
      "75          109  DU_04        1         1       1     1        3     76   \n",
      "76          110  DU_04        1         1       1     1        3     77   \n",
      "77          111  DU_04        1         1       1     1        3     78   \n",
      "78          112  DU_04        1         1       1     1        3     79   \n",
      "79          113  DU_04        1         1       1     1        3     80   \n",
      "80          114  DU_04        1         1       1     1        3     81   \n",
      "81          115  DU_04        1         1       1     1        3     82   \n",
      "82          116  DU_04        1         1       1     1        3     83   \n",
      "83          117  DU_04        1         1       1     1        3     84   \n",
      "84          118  DU_04        1         1       1     1        3     85   \n",
      "85          119  DU_04        1         1       1     1        3     86   \n",
      "86          120  DU_04        1         1       1     1        3     87   \n",
      "87          121  DU_04        1         1       1     1        3     88   \n",
      "88          122  DU_04        1         1       1     1        3     89   \n",
      "89          123  DU_04        1         1       1     1        3     90   \n",
      "90          124  DU_04        1         1       1     1        3     91   \n",
      "91          125  DU_04        1         1       1     1        3     92   \n",
      "92          126  DU_04        1         1       1     1        3     93   \n",
      "93          127  DU_04        1         1       1     1        3     94   \n",
      "94          128  DU_04        1         1       1     1        3     95   \n",
      "95          129  DU_04        1         1       1     1        3     96   \n",
      "96          130  DU_04        1         1       1     1        3     97   \n",
      "97          131  DU_04        1         1       1     1        3     98   \n",
      "98          132  DU_04        1         1       1     1        3     99   \n",
      "99          133  DU_04        1         1       1     1        3    100   \n",
      "100         134  DU_04        1         1       1     1        3    101   \n",
      "101         135  DU_04        1         1       1     1        3    102   \n",
      "102         136  DU_04        1         1       1     1        3    103   \n",
      "103         137  DU_04        1         1       1     1        4    104   \n",
      "104         138  DU_04        1         1       1     1        4    105   \n",
      "105         139  DU_04        1         1       1     1        4    106   \n",
      "106         140  DU_04        1         1       1     1        4    107   \n",
      "107         141  DU_04        1         1       1     1        4    108   \n",
      "108         142  DU_04        1         1       1     1        4    109   \n",
      "109         143  DU_04        1         1       1     1        4    110   \n",
      "110         144  DU_04        1         1       1     1        4    111   \n",
      "111         145  DU_04        1         1       1     1        4    112   \n",
      "112         146  DU_04        1         1       1     1        4    113   \n",
      "113         147  DU_04        1         1       1     1        4    114   \n",
      "114         148  DU_04        1         1       1     1        4    115   \n",
      "115         149  DU_04        1         1       1     1        4    116   \n",
      "116         150  DU_04        1         1       1     1        5    117   \n",
      "117         151  DU_04        1         1       1     1        5    118   \n",
      "118         152  DU_04        1         1       1     1        5    119   \n",
      "119         153  DU_04        1         1       1     1        5    120   \n",
      "120         154  DU_04        1         1       1     1        5    121   \n",
      "121         155  DU_04        1         1       1     1        5    122   \n",
      "122         156  DU_04        1         1       1     1        5    123   \n",
      "123         157  DU_04        1         1       1     1        5    124   \n",
      "124         158  DU_04        1         1       1     1        5    125   \n",
      "125         159  DU_04        1         1       1     1        5    126   \n",
      "126         160  DU_04        1         1       1     1        5    127   \n",
      "127         161  DU_04        1         1       1     1        5    128   \n",
      "128          22  DU_04        1         1       1     1        5    129   \n",
      "129          23  DU_04        1         1       1     1        5    130   \n",
      "130          24  DU_04        1         1       1     1        5    131   \n",
      "131          25  DU_04        1         1       1     1        5    132   \n",
      "132          26  DU_04        1         1       1     1        5    133   \n",
      "133          27  DU_04        1         1       1     1        5    134   \n",
      "134          28  DU_04        1         1       1     1        5    135   \n",
      "135          29  DU_04        1         1       1     1        5    136   \n",
      "136          30  DU_04        1         1       1     1        5    137   \n",
      "137          31  DU_04        1         1       1     1        5    138   \n",
      "138          32  DU_04        1         1       1     1        6    139   \n",
      "139          33  DU_04        1         1       1     1        6    140   \n",
      "140           1  DU_04        1         1       1     1        6    141   \n",
      "141           2  DU_04        1         1       1     1        6    142   \n",
      "142           3  DU_04        1         1       1     1        6    143   \n",
      "143           4  DU_04        1         1       1     1        6    144   \n",
      "144           5  DU_04        1         1       1     1        6    145   \n",
      "145           6  DU_04        1         1       1     1        6    146   \n",
      "146           7  DU_04        1         1       1     1        6    147   \n",
      "147           8  DU_04        1         1       1     1        6    148   \n",
      "148           9  DU_04        1         1       1     1        6    149   \n",
      "149          10  DU_04        1         1       1     1        6    150   \n",
      "150          11  DU_04        1         1       1     1        6    151   \n",
      "151          12  DU_04        1         1       1     1        6    152   \n",
      "152          13  DU_04        1         1       1     1        6    153   \n",
      "153          14  DU_04        1         1       1     1        6    154   \n",
      "154          15  DU_04        1         1       1     1        6    155   \n",
      "155          16  DU_04        1         1       1     1        6    156   \n",
      "156          17  DU_04        1         1       1     1        6    157   \n",
      "157          18  DU_04        1         1       1     1        6    158   \n",
      "158          19  DU_04        1         1       1     1        6    159   \n",
      "159          20  DU_04        1         1       1     1        6    160   \n",
      "160          21  DU_04        1         1       1     1        6    161   \n",
      "\n",
      "               ia   PoS  blink  skip  nrun  reread  nfix  refix  reg.in   \n",
      "0          Samuel   NNP      0     0   2.0     1.0   2.0    0.0     1.0  \\\n",
      "1          Morse,   NNP      0     0   1.0     0.0   3.0    1.0     1.0   \n",
      "2            best   JJS      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "3           known   VBN      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "4           today    NN      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "5              as    IN      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "6             the    DT      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "7        inventor    NN      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "8              of    IN      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "9           Morse   NNP      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "10           Code   NNP      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "11            and    CC      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "12            one    CD      0     0   1.0     0.0   2.0    1.0     1.0   \n",
      "13             of    IN      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "14            the    DT      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "15      inventors   NNS      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "16             of    IN      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "17            the    DT      0     0   1.0     0.0   1.0    0.0     1.0   \n",
      "18     telegraph,    NN      0     0   2.0     1.0   2.0    0.0     0.0   \n",
      "19            was   VBD      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "20     originally    RB      0     0   1.0     0.0   3.0    1.0     0.0   \n",
      "21              a    DT      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "22      prominent    JJ      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "23       painter.    NN      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "24          While    IN      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "25             he   PRP      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "26            was   VBD      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "27         always    RB      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "28     interested    JJ      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "29             in    IN      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "30     technology    NN      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "31            and    CC      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "32        studied    JJ      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "33     electrical    JJ      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "34    engineering    NN      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "35             in    IN      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "36       college,    NN      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "37          Morse   NNP      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "38           went   VBD      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "39             to    TO      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "40          Paris   NNP      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "41             to    TO      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "42          learn    VB      0     0   1.0     0.0   1.0    0.0     1.0   \n",
      "43           from    IN      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "44         famous    JJ      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "45        artists   NNS      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "46             of    IN      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "47            his  PRP$      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "48            day    NN      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "49            and    CC      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "50          later    RB      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "51        painted   VBD      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "52           many    JJ      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "53       pictures   NNS      0     0   1.0     0.0   1.0    0.0     1.0   \n",
      "54           that   WDT      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "55            now    RB      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "56           hang   VBZ      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "57             in    IN      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "58       museums,   NNS      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "59      including   VBG      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "60              a    DT      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "61       portrait    NN      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "62             of    IN      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "63         former    JJ      0     0   1.0     0.0   1.0    0.0     1.0   \n",
      "64      President   NNP      0     0   2.0     1.0   2.0    0.0     0.0   \n",
      "65           John   NNP      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "66         Adams.   NNP      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "67             In    IN      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "68          1825,    CD      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "69          Morse   NNP      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "70            was   VBD      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "71             in    IN      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "72    Washington,   NNP      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "73          D.C.,   NNP      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "74       painting   VBG      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "75              a    DT      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "76       portrait    NN      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "77             of    IN      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "78            the    DT      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "79        Marquis   NNP      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "80             de    FW      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "81      Lafayette   NNP      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "82           when   WRB      0     0   1.0     0.0   1.0    0.0     1.0   \n",
      "83              a    DT      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "84      messenger    NN      0     0   3.0     1.0   4.0    1.0     1.0   \n",
      "85        arrived   VBN      0     0   2.0     1.0   3.0    0.0     1.0   \n",
      "86             on    IN      0     0   2.0     1.0   2.0    0.0     1.0   \n",
      "87      horseback    NN      0     0   2.0     1.0   2.0    0.0     0.0   \n",
      "88             to    TO      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "89           tell    VB      0     0   1.0     0.0   1.0    0.0     1.0   \n",
      "90            him   PRP      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "91           that    IN      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "92            his  PRP$      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "93           wife    NN      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "94            was   VBD      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "95        gravely    RB      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "96            ill    JJ      0     0   1.0     0.0   1.0    0.0     1.0   \n",
      "97           back    RB      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "98             at    IN      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "99            his  PRP$      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "100          home    NN      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "101            in    IN      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "102  Connecticut.   NNP      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "103           The    DT      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "104       message    NN      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "105           had   VBD      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "106         taken   VBN      0     0   2.0     1.0   4.0    1.0     1.0   \n",
      "107       several    JJ      0     0   2.0     1.0   2.0    0.0     0.0   \n",
      "108          days   NNS      0     0   1.0     0.0   1.0    0.0     1.0   \n",
      "109            to    TO      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "110         reach    VB      0     0   2.0     1.0   2.0    0.0     0.0   \n",
      "111           him   PRP      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "112       because    IN      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "113            of    IN      0     0   1.0     0.0   1.0    0.0     1.0   \n",
      "114           the    DT      0     0   1.0     0.0   1.0    0.0     1.0   \n",
      "115     distance.    NN      0     0   2.0     1.0   2.0    0.0     0.0   \n",
      "116         Morse   NNP      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "117        rushed   VBD      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "118            to    TO      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "119           his  PRP$      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "120          home    NN      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "121            as    RB      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "122          fast    RB      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "123            as    IN      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "124            he   PRP      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "125        could,    MD      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "126           but    CC      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "127           his  PRP$      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "128          wife    NN      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "129           had   VBD      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "130       already    RB      0     0   1.0     0.0   1.0    0.0     1.0   \n",
      "131        passed   VBN      0     0   2.0     1.0   2.0    0.0     0.0   \n",
      "132          away    RB      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "133            by    IN      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "134           the    DT      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "135          time    NN      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "136            he   PRP      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "137      arrived.   VBD      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "138        Grief-    JJ      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "139     stricken,    JJ      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "140            he   PRP      0     0   2.0     1.0   2.0    0.0     1.0   \n",
      "141          gave   VBD      0     0   2.0     1.0   2.0    0.0     0.0   \n",
      "142            up    RP      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "143      painting    NN      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "144           and    CC      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "145       devoted   VBD      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "146           the    DT      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "147          rest    NN      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "148            of    IN      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "149           his  PRP$      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "150          life    NN      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "151            to    TO      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "152       finding   VBG      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "153          ways   NNS      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "154            to    TO      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "155      transmit    VB      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "156      messages   NNS      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "157          over    IN      0     1   NaN     NaN   NaN    NaN     NaN   \n",
      "158          long    JJ      0     0   1.0     0.0   1.0    0.0     0.0   \n",
      "159     distances   NNS      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "160       faster.   RBR      0     0   1.0     0.0   2.0    1.0     0.0   \n",
      "\n",
      "     reg.out    dur  firstrun.skip  firstrun.nfix  firstrun.refix   \n",
      "0        0.0  312.0              0            1.0             0.0  \\\n",
      "1        1.0  408.0              1            3.0             1.0   \n",
      "2        1.0   96.0              0            1.0             0.0   \n",
      "3        0.0  216.0              0            1.0             0.0   \n",
      "4        0.0  164.0              0            1.0             0.0   \n",
      "5        0.0  350.0              0            1.0             0.0   \n",
      "6        NaN    NaN              1            NaN             NaN   \n",
      "7        0.0  219.0              0            1.0             0.0   \n",
      "8        0.0  154.0              0            1.0             0.0   \n",
      "9        0.0  349.0              0            1.0             0.0   \n",
      "10       0.0  174.0              0            1.0             0.0   \n",
      "11       NaN    NaN              1            NaN             NaN   \n",
      "12       0.0  347.0              1            2.0             1.0   \n",
      "13       0.0  155.0              1            1.0             0.0   \n",
      "14       1.0  128.0              0            1.0             0.0   \n",
      "15       0.0  205.0              0            1.0             0.0   \n",
      "16       NaN    NaN              1            NaN             NaN   \n",
      "17       0.0  143.0              1            1.0             0.0   \n",
      "18       1.0  373.0              0            1.0             0.0   \n",
      "19       NaN    NaN              1            NaN             NaN   \n",
      "20       0.0  511.0              0            3.0             1.0   \n",
      "21       NaN    NaN              1            NaN             NaN   \n",
      "22       0.0  361.0              0            2.0             1.0   \n",
      "23       0.0  417.0              0            2.0             1.0   \n",
      "24       0.0  273.0              0            1.0             0.0   \n",
      "25       NaN    NaN              1            NaN             NaN   \n",
      "26       0.0  173.0              0            1.0             0.0   \n",
      "27       0.0  229.0              0            1.0             0.0   \n",
      "28       0.0  225.0              0            1.0             0.0   \n",
      "29       NaN    NaN              1            NaN             NaN   \n",
      "30       0.0  340.0              0            2.0             1.0   \n",
      "31       NaN    NaN              1            NaN             NaN   \n",
      "32       0.0  356.0              0            2.0             1.0   \n",
      "33       0.0  229.0              0            1.0             0.0   \n",
      "34       0.0  358.0              0            2.0             1.0   \n",
      "35       NaN    NaN              1            NaN             NaN   \n",
      "36       0.0  351.0              0            1.0             0.0   \n",
      "37       0.0  484.0              0            1.0             0.0   \n",
      "38       0.0  187.0              0            1.0             0.0   \n",
      "39       NaN    NaN              1            NaN             NaN   \n",
      "40       0.0  159.0              0            1.0             0.0   \n",
      "41       NaN    NaN              1            NaN             NaN   \n",
      "42       0.0  200.0              1            1.0             0.0   \n",
      "43       1.0  155.0              0            1.0             0.0   \n",
      "44       0.0  217.0              0            1.0             0.0   \n",
      "45       0.0  343.0              0            2.0             1.0   \n",
      "46       NaN    NaN              1            NaN             NaN   \n",
      "47       NaN    NaN              1            NaN             NaN   \n",
      "48       NaN    NaN              1            NaN             NaN   \n",
      "49       0.0  350.0              0            1.0             0.0   \n",
      "50       NaN    NaN              1            NaN             NaN   \n",
      "51       0.0  462.0              0            2.0             1.0   \n",
      "52       0.0   96.0              0            1.0             0.0   \n",
      "53       0.0  217.0              1            1.0             0.0   \n",
      "54       1.0  120.0              0            1.0             0.0   \n",
      "55       NaN    NaN              1            NaN             NaN   \n",
      "56       0.0  238.0              0            1.0             0.0   \n",
      "57       NaN    NaN              1            NaN             NaN   \n",
      "58       0.0  279.0              0            1.0             0.0   \n",
      "59       0.0  313.0              0            2.0             1.0   \n",
      "60       NaN    NaN              1            NaN             NaN   \n",
      "61       0.0  219.0              0            1.0             0.0   \n",
      "62       NaN    NaN              1            NaN             NaN   \n",
      "63       0.0  135.0              1            1.0             0.0   \n",
      "64       1.0  304.0              0            1.0             0.0   \n",
      "65       NaN    NaN              1            NaN             NaN   \n",
      "66       0.0  208.0              0            1.0             0.0   \n",
      "67       0.0  140.0              0            1.0             0.0   \n",
      "68       NaN    NaN              1            NaN             NaN   \n",
      "69       0.0  551.0              0            2.0             1.0   \n",
      "70       NaN    NaN              1            NaN             NaN   \n",
      "71       NaN    NaN              1            NaN             NaN   \n",
      "72       0.0  355.0              0            2.0             1.0   \n",
      "73       NaN    NaN              1            NaN             NaN   \n",
      "74       0.0  385.0              0            2.0             1.0   \n",
      "75       NaN    NaN              1            NaN             NaN   \n",
      "76       0.0  243.0              0            1.0             0.0   \n",
      "77       NaN    NaN              1            NaN             NaN   \n",
      "78       NaN    NaN              1            NaN             NaN   \n",
      "79       0.0  366.0              0            2.0             1.0   \n",
      "80       NaN    NaN              1            NaN             NaN   \n",
      "81       0.0  387.0              0            2.0             1.0   \n",
      "82       0.0  252.0              1            1.0             0.0   \n",
      "83       NaN    NaN              1            NaN             NaN   \n",
      "84       0.0  877.0              0            2.0             1.0   \n",
      "85       1.0  675.0              1            2.0             0.0   \n",
      "86       1.0  361.0              1            1.0             0.0   \n",
      "87       1.0  318.0              0            1.0             0.0   \n",
      "88       NaN    NaN              1            NaN             NaN   \n",
      "89       0.0  238.0              1            1.0             0.0   \n",
      "90       NaN    NaN              1            NaN             NaN   \n",
      "91       1.0  118.0              0            1.0             0.0   \n",
      "92       0.0  171.0              0            1.0             0.0   \n",
      "93       NaN    NaN              1            NaN             NaN   \n",
      "94       0.0  145.0              0            1.0             0.0   \n",
      "95       0.0  227.0              0            1.0             0.0   \n",
      "96       0.0  189.0              1            1.0             0.0   \n",
      "97       0.0  165.0              1            1.0             0.0   \n",
      "98       NaN    NaN              1            NaN             NaN   \n",
      "99       1.0  144.0              0            1.0             0.0   \n",
      "100      0.0  170.0              0            1.0             0.0   \n",
      "101      NaN    NaN              1            NaN             NaN   \n",
      "102      0.0  476.0              0            2.0             1.0   \n",
      "103      NaN    NaN              1            NaN             NaN   \n",
      "104      0.0  262.0              0            1.0             0.0   \n",
      "105      NaN    NaN              1            NaN             NaN   \n",
      "106      0.0  722.0              0            2.0             1.0   \n",
      "107      1.0  559.0              0            1.0             0.0   \n",
      "108      0.0  344.0              1            1.0             0.0   \n",
      "109      NaN    NaN              1            NaN             NaN   \n",
      "110      1.0  505.0              0            1.0             0.0   \n",
      "111      NaN    NaN              1            NaN             NaN   \n",
      "112      0.0  251.0              0            1.0             0.0   \n",
      "113      0.0  180.0              1            1.0             0.0   \n",
      "114      1.0  119.0              1            1.0             0.0   \n",
      "115      1.0  368.0              0            1.0             0.0   \n",
      "116      0.0  435.0              0            2.0             1.0   \n",
      "117      0.0  608.0              0            2.0             1.0   \n",
      "118      NaN    NaN              1            NaN             NaN   \n",
      "119      0.0  325.0              0            1.0             0.0   \n",
      "120      NaN    NaN              1            NaN             NaN   \n",
      "121      0.0  170.0              0            1.0             0.0   \n",
      "122      NaN    NaN              1            NaN             NaN   \n",
      "123      NaN    NaN              1            NaN             NaN   \n",
      "124      0.0  289.0              0            1.0             0.0   \n",
      "125      NaN    NaN              1            NaN             NaN   \n",
      "126      NaN    NaN              1            NaN             NaN   \n",
      "127      0.0  383.0              0            1.0             0.0   \n",
      "128      NaN    NaN              1            NaN             NaN   \n",
      "129      0.0  152.0              0            1.0             0.0   \n",
      "130      0.0  177.0              1            1.0             0.0   \n",
      "131      1.0  373.0              0            1.0             0.0   \n",
      "132      NaN    NaN              1            NaN             NaN   \n",
      "133      NaN    NaN              1            NaN             NaN   \n",
      "134      0.0  199.0              0            1.0             0.0   \n",
      "135      0.0  251.0              0            1.0             0.0   \n",
      "136      NaN    NaN              1            NaN             NaN   \n",
      "137      0.0  166.0              0            1.0             0.0   \n",
      "138      0.0  343.0              0            2.0             1.0   \n",
      "139      0.0  448.0              0            2.0             1.0   \n",
      "140      0.0  464.0              1            1.0             0.0   \n",
      "141      1.0  480.0              0            1.0             0.0   \n",
      "142      0.0  155.0              0            1.0             0.0   \n",
      "143      0.0  323.0              0            1.0             0.0   \n",
      "144      NaN    NaN              1            NaN             NaN   \n",
      "145      0.0  462.0              0            2.0             1.0   \n",
      "146      0.0  183.0              0            1.0             0.0   \n",
      "147      0.0   86.0              0            1.0             0.0   \n",
      "148      NaN    NaN              1            NaN             NaN   \n",
      "149      NaN    NaN              1            NaN             NaN   \n",
      "150      0.0  288.0              0            2.0             1.0   \n",
      "151      NaN    NaN              1            NaN             NaN   \n",
      "152      0.0  269.0              0            1.0             0.0   \n",
      "153      NaN    NaN              1            NaN             NaN   \n",
      "154      0.0  174.0              0            1.0             0.0   \n",
      "155      0.0  334.0              0            1.0             0.0   \n",
      "156      0.0  258.0              0            1.0             0.0   \n",
      "157      NaN    NaN              1            NaN             NaN   \n",
      "158      0.0  243.0              0            1.0             0.0   \n",
      "159      0.0  348.0              0            2.0             1.0   \n",
      "160      0.0  628.0              0            2.0             1.0   \n",
      "\n",
      "     firstrun.reg.in  firstrun.reg.out  firstrun.dur  firstrun.gopast   \n",
      "0                0.0               0.0          48.0             48.0  \\\n",
      "1                1.0               1.0         408.0              0.0   \n",
      "2                0.0               1.0          96.0            768.0   \n",
      "3                0.0               0.0         216.0            216.0   \n",
      "4                0.0               0.0         164.0            164.0   \n",
      "5                0.0               0.0         350.0            350.0   \n",
      "6                NaN               NaN           NaN              NaN   \n",
      "7                0.0               0.0         219.0            219.0   \n",
      "8                0.0               0.0         154.0            154.0   \n",
      "9                0.0               0.0         349.0            349.0   \n",
      "10               0.0               0.0         174.0            174.0   \n",
      "11               NaN               NaN           NaN              NaN   \n",
      "12               1.0               0.0         347.0              0.0   \n",
      "13               0.0               0.0         155.0              0.0   \n",
      "14               0.0               1.0         128.0            630.0   \n",
      "15               0.0               0.0         205.0            205.0   \n",
      "16               NaN               NaN           NaN              NaN   \n",
      "17               1.0               0.0         143.0              0.0   \n",
      "18               0.0               1.0         199.0            516.0   \n",
      "19               NaN               NaN           NaN              NaN   \n",
      "20               0.0               0.0         511.0            511.0   \n",
      "21               NaN               NaN           NaN              NaN   \n",
      "22               0.0               0.0         361.0            361.0   \n",
      "23               0.0               0.0         417.0            417.0   \n",
      "24               0.0               0.0         273.0            273.0   \n",
      "25               NaN               NaN           NaN              NaN   \n",
      "26               0.0               0.0         173.0            173.0   \n",
      "27               0.0               0.0         229.0            229.0   \n",
      "28               0.0               0.0         225.0            225.0   \n",
      "29               NaN               NaN           NaN              NaN   \n",
      "30               0.0               0.0         340.0            340.0   \n",
      "31               NaN               NaN           NaN              NaN   \n",
      "32               0.0               0.0         356.0            356.0   \n",
      "33               0.0               0.0         229.0            229.0   \n",
      "34               0.0               0.0         358.0            358.0   \n",
      "35               NaN               NaN           NaN              NaN   \n",
      "36               0.0               0.0         351.0            351.0   \n",
      "37               0.0               0.0         484.0            484.0   \n",
      "38               0.0               0.0         187.0            187.0   \n",
      "39               NaN               NaN           NaN              NaN   \n",
      "40               0.0               0.0         159.0            159.0   \n",
      "41               NaN               NaN           NaN              NaN   \n",
      "42               1.0               0.0         200.0              0.0   \n",
      "43               0.0               1.0         155.0            355.0   \n",
      "44               0.0               0.0         217.0            217.0   \n",
      "45               0.0               0.0         343.0            343.0   \n",
      "46               NaN               NaN           NaN              NaN   \n",
      "47               NaN               NaN           NaN              NaN   \n",
      "48               NaN               NaN           NaN              NaN   \n",
      "49               0.0               0.0         350.0            350.0   \n",
      "50               NaN               NaN           NaN              NaN   \n",
      "51               0.0               0.0         462.0            462.0   \n",
      "52               0.0               0.0          96.0             96.0   \n",
      "53               1.0               0.0         217.0              0.0   \n",
      "54               0.0               1.0         120.0            337.0   \n",
      "55               NaN               NaN           NaN              NaN   \n",
      "56               0.0               0.0         238.0            238.0   \n",
      "57               NaN               NaN           NaN              NaN   \n",
      "58               0.0               0.0         279.0            279.0   \n",
      "59               0.0               0.0         313.0            313.0   \n",
      "60               NaN               NaN           NaN              NaN   \n",
      "61               0.0               0.0         219.0            219.0   \n",
      "62               NaN               NaN           NaN              NaN   \n",
      "63               1.0               0.0         135.0              0.0   \n",
      "64               0.0               1.0         168.0            439.0   \n",
      "65               NaN               NaN           NaN              NaN   \n",
      "66               0.0               0.0         208.0            208.0   \n",
      "67               0.0               0.0         140.0            140.0   \n",
      "68               NaN               NaN           NaN              NaN   \n",
      "69               0.0               0.0         551.0            551.0   \n",
      "70               NaN               NaN           NaN              NaN   \n",
      "71               NaN               NaN           NaN              NaN   \n",
      "72               0.0               0.0         355.0            355.0   \n",
      "73               NaN               NaN           NaN              NaN   \n",
      "74               0.0               0.0         385.0            385.0   \n",
      "75               NaN               NaN           NaN              NaN   \n",
      "76               0.0               0.0         243.0            243.0   \n",
      "77               NaN               NaN           NaN              NaN   \n",
      "78               NaN               NaN           NaN              NaN   \n",
      "79               0.0               0.0         366.0            366.0   \n",
      "80               NaN               NaN           NaN              NaN   \n",
      "81               0.0               0.0         387.0            387.0   \n",
      "82               1.0               0.0         252.0              0.0   \n",
      "83               NaN               NaN           NaN              NaN   \n",
      "84               0.0               0.0         379.0            379.0   \n",
      "85               1.0               1.0         539.0              0.0   \n",
      "86               1.0               1.0         161.0              0.0   \n",
      "87               0.0               1.0         163.0           2104.0   \n",
      "88               NaN               NaN           NaN              NaN   \n",
      "89               1.0               0.0         238.0              0.0   \n",
      "90               NaN               NaN           NaN              NaN   \n",
      "91               0.0               1.0         118.0            356.0   \n",
      "92               0.0               0.0         171.0            171.0   \n",
      "93               NaN               NaN           NaN              NaN   \n",
      "94               0.0               0.0         145.0            145.0   \n",
      "95               0.0               0.0         227.0            227.0   \n",
      "96               1.0               0.0         189.0              0.0   \n",
      "97               0.0               0.0         165.0              0.0   \n",
      "98               NaN               NaN           NaN              NaN   \n",
      "99               0.0               1.0         144.0            498.0   \n",
      "100              0.0               0.0         170.0            170.0   \n",
      "101              NaN               NaN           NaN              NaN   \n",
      "102              0.0               0.0         476.0            476.0   \n",
      "103              NaN               NaN           NaN              NaN   \n",
      "104              0.0               0.0         262.0            262.0   \n",
      "105              NaN               NaN           NaN              NaN   \n",
      "106              0.0               0.0         411.0            411.0   \n",
      "107              0.0               1.0         404.0            870.0   \n",
      "108              1.0               0.0         344.0              0.0   \n",
      "109              NaN               NaN           NaN              NaN   \n",
      "110              0.0               1.0         124.0            849.0   \n",
      "111              NaN               NaN           NaN              NaN   \n",
      "112              0.0               0.0         251.0            251.0   \n",
      "113              1.0               0.0         180.0              0.0   \n",
      "114              1.0               1.0         119.0              0.0   \n",
      "115              0.0               1.0         158.0            667.0   \n",
      "116              0.0               0.0         435.0            435.0   \n",
      "117              0.0               0.0         608.0            608.0   \n",
      "118              NaN               NaN           NaN              NaN   \n",
      "119              0.0               0.0         325.0            325.0   \n",
      "120              NaN               NaN           NaN              NaN   \n",
      "121              0.0               0.0         170.0            170.0   \n",
      "122              NaN               NaN           NaN              NaN   \n",
      "123              NaN               NaN           NaN              NaN   \n",
      "124              0.0               0.0         289.0            289.0   \n",
      "125              NaN               NaN           NaN              NaN   \n",
      "126              NaN               NaN           NaN              NaN   \n",
      "127              0.0               0.0         383.0            383.0   \n",
      "128              NaN               NaN           NaN              NaN   \n",
      "129              0.0               0.0         152.0            152.0   \n",
      "130              1.0               0.0         177.0              0.0   \n",
      "131              0.0               1.0         146.0            550.0   \n",
      "132              NaN               NaN           NaN              NaN   \n",
      "133              NaN               NaN           NaN              NaN   \n",
      "134              0.0               0.0         199.0            199.0   \n",
      "135              0.0               0.0         251.0            251.0   \n",
      "136              NaN               NaN           NaN              NaN   \n",
      "137              0.0               0.0         166.0            166.0   \n",
      "138              0.0               0.0         343.0            343.0   \n",
      "139              0.0               0.0         448.0            448.0   \n",
      "140              1.0               0.0         278.0              0.0   \n",
      "141              0.0               1.0         164.0            944.0   \n",
      "142              0.0               0.0         155.0            155.0   \n",
      "143              0.0               0.0         323.0            323.0   \n",
      "144              NaN               NaN           NaN              NaN   \n",
      "145              0.0               0.0         462.0            462.0   \n",
      "146              0.0               0.0         183.0            183.0   \n",
      "147              0.0               0.0          86.0             86.0   \n",
      "148              NaN               NaN           NaN              NaN   \n",
      "149              NaN               NaN           NaN              NaN   \n",
      "150              0.0               0.0         288.0            288.0   \n",
      "151              NaN               NaN           NaN              NaN   \n",
      "152              0.0               0.0         269.0            269.0   \n",
      "153              NaN               NaN           NaN              NaN   \n",
      "154              0.0               0.0         174.0            174.0   \n",
      "155              0.0               0.0         334.0            334.0   \n",
      "156              0.0               0.0         258.0            258.0   \n",
      "157              NaN               NaN           NaN              NaN   \n",
      "158              0.0               0.0         243.0            243.0   \n",
      "159              0.0               0.0         348.0            348.0   \n",
      "160              0.0               0.0         628.0            628.0   \n",
      "\n",
      "     firstrun.gopast.sel  firstfix.sac.in  firstfix.sac.out  firstfix.launch   \n",
      "0                   48.0              NaN              16.0              NaN  \\\n",
      "1                    0.0             -7.0              -5.0            -10.0   \n",
      "2                   96.0             16.0              -7.0             13.0   \n",
      "3                  216.0              8.0               6.0              7.0   \n",
      "4                  164.0              6.0               5.0              5.0   \n",
      "5                  350.0              5.0               9.0              4.0   \n",
      "6                    NaN              NaN               NaN              NaN   \n",
      "7                  219.0              9.0               7.0              7.0   \n",
      "8                  154.0              7.0               7.0              7.0   \n",
      "9                  349.0              7.0               5.0              3.0   \n",
      "10                 174.0              5.0              14.0              2.0   \n",
      "11                   NaN              NaN               NaN              NaN   \n",
      "12                   0.0             -5.0              -2.0             -8.0   \n",
      "13                   0.0              4.0              10.0              3.0   \n",
      "14                 128.0             14.0              -5.0             13.0   \n",
      "15                 205.0             10.0              15.0              6.0   \n",
      "16                   NaN              NaN               NaN              NaN   \n",
      "17                   0.0             -3.0               8.0             -6.0   \n",
      "18                 373.0             15.0              -3.0             13.0   \n",
      "19                   NaN              NaN               NaN              NaN   \n",
      "20                 511.0            -90.0              -6.0            -96.0   \n",
      "21                   NaN              NaN               NaN              NaN   \n",
      "22                 361.0              9.0              -1.0              5.0   \n",
      "23                 417.0             11.0              -1.0              7.0   \n",
      "24                 273.0             10.0               6.0              6.0   \n",
      "25                   NaN              NaN               NaN              NaN   \n",
      "26                 173.0              6.0               7.0              5.0   \n",
      "27                 229.0              7.0               7.0              3.0   \n",
      "28                 225.0              7.0              15.0              3.0   \n",
      "29                   NaN              NaN               NaN              NaN   \n",
      "30                 340.0             15.0              -1.0             10.0   \n",
      "31                   NaN              NaN               NaN              NaN   \n",
      "32                 356.0             17.0              -2.0             11.0   \n",
      "33                 229.0              9.0             -92.0              4.0   \n",
      "34                 358.0            -92.0              -2.0            -97.0   \n",
      "35                   NaN              NaN               NaN              NaN   \n",
      "36                 351.0             14.0              11.0             11.0   \n",
      "37                 484.0             11.0               5.0              6.0   \n",
      "38                 187.0              5.0               6.0              1.0   \n",
      "39                   NaN              NaN               NaN              NaN   \n",
      "40                 159.0              6.0              13.0              4.0   \n",
      "41                   NaN              NaN               NaN              NaN   \n",
      "42                   0.0             -3.0              11.0             -6.0   \n",
      "43                 155.0             13.0              -3.0             13.0   \n",
      "44                 217.0             11.0               4.0              8.0   \n",
      "45                 343.0              4.0               6.0              4.0   \n",
      "46                   NaN              NaN               NaN              NaN   \n",
      "47                   NaN              NaN               NaN              NaN   \n",
      "48                   NaN              NaN               NaN              NaN   \n",
      "49                 350.0             15.0               8.0             10.0   \n",
      "50                   NaN              NaN               NaN              NaN   \n",
      "51                 462.0              8.0               6.0              8.0   \n",
      "52                  96.0              3.0             -92.0              2.0   \n",
      "53                   0.0             -7.0              17.0            -10.0   \n",
      "54                 120.0            -92.0              -7.0            -94.0   \n",
      "55                   NaN              NaN               NaN              NaN   \n",
      "56                 238.0             17.0               7.0             14.0   \n",
      "57                   NaN              NaN               NaN              NaN   \n",
      "58                 279.0              7.0              15.0              5.0   \n",
      "59                 313.0             15.0              -4.0              7.0   \n",
      "60                   NaN              NaN               NaN              NaN   \n",
      "61                 219.0             13.0              18.0              8.0   \n",
      "62                   NaN              NaN               NaN              NaN   \n",
      "63                   0.0             -5.0               7.0            -11.0   \n",
      "64                 304.0             18.0              -5.0             14.0   \n",
      "65                   NaN              NaN               NaN              NaN   \n",
      "66                 208.0             10.0               7.0              9.0   \n",
      "67                 140.0              7.0               8.0              6.0   \n",
      "68                   NaN              NaN               NaN              NaN   \n",
      "69                 551.0              8.0               5.0              8.0   \n",
      "70                   NaN              NaN               NaN              NaN   \n",
      "71                   NaN              NaN               NaN              NaN   \n",
      "72                 355.0            -91.0              -6.0            -99.0   \n",
      "73                   NaN              NaN               NaN              NaN   \n",
      "74                 385.0             16.0               7.0             16.0   \n",
      "75                   NaN              NaN               NaN              NaN   \n",
      "76                 243.0              9.0              13.0              4.0   \n",
      "77                   NaN              NaN               NaN              NaN   \n",
      "78                   NaN              NaN               NaN              NaN   \n",
      "79                 366.0             13.0               3.0             11.0   \n",
      "80                   NaN              NaN               NaN              NaN   \n",
      "81                 387.0             11.0              -1.0              6.0   \n",
      "82                   0.0            -20.0               5.0            -22.0   \n",
      "83                   NaN              NaN               NaN              NaN   \n",
      "84                 379.0             14.0               5.0             13.0   \n",
      "85                   0.0             -7.0             -11.0            -10.0   \n",
      "86                   0.0             -4.0              -7.0             -6.0   \n",
      "87                 318.0             18.0              -4.0             15.0   \n",
      "88                   NaN              NaN               NaN              NaN   \n",
      "89                   0.0            -11.0              16.0            -12.0   \n",
      "90                   NaN              NaN               NaN              NaN   \n",
      "91                 118.0            -87.0             -11.0            -90.0   \n",
      "92                 171.0             16.0               7.0             13.0   \n",
      "93                   NaN              NaN               NaN              NaN   \n",
      "94                 145.0              7.0               8.0              6.0   \n",
      "95                 227.0              8.0              17.0              3.0   \n",
      "96                   0.0            -12.0               6.0            -14.0   \n",
      "97                   0.0              6.0               9.0              2.0   \n",
      "98                   NaN              NaN               NaN              NaN   \n",
      "99                 144.0             17.0             -12.0             15.0   \n",
      "100                170.0              9.0              13.0              8.0   \n",
      "101                  NaN              NaN               NaN              NaN   \n",
      "102                476.0             13.0              -2.0              7.0   \n",
      "103                  NaN              NaN               NaN              NaN   \n",
      "104                262.0             17.0               9.0             13.0   \n",
      "105                  NaN              NaN               NaN              NaN   \n",
      "106                411.0              9.0               3.0              8.0   \n",
      "107                559.0              6.0              -9.0              2.0   \n",
      "108                  0.0             -8.0               7.0            -10.0   \n",
      "109                  NaN              NaN               NaN              NaN   \n",
      "110                505.0            -91.0              -8.0            -94.0   \n",
      "111                  NaN              NaN               NaN              NaN   \n",
      "112                251.0              8.0              17.0              8.0   \n",
      "113                  0.0             -4.0               8.0             -6.0   \n",
      "114                  0.0             -3.0              -4.0             -6.0   \n",
      "115                368.0             17.0              -3.0             15.0   \n",
      "116                435.0             12.0              -2.0              7.0   \n",
      "117                608.0              3.0               3.0              3.0   \n",
      "118                  NaN              NaN               NaN              NaN   \n",
      "119                325.0              9.0               7.0              7.0   \n",
      "120                  NaN              NaN               NaN              NaN   \n",
      "121                170.0              7.0              11.0              3.0   \n",
      "122                  NaN              NaN               NaN              NaN   \n",
      "123                  NaN              NaN               NaN              NaN   \n",
      "124                289.0             11.0              16.0             11.0   \n",
      "125                  NaN              NaN               NaN              NaN   \n",
      "126                  NaN              NaN               NaN              NaN   \n",
      "127                383.0             16.0               8.0             14.0   \n",
      "128                  NaN              NaN               NaN              NaN   \n",
      "129                152.0              8.0             -95.0              7.0   \n",
      "130                  0.0             -5.0               9.0             -8.0   \n",
      "131                373.0            -95.0              -5.0            -95.0   \n",
      "132                  NaN              NaN               NaN              NaN   \n",
      "133                  NaN              NaN               NaN              NaN   \n",
      "134                199.0             11.0               7.0             11.0   \n",
      "135                251.0              7.0               6.0              4.0   \n",
      "136                  NaN              NaN               NaN              NaN   \n",
      "137                166.0              6.0              14.0              5.0   \n",
      "138                343.0             14.0              -4.0              8.0   \n",
      "139                448.0              5.0               3.0              5.0   \n",
      "140                  0.0             -3.0               3.0             -5.0   \n",
      "141                480.0             11.0              -3.0              9.0   \n",
      "142                155.0              6.0               6.0              6.0   \n",
      "143                323.0              6.0              10.0              3.0   \n",
      "144                  NaN              NaN               NaN              NaN   \n",
      "145                462.0             10.0               5.0             10.0   \n",
      "146                183.0              6.0               4.0              3.0   \n",
      "147                 86.0              4.0             -91.0              1.0   \n",
      "148                  NaN              NaN               NaN              NaN   \n",
      "149                  NaN              NaN               NaN              NaN   \n",
      "150                288.0            -91.0              -4.0            -95.0   \n",
      "151                  NaN              NaN               NaN              NaN   \n",
      "152                269.0              9.0              12.0              8.0   \n",
      "153                  NaN              NaN               NaN              NaN   \n",
      "154                174.0             12.0               8.0             12.0   \n",
      "155                334.0              8.0               9.0              3.0   \n",
      "156                258.0              9.0               9.0              4.0   \n",
      "157                  NaN              NaN               NaN              NaN   \n",
      "158                243.0              9.0              11.0              9.0   \n",
      "159                348.0             11.0              -2.0             10.0   \n",
      "160                628.0              9.0              -3.0              6.0   \n",
      "\n",
      "     firstfix.land  firstfix.cland  firstfix.dur  singlefix  singlefix.sac.in   \n",
      "0              0.0            -3.5          48.0          1               NaN  \\\n",
      "1              3.0            -0.5         117.0          0               NaN   \n",
      "2              3.0             0.5          96.0          1              16.0   \n",
      "3              1.0            -2.0         216.0          1               8.0   \n",
      "4              1.0            -2.0         164.0          1               6.0   \n",
      "5              1.0            -0.5         350.0          1               5.0   \n",
      "6              NaN             NaN           NaN          0               NaN   \n",
      "7              2.0            -2.5         219.0          1               9.0   \n",
      "8              0.0            -1.5         154.0          1               7.0   \n",
      "9              4.0             1.0         349.0          1               7.0   \n",
      "10             3.0             0.5         174.0          1               5.0   \n",
      "11             NaN             NaN           NaN          0               NaN   \n",
      "12             3.0             1.0         124.0          0               NaN   \n",
      "13             1.0            -0.5         155.0          1               4.0   \n",
      "14             1.0            -1.0         128.0          1              14.0   \n",
      "15             4.0            -1.0         205.0          1              10.0   \n",
      "16             NaN             NaN           NaN          0               NaN   \n",
      "17             3.0             1.0         143.0          1              -3.0   \n",
      "18             2.0            -3.5         199.0          1              15.0   \n",
      "19             NaN             NaN           NaN          0               NaN   \n",
      "20             6.0             0.5         121.0          0               NaN   \n",
      "21             NaN             NaN           NaN          0               NaN   \n",
      "22             4.0            -1.0         191.0          0               NaN   \n",
      "23             4.0            -0.5         160.0          0               NaN   \n",
      "24             4.0             1.0         273.0          1              10.0   \n",
      "25             NaN             NaN           NaN          0               NaN   \n",
      "26             1.0            -1.0         173.0          1               6.0   \n",
      "27             4.0             0.5         229.0          1               7.0   \n",
      "28             4.0            -1.5         225.0          1               7.0   \n",
      "29             NaN             NaN           NaN          0               NaN   \n",
      "30             5.0            -0.5         179.0          0               NaN   \n",
      "31             NaN             NaN           NaN          0               NaN   \n",
      "32             6.0             2.0         172.0          0               NaN   \n",
      "33             5.0            -0.5         229.0          1               9.0   \n",
      "34             5.0            -1.0         136.0          0               NaN   \n",
      "35             NaN             NaN           NaN          0               NaN   \n",
      "36             3.0            -1.5         351.0          1              14.0   \n",
      "37             5.0             2.0         484.0          1              11.0   \n",
      "38             4.0             1.5         187.0          1               5.0   \n",
      "39             NaN             NaN           NaN          0               NaN   \n",
      "40             2.0            -1.0         159.0          1               6.0   \n",
      "41             NaN             NaN           NaN          0               NaN   \n",
      "42             3.0             0.0         200.0          1              -3.0   \n",
      "43             0.0            -2.5         155.0          1              13.0   \n",
      "44             3.0            -0.5         217.0          1              11.0   \n",
      "45             0.0            -4.0         183.0          0               NaN   \n",
      "46             NaN             NaN           NaN          0               NaN   \n",
      "47             NaN             NaN           NaN          0               NaN   \n",
      "48             NaN             NaN           NaN          0               NaN   \n",
      "49             5.0             3.0         350.0          1              15.0   \n",
      "50             NaN             NaN           NaN          0               NaN   \n",
      "51             0.0            -4.0         229.0          0               NaN   \n",
      "52             1.0            -1.5          96.0          1               3.0   \n",
      "53             3.0            -1.5         217.0          1              -7.0   \n",
      "54             2.0            -0.5         120.0          1             -92.0   \n",
      "55             NaN             NaN           NaN          0               NaN   \n",
      "56             3.0             0.5         238.0          1              17.0   \n",
      "57             NaN             NaN           NaN          0               NaN   \n",
      "58             2.0            -2.5         279.0          1               7.0   \n",
      "59             8.0             3.0         145.0          0               NaN   \n",
      "60             NaN             NaN           NaN          0               NaN   \n",
      "61             5.0             0.5         219.0          1              13.0   \n",
      "62             NaN             NaN           NaN          0               NaN   \n",
      "63             6.0             2.5         135.0          1              -5.0   \n",
      "64             4.0            -1.0         168.0          1              18.0   \n",
      "65             NaN             NaN           NaN          0               NaN   \n",
      "66             1.0            -2.5         208.0          1              10.0   \n",
      "67             1.0            -0.5         140.0          1               7.0   \n",
      "68             NaN             NaN           NaN          0               NaN   \n",
      "69             0.0            -3.0         327.0          0               NaN   \n",
      "70             NaN             NaN           NaN          0               NaN   \n",
      "71             NaN             NaN           NaN          0               NaN   \n",
      "72             8.0             2.0         145.0          0               NaN   \n",
      "73             NaN             NaN           NaN          0               NaN   \n",
      "74             0.0            -4.5         151.0          0               NaN   \n",
      "75             NaN             NaN           NaN          0               NaN   \n",
      "76             5.0             0.5         243.0          1               9.0   \n",
      "77             NaN             NaN           NaN          0               NaN   \n",
      "78             NaN             NaN           NaN          0               NaN   \n",
      "79             2.0            -2.0         232.0          0               NaN   \n",
      "80             NaN             NaN           NaN          0               NaN   \n",
      "81             5.0             0.0         214.0          0               NaN   \n",
      "82             2.0            -0.5         252.0          1             -20.0   \n",
      "83             NaN             NaN           NaN          0               NaN   \n",
      "84             1.0            -4.0         186.0          0               NaN   \n",
      "85             3.0            -1.0         147.0          0               NaN   \n",
      "86             2.0             0.5         161.0          1              -4.0   \n",
      "87             3.0            -2.0         163.0          1              18.0   \n",
      "88             NaN             NaN           NaN          0               NaN   \n",
      "89             1.0            -1.5         238.0          1             -11.0   \n",
      "90             NaN             NaN           NaN          0               NaN   \n",
      "91             3.0             0.5         118.0          1             -87.0   \n",
      "92             3.0             1.0         171.0          1              16.0   \n",
      "93             NaN             NaN           NaN          0               NaN   \n",
      "94             1.0            -1.0         145.0          1               7.0   \n",
      "95             5.0             1.0         227.0          1               8.0   \n",
      "96             2.0             0.0         189.0          1             -12.0   \n",
      "97             4.0             1.5         165.0          1               6.0   \n",
      "98             NaN             NaN           NaN          0               NaN   \n",
      "99             2.0             0.0         144.0          1              17.0   \n",
      "100            1.0            -1.5         170.0          1               9.0   \n",
      "101            NaN             NaN           NaN          0               NaN   \n",
      "102            6.0            -0.5         319.0          0               NaN   \n",
      "103            NaN             NaN           NaN          0               NaN   \n",
      "104            4.0             0.0         262.0          1              17.0   \n",
      "105            NaN             NaN           NaN          0               NaN   \n",
      "106            1.0            -2.0         254.0          0               NaN   \n",
      "107            4.0             0.0         404.0          1               6.0   \n",
      "108            2.0            -0.5         344.0          1              -8.0   \n",
      "109            NaN             NaN           NaN          0               NaN   \n",
      "110            3.0             0.0         124.0          1             -91.0   \n",
      "111            NaN             NaN           NaN          0               NaN   \n",
      "112            0.0            -4.0         251.0          1               8.0   \n",
      "113            2.0             0.5         180.0          1              -4.0   \n",
      "114            3.0             1.0         119.0          1              -3.0   \n",
      "115            2.0            -3.0         158.0          1              17.0   \n",
      "116            5.0             2.0         214.0          0               NaN   \n",
      "117            0.0            -3.5         187.0          0               NaN   \n",
      "118            NaN             NaN           NaN          0               NaN   \n",
      "119            2.0             0.0         325.0          1               9.0   \n",
      "120            NaN             NaN           NaN          0               NaN   \n",
      "121            4.0             2.5         170.0          1               7.0   \n",
      "122            NaN             NaN           NaN          0               NaN   \n",
      "123            NaN             NaN           NaN          0               NaN   \n",
      "124            0.0            -1.5         289.0          1              11.0   \n",
      "125            NaN             NaN           NaN          0               NaN   \n",
      "126            NaN             NaN           NaN          0               NaN   \n",
      "127            2.0             0.0         383.0          1              16.0   \n",
      "128            NaN             NaN           NaN          0               NaN   \n",
      "129            1.0            -1.0         152.0          1               8.0   \n",
      "130            3.0            -1.0         177.0          1              -5.0   \n",
      "131            0.0            -3.5         146.0          1             -95.0   \n",
      "132            NaN             NaN           NaN          0               NaN   \n",
      "133            NaN             NaN           NaN          0               NaN   \n",
      "134            0.0            -2.0         199.0          1              11.0   \n",
      "135            3.0             0.5         251.0          1               7.0   \n",
      "136            NaN             NaN           NaN          0               NaN   \n",
      "137            1.0            -3.5         166.0          1               6.0   \n",
      "138            6.0             2.5         146.0          0               NaN   \n",
      "139            0.0            -5.0         222.0          0               NaN   \n",
      "140            2.0             0.5         278.0          1              -3.0   \n",
      "141            2.0            -0.5         164.0          1              11.0   \n",
      "142            0.0            -1.5         155.0          1               6.0   \n",
      "143            3.0            -1.5         323.0          1               6.0   \n",
      "144            NaN             NaN           NaN          0               NaN   \n",
      "145            0.0            -4.0         265.0          0               NaN   \n",
      "146            3.0             1.0         183.0          1               6.0   \n",
      "147            3.0             0.5          86.0          1               4.0   \n",
      "148            NaN             NaN           NaN          0               NaN   \n",
      "149            NaN             NaN           NaN          0               NaN   \n",
      "150            4.0             1.5         116.0          0               NaN   \n",
      "151            NaN             NaN           NaN          0               NaN   \n",
      "152            1.0            -3.0         269.0          1               9.0   \n",
      "153            NaN             NaN           NaN          0               NaN   \n",
      "154            0.0            -1.5         174.0          1              12.0   \n",
      "155            5.0             0.5         334.0          1               8.0   \n",
      "156            5.0             0.5         258.0          1               9.0   \n",
      "157            NaN             NaN           NaN          0               NaN   \n",
      "158            0.0            -2.5         243.0          1               9.0   \n",
      "159            1.0            -4.0         230.0          0               NaN   \n",
      "160            3.0            -1.0         134.0          0               NaN   \n",
      "\n",
      "     singlefix.sac.out  singlefix.launch  singlefix.land  singlefix.cland   \n",
      "0                 16.0               NaN             0.0             -3.5  \\\n",
      "1                  NaN               NaN             NaN              NaN   \n",
      "2                 -7.0              13.0             3.0              0.5   \n",
      "3                  6.0               7.0             1.0             -2.0   \n",
      "4                  5.0               5.0             1.0             -2.0   \n",
      "5                  9.0               4.0             1.0             -0.5   \n",
      "6                  NaN               NaN             NaN              NaN   \n",
      "7                  7.0               7.0             2.0             -2.5   \n",
      "8                  7.0               7.0             0.0             -1.5   \n",
      "9                  5.0               3.0             4.0              1.0   \n",
      "10                14.0               2.0             3.0              0.5   \n",
      "11                 NaN               NaN             NaN              NaN   \n",
      "12                 NaN               NaN             NaN              NaN   \n",
      "13                10.0               3.0             1.0             -0.5   \n",
      "14                -5.0              13.0             1.0             -1.0   \n",
      "15                15.0               6.0             4.0             -1.0   \n",
      "16                 NaN               NaN             NaN              NaN   \n",
      "17                 8.0              -6.0             3.0              1.0   \n",
      "18                -3.0              13.0             2.0             -3.5   \n",
      "19                 NaN               NaN             NaN              NaN   \n",
      "20                 NaN               NaN             NaN              NaN   \n",
      "21                 NaN               NaN             NaN              NaN   \n",
      "22                 NaN               NaN             NaN              NaN   \n",
      "23                 NaN               NaN             NaN              NaN   \n",
      "24                 6.0               6.0             4.0              1.0   \n",
      "25                 NaN               NaN             NaN              NaN   \n",
      "26                 7.0               5.0             1.0             -1.0   \n",
      "27                 7.0               3.0             4.0              0.5   \n",
      "28                15.0               3.0             4.0             -1.5   \n",
      "29                 NaN               NaN             NaN              NaN   \n",
      "30                 NaN               NaN             NaN              NaN   \n",
      "31                 NaN               NaN             NaN              NaN   \n",
      "32                 NaN               NaN             NaN              NaN   \n",
      "33               -92.0               4.0             5.0             -0.5   \n",
      "34                 NaN               NaN             NaN              NaN   \n",
      "35                 NaN               NaN             NaN              NaN   \n",
      "36                11.0              11.0             3.0             -1.5   \n",
      "37                 5.0               6.0             5.0              2.0   \n",
      "38                 6.0               1.0             4.0              1.5   \n",
      "39                 NaN               NaN             NaN              NaN   \n",
      "40                13.0               4.0             2.0             -1.0   \n",
      "41                 NaN               NaN             NaN              NaN   \n",
      "42                11.0              -6.0             3.0              0.0   \n",
      "43                -3.0              13.0             0.0             -2.5   \n",
      "44                 4.0               8.0             3.0             -0.5   \n",
      "45                 NaN               NaN             NaN              NaN   \n",
      "46                 NaN               NaN             NaN              NaN   \n",
      "47                 NaN               NaN             NaN              NaN   \n",
      "48                 NaN               NaN             NaN              NaN   \n",
      "49                 8.0              10.0             5.0              3.0   \n",
      "50                 NaN               NaN             NaN              NaN   \n",
      "51                 NaN               NaN             NaN              NaN   \n",
      "52               -92.0               2.0             1.0             -1.5   \n",
      "53                17.0             -10.0             3.0             -1.5   \n",
      "54                -7.0             -94.0             2.0             -0.5   \n",
      "55                 NaN               NaN             NaN              NaN   \n",
      "56                 7.0              14.0             3.0              0.5   \n",
      "57                 NaN               NaN             NaN              NaN   \n",
      "58                15.0               5.0             2.0             -2.5   \n",
      "59                 NaN               NaN             NaN              NaN   \n",
      "60                 NaN               NaN             NaN              NaN   \n",
      "61                18.0               8.0             5.0              0.5   \n",
      "62                 NaN               NaN             NaN              NaN   \n",
      "63                 7.0             -11.0             6.0              2.5   \n",
      "64                -5.0              14.0             4.0             -1.0   \n",
      "65                 NaN               NaN             NaN              NaN   \n",
      "66                 7.0               9.0             1.0             -2.5   \n",
      "67                 8.0               6.0             1.0             -0.5   \n",
      "68                 NaN               NaN             NaN              NaN   \n",
      "69                 NaN               NaN             NaN              NaN   \n",
      "70                 NaN               NaN             NaN              NaN   \n",
      "71                 NaN               NaN             NaN              NaN   \n",
      "72                 NaN               NaN             NaN              NaN   \n",
      "73                 NaN               NaN             NaN              NaN   \n",
      "74                 NaN               NaN             NaN              NaN   \n",
      "75                 NaN               NaN             NaN              NaN   \n",
      "76                13.0               4.0             5.0              0.5   \n",
      "77                 NaN               NaN             NaN              NaN   \n",
      "78                 NaN               NaN             NaN              NaN   \n",
      "79                 NaN               NaN             NaN              NaN   \n",
      "80                 NaN               NaN             NaN              NaN   \n",
      "81                 NaN               NaN             NaN              NaN   \n",
      "82                 5.0             -22.0             2.0             -0.5   \n",
      "83                 NaN               NaN             NaN              NaN   \n",
      "84                 NaN               NaN             NaN              NaN   \n",
      "85                 NaN               NaN             NaN              NaN   \n",
      "86                -7.0              -6.0             2.0              0.5   \n",
      "87                -4.0              15.0             3.0             -2.0   \n",
      "88                 NaN               NaN             NaN              NaN   \n",
      "89                16.0             -12.0             1.0             -1.5   \n",
      "90                 NaN               NaN             NaN              NaN   \n",
      "91               -11.0             -90.0             3.0              0.5   \n",
      "92                 7.0              13.0             3.0              1.0   \n",
      "93                 NaN               NaN             NaN              NaN   \n",
      "94                 8.0               6.0             1.0             -1.0   \n",
      "95                17.0               3.0             5.0              1.0   \n",
      "96                 6.0             -14.0             2.0              0.0   \n",
      "97                 9.0               2.0             4.0              1.5   \n",
      "98                 NaN               NaN             NaN              NaN   \n",
      "99               -12.0              15.0             2.0              0.0   \n",
      "100               13.0               8.0             1.0             -1.5   \n",
      "101                NaN               NaN             NaN              NaN   \n",
      "102                NaN               NaN             NaN              NaN   \n",
      "103                NaN               NaN             NaN              NaN   \n",
      "104                9.0              13.0             4.0              0.0   \n",
      "105                NaN               NaN             NaN              NaN   \n",
      "106                NaN               NaN             NaN              NaN   \n",
      "107               -9.0               2.0             4.0              0.0   \n",
      "108                7.0             -10.0             2.0             -0.5   \n",
      "109                NaN               NaN             NaN              NaN   \n",
      "110               -8.0             -94.0             3.0              0.0   \n",
      "111                NaN               NaN             NaN              NaN   \n",
      "112               17.0               8.0             0.0             -4.0   \n",
      "113                8.0              -6.0             2.0              0.5   \n",
      "114               -4.0              -6.0             3.0              1.0   \n",
      "115               -3.0              15.0             2.0             -3.0   \n",
      "116                NaN               NaN             NaN              NaN   \n",
      "117                NaN               NaN             NaN              NaN   \n",
      "118                NaN               NaN             NaN              NaN   \n",
      "119                7.0               7.0             2.0              0.0   \n",
      "120                NaN               NaN             NaN              NaN   \n",
      "121               11.0               3.0             4.0              2.5   \n",
      "122                NaN               NaN             NaN              NaN   \n",
      "123                NaN               NaN             NaN              NaN   \n",
      "124               16.0              11.0             0.0             -1.5   \n",
      "125                NaN               NaN             NaN              NaN   \n",
      "126                NaN               NaN             NaN              NaN   \n",
      "127                8.0              14.0             2.0              0.0   \n",
      "128                NaN               NaN             NaN              NaN   \n",
      "129              -95.0               7.0             1.0             -1.0   \n",
      "130                9.0              -8.0             3.0             -1.0   \n",
      "131               -5.0             -95.0             0.0             -3.5   \n",
      "132                NaN               NaN             NaN              NaN   \n",
      "133                NaN               NaN             NaN              NaN   \n",
      "134                7.0              11.0             0.0             -2.0   \n",
      "135                6.0               4.0             3.0              0.5   \n",
      "136                NaN               NaN             NaN              NaN   \n",
      "137               14.0               5.0             1.0             -3.5   \n",
      "138                NaN               NaN             NaN              NaN   \n",
      "139                NaN               NaN             NaN              NaN   \n",
      "140                3.0              -5.0             2.0              0.5   \n",
      "141               -3.0               9.0             2.0             -0.5   \n",
      "142                6.0               6.0             0.0             -1.5   \n",
      "143               10.0               3.0             3.0             -1.5   \n",
      "144                NaN               NaN             NaN              NaN   \n",
      "145                NaN               NaN             NaN              NaN   \n",
      "146                4.0               3.0             3.0              1.0   \n",
      "147              -91.0               1.0             3.0              0.5   \n",
      "148                NaN               NaN             NaN              NaN   \n",
      "149                NaN               NaN             NaN              NaN   \n",
      "150                NaN               NaN             NaN              NaN   \n",
      "151                NaN               NaN             NaN              NaN   \n",
      "152               12.0               8.0             1.0             -3.0   \n",
      "153                NaN               NaN             NaN              NaN   \n",
      "154                8.0              12.0             0.0             -1.5   \n",
      "155                9.0               3.0             5.0              0.5   \n",
      "156                9.0               4.0             5.0              0.5   \n",
      "157                NaN               NaN             NaN              NaN   \n",
      "158               11.0               9.0             0.0             -2.5   \n",
      "159                NaN               NaN             NaN              NaN   \n",
      "160                NaN               NaN             NaN              NaN   \n",
      "\n",
      "     singlefix.dur lang  trial uniform_id  \n",
      "0             48.0   du    NaN       du_4  \n",
      "1              NaN   du    NaN       du_4  \n",
      "2             96.0   du    NaN       du_4  \n",
      "3            216.0   du    NaN       du_4  \n",
      "4            164.0   du    NaN       du_4  \n",
      "5            350.0   du    NaN       du_4  \n",
      "6              NaN   du    NaN       du_4  \n",
      "7            219.0   du    NaN       du_4  \n",
      "8            154.0   du    NaN       du_4  \n",
      "9            349.0   du    NaN       du_4  \n",
      "10           174.0   du    NaN       du_4  \n",
      "11             NaN   du    NaN       du_4  \n",
      "12             NaN   du    NaN       du_4  \n",
      "13           155.0   du    NaN       du_4  \n",
      "14           128.0   du    NaN       du_4  \n",
      "15           205.0   du    NaN       du_4  \n",
      "16             NaN   du    NaN       du_4  \n",
      "17           143.0   du    NaN       du_4  \n",
      "18           199.0   du    NaN       du_4  \n",
      "19             NaN   du    NaN       du_4  \n",
      "20             NaN   du    NaN       du_4  \n",
      "21             NaN   du    NaN       du_4  \n",
      "22             NaN   du    NaN       du_4  \n",
      "23             NaN   du    NaN       du_4  \n",
      "24           273.0   du    NaN       du_4  \n",
      "25             NaN   du    NaN       du_4  \n",
      "26           173.0   du    NaN       du_4  \n",
      "27           229.0   du    NaN       du_4  \n",
      "28           225.0   du    NaN       du_4  \n",
      "29             NaN   du    NaN       du_4  \n",
      "30             NaN   du    NaN       du_4  \n",
      "31             NaN   du    NaN       du_4  \n",
      "32             NaN   du    NaN       du_4  \n",
      "33           229.0   du    NaN       du_4  \n",
      "34             NaN   du    NaN       du_4  \n",
      "35             NaN   du    NaN       du_4  \n",
      "36           351.0   du    NaN       du_4  \n",
      "37           484.0   du    NaN       du_4  \n",
      "38           187.0   du    NaN       du_4  \n",
      "39             NaN   du    NaN       du_4  \n",
      "40           159.0   du    NaN       du_4  \n",
      "41             NaN   du    NaN       du_4  \n",
      "42           200.0   du    NaN       du_4  \n",
      "43           155.0   du    NaN       du_4  \n",
      "44           217.0   du    NaN       du_4  \n",
      "45             NaN   du    NaN       du_4  \n",
      "46             NaN   du    NaN       du_4  \n",
      "47             NaN   du    NaN       du_4  \n",
      "48             NaN   du    NaN       du_4  \n",
      "49           350.0   du    NaN       du_4  \n",
      "50             NaN   du    NaN       du_4  \n",
      "51             NaN   du    NaN       du_4  \n",
      "52            96.0   du    NaN       du_4  \n",
      "53           217.0   du    NaN       du_4  \n",
      "54           120.0   du    NaN       du_4  \n",
      "55             NaN   du    NaN       du_4  \n",
      "56           238.0   du    NaN       du_4  \n",
      "57             NaN   du    NaN       du_4  \n",
      "58           279.0   du    NaN       du_4  \n",
      "59             NaN   du    NaN       du_4  \n",
      "60             NaN   du    NaN       du_4  \n",
      "61           219.0   du    NaN       du_4  \n",
      "62             NaN   du    NaN       du_4  \n",
      "63           135.0   du    NaN       du_4  \n",
      "64           168.0   du    NaN       du_4  \n",
      "65             NaN   du    NaN       du_4  \n",
      "66           208.0   du    NaN       du_4  \n",
      "67           140.0   du    NaN       du_4  \n",
      "68             NaN   du    NaN       du_4  \n",
      "69             NaN   du    NaN       du_4  \n",
      "70             NaN   du    NaN       du_4  \n",
      "71             NaN   du    NaN       du_4  \n",
      "72             NaN   du    NaN       du_4  \n",
      "73             NaN   du    NaN       du_4  \n",
      "74             NaN   du    NaN       du_4  \n",
      "75             NaN   du    NaN       du_4  \n",
      "76           243.0   du    NaN       du_4  \n",
      "77             NaN   du    NaN       du_4  \n",
      "78             NaN   du    NaN       du_4  \n",
      "79             NaN   du    NaN       du_4  \n",
      "80             NaN   du    NaN       du_4  \n",
      "81             NaN   du    NaN       du_4  \n",
      "82           252.0   du    NaN       du_4  \n",
      "83             NaN   du    NaN       du_4  \n",
      "84             NaN   du    NaN       du_4  \n",
      "85             NaN   du    NaN       du_4  \n",
      "86           161.0   du    NaN       du_4  \n",
      "87           163.0   du    NaN       du_4  \n",
      "88             NaN   du    NaN       du_4  \n",
      "89           238.0   du    NaN       du_4  \n",
      "90             NaN   du    NaN       du_4  \n",
      "91           118.0   du    NaN       du_4  \n",
      "92           171.0   du    NaN       du_4  \n",
      "93             NaN   du    NaN       du_4  \n",
      "94           145.0   du    NaN       du_4  \n",
      "95           227.0   du    NaN       du_4  \n",
      "96           189.0   du    NaN       du_4  \n",
      "97           165.0   du    NaN       du_4  \n",
      "98             NaN   du    NaN       du_4  \n",
      "99           144.0   du    NaN       du_4  \n",
      "100          170.0   du    NaN       du_4  \n",
      "101            NaN   du    NaN       du_4  \n",
      "102            NaN   du    NaN       du_4  \n",
      "103            NaN   du    NaN       du_4  \n",
      "104          262.0   du    NaN       du_4  \n",
      "105            NaN   du    NaN       du_4  \n",
      "106            NaN   du    NaN       du_4  \n",
      "107          404.0   du    NaN       du_4  \n",
      "108          344.0   du    NaN       du_4  \n",
      "109            NaN   du    NaN       du_4  \n",
      "110          124.0   du    NaN       du_4  \n",
      "111            NaN   du    NaN       du_4  \n",
      "112          251.0   du    NaN       du_4  \n",
      "113          180.0   du    NaN       du_4  \n",
      "114          119.0   du    NaN       du_4  \n",
      "115          158.0   du    NaN       du_4  \n",
      "116            NaN   du    NaN       du_4  \n",
      "117            NaN   du    NaN       du_4  \n",
      "118            NaN   du    NaN       du_4  \n",
      "119          325.0   du    NaN       du_4  \n",
      "120            NaN   du    NaN       du_4  \n",
      "121          170.0   du    NaN       du_4  \n",
      "122            NaN   du    NaN       du_4  \n",
      "123            NaN   du    NaN       du_4  \n",
      "124          289.0   du    NaN       du_4  \n",
      "125            NaN   du    NaN       du_4  \n",
      "126            NaN   du    NaN       du_4  \n",
      "127          383.0   du    NaN       du_4  \n",
      "128            NaN   du    NaN       du_4  \n",
      "129          152.0   du    NaN       du_4  \n",
      "130          177.0   du    NaN       du_4  \n",
      "131          146.0   du    NaN       du_4  \n",
      "132            NaN   du    NaN       du_4  \n",
      "133            NaN   du    NaN       du_4  \n",
      "134          199.0   du    NaN       du_4  \n",
      "135          251.0   du    NaN       du_4  \n",
      "136            NaN   du    NaN       du_4  \n",
      "137          166.0   du    NaN       du_4  \n",
      "138            NaN   du    NaN       du_4  \n",
      "139            NaN   du    NaN       du_4  \n",
      "140          278.0   du    NaN       du_4  \n",
      "141          164.0   du    NaN       du_4  \n",
      "142          155.0   du    NaN       du_4  \n",
      "143          323.0   du    NaN       du_4  \n",
      "144            NaN   du    NaN       du_4  \n",
      "145            NaN   du    NaN       du_4  \n",
      "146          183.0   du    NaN       du_4  \n",
      "147           86.0   du    NaN       du_4  \n",
      "148            NaN   du    NaN       du_4  \n",
      "149            NaN   du    NaN       du_4  \n",
      "150            NaN   du    NaN       du_4  \n",
      "151            NaN   du    NaN       du_4  \n",
      "152          269.0   du    NaN       du_4  \n",
      "153            NaN   du    NaN       du_4  \n",
      "154          174.0   du    NaN       du_4  \n",
      "155          334.0   du    NaN       du_4  \n",
      "156          258.0   du    NaN       du_4  \n",
      "157            NaN   du    NaN       du_4  \n",
      "158          243.0   du    NaN       du_4  \n",
      "159            NaN   du    NaN       du_4  \n",
      "160            NaN   du    NaN       du_4  \n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efce44fd-d182-4eea-ab8e-f244a5493a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e698b69a-60db-44d6-b152-10f89aa0bbc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
