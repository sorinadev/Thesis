{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deacef26-a87e-4991-8e86-ed31c5c3de75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing neccessary libraries\n",
    "from nltk.tag import DefaultTagger\n",
    "from nltk.corpus import wordnet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad001fb4-8495-4ee8-824e-a91d3a593dbc",
   "metadata": {},
   "source": [
    "## Import the texts in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a61f0b4-3b87-4b47-aaa1-450199193da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samuel Morse, best known today as the inventor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leonardo da Vinci is not only one of the most ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Amazon Rainforest is one of the most impor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Howard Gardner was a psychologist best known f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Internet has made life a whole lot easier ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Many people fail to realize just how crucial g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A bird's feathers are extremely important, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hibernation in animals is an extremely fascina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>At one time, the use of leeches to treat medic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>When online file-sharing programs emerged, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The pencil is a modern-day version of a centur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Technology is rapidly expanding the scope of c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   Samuel Morse, best known today as the inventor...\n",
       "1   Leonardo da Vinci is not only one of the most ...\n",
       "2   The Amazon Rainforest is one of the most impor...\n",
       "3   Howard Gardner was a psychologist best known f...\n",
       "4   The Internet has made life a whole lot easier ...\n",
       "5   Many people fail to realize just how crucial g...\n",
       "6   A bird's feathers are extremely important, and...\n",
       "7   Hibernation in animals is an extremely fascina...\n",
       "8   At one time, the use of leeches to treat medic...\n",
       "9   When online file-sharing programs emerged, the...\n",
       "10  The pencil is a modern-day version of a centur...\n",
       "11  Technology is rapidly expanding the scope of c..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading used texts csv file \n",
    "texts_questions = pd.read_csv(\"texts.csv\")\n",
    "texts = pd.read_csv(\"texts.csv\", usecols = [2])\n",
    "\n",
    "texts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b090b60-76a4-4b9e-9edd-8e7c38088be0",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63b17f2f-a5de-47b6-ac18-7c51acb5cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Edit the texts functions\n",
    "\n",
    "### count the number of words in text\n",
    "def word_count(text):\n",
    "    num_of_words = len(text.split())\n",
    "    return num_of_words\n",
    "\n",
    "### remove the punctuation in text\n",
    "def remove_punct(text):\n",
    "    \n",
    "    # remove the commas\n",
    "    text = text.replace(',', '')\n",
    "    \n",
    "    # remove the punctuation marks\n",
    "    text = text.replace('.', '')\n",
    "    \n",
    "    # remove the colons \n",
    "    text = text.replace(\":\", \"\")\n",
    "    \n",
    "    # remove the semicolons\n",
    "    text = text.replace(\";\", \"\")\n",
    "    \n",
    "    # remove the apostrophe\n",
    "    text = text.replace(\"’\", '')\n",
    "    \n",
    "    # remove the apostrophe\n",
    "    text = text.replace(\"'\", '')\n",
    "    \n",
    "    # remove the beginning quotation mark\n",
    "    text = text.replace(\"“\", '')\n",
    "    \n",
    "    # remove the ending quotation mark\n",
    "    text = text.replace(\"”\", '')\n",
    "    \n",
    "    #split the concatenated words into parts\n",
    "    text = text.replace(\"-\", \"- \")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10f6a9a1-0dcf-492b-af3e-3bb6184ece43",
   "metadata": {},
   "source": [
    "## First text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be574e9f-beb1-4bb6-92b0-3d6ec7918d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 160\n",
      "\n",
      "ORGINAL TEXT: \n",
      " Samuel Morse, best known today as the inventor of Morse Code and one of the inventors of the telegraph, was originally a prominent painter. While he was always interested in technology and studied electrical engineering in college, Morse went to Paris to learn from famous artists of his day and later painted many pictures that now hang in museums, including a portrait of former President John Adams. In 1825, Morse was in Washington, D.C., painting a portrait of the Marquis de Lafayette when a messenger arrived on horseback to tell him that his wife was gravely ill back at his home in Connecticut. The message had taken several days to reach him because of the distance. Morse rushed to his home as fast as he could, but his wife had already passed away by the time he arrived. Grief-stricken, he gave up painting and devoted the rest of his life to finding ways to transmit messages over long distances faster.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " Samuel Morse best known today as the inventor of Morse Code and one of the inventors of the telegraph was originally a prominent painter While he was always interested in technology and studied electrical engineering in college Morse went to Paris to learn from famous artists of his day and later painted many pictures that now hang in museums including a portrait of former President John Adams In 1825 Morse was in Washington DC painting a portrait of the Marquis de Lafayette when a messenger arrived on horseback to tell him that his wife was gravely ill back at his home in Connecticut The message had taken several days to reach him because of the distance Morse rushed to his home as fast as he could but his wife had already passed away by the time he arrived Grief- stricken he gave up painting and devoted the rest of his life to finding ways to transmit messages over long distances faster\n"
     ]
    }
   ],
   "source": [
    "### save the FIRST TEXT out of 12\n",
    "text0 =  texts['text'].iat[0]\n",
    "\n",
    "## remove punctuation from text0:\n",
    "text0_word_count = word_count(text0)\n",
    "text0_remove_punct = remove_punct(text0)\n",
    "print(\"Number of words in this text:\", text0_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text0)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text0_remove_punct)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "706e2b4a-8c5a-44d5-84bd-fd190c1d99b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text0_tokens = nltk.word_tokenize(text0_remove_punct)\n",
    "\n",
    "# print(text0_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a30f54eb-1d7f-4394-b603-a78a53fada2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text0_tagged_tokens = nltk.pos_tag(text0_tokens)\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text0_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe7aed7-60e6-409c-8476-384b520bd20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text0_df_tagged = pd.DataFrame(text0_tagged_tokens, columns=['ia', 'PoS'])\n",
    "\n",
    "## add the text number (itemid) and the word order number(ianum) to the dataframe\n",
    "text0_df_tagged.insert(loc=0, column='ianum', value=np.arange(len(text0_df_tagged))+1)\n",
    "text0_df_tagged.insert(loc=0, column='itemid', value=1)\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "# for Grief-stricken\n",
    "# the adjective has been separated into two word parts: Grief- (NNP) and stricken (NN) and incorrectly tagged as Personal Noun and Noun\n",
    "# change the tags of \"Grief-\" and \"stricken\" to adjective\n",
    "text0_df_tagged.loc[138:139,'PoS'] = \"JJ\"\n",
    "\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(text0_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8fbf601-ffe2-4a54-a3b5-5bb9c65ddd91",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Second text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02e09f14-9832-4194-92df-3e4f21684274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 98\n",
      "\n",
      "ORGINAL TEXT: \n",
      " Leonardo da Vinci is not only one of the most famous artists in history, but he was also a botanist, a writer, and an inventor. Even though most of his inventions were not actually built in his lifetime, many of today’s modern machines can be traced back to some of his original designs. The parachute, the military tank, the bicycle, and even the airplane were foretold in the imaginative drawings that can still be seen in the fragments of da Vinci’s notebooks. Over five hundred years ago, this man conceived ideas that were far ahead of his time.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " Leonardo da Vinci is not only one of the most famous artists in history but he was also a botanist a writer and an inventor Even though most of his inventions were not actually built in his lifetime many of todays modern machines can be traced back to some of his original designs The parachute the military tank the bicycle and even the airplane were foretold in the imaginative drawings that can still be seen in the fragments of da Vincis notebooks Over five hundred years ago this man conceived ideas that were far ahead of his time\n"
     ]
    }
   ],
   "source": [
    "### save the SECOND TEXT out of 12\n",
    "text1 =  texts['text'].iat[1]\n",
    "\n",
    "## remove punctuation from text0:\n",
    "text1_word_count = word_count(text1)\n",
    "text1_remove_punct = remove_punct(text1)\n",
    "print(\"Number of words in this text:\", text1_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text1)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text1_remove_punct)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ec36c1f-eecf-4bef-aa1a-e835abdb0531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text1_tokens = nltk.word_tokenize(text1_remove_punct)\n",
    "\n",
    "# print(text1_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b702428-7ace-4f41-b3dc-fa72884a94db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text1_tagged_tokens = nltk.pos_tag(text1_tokens)\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text1_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd6190bb-06d5-47c8-9bc5-7a8eb1c1e60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text1_df_tagged = pd.DataFrame(text1_tagged_tokens, columns=['ia', 'PoS'])\n",
    "\n",
    "## add the text number (itemid) and the word order number(ianum) to the dataframe\n",
    "text1_df_tagged.insert(loc=0, column='ianum', value=np.arange(len(text1_df_tagged))+1)\n",
    "text1_df_tagged.insert(loc=0, column='itemid', value=2)\n",
    "\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# for today's and Vinci's\n",
    "# \"today's\" is composed of two word parts: today- (NN) and 's (POS) and incorrectly tagged as NN + NN, \n",
    "    # and when written together as \"todays\", the word is incorrectly tagged as noun plural (NNS)\n",
    "# change the tags of \"todays\" to Possesive ending (POS)\n",
    "text1_df_tagged.loc[40,'PoS'] = \"POS\"\n",
    "\n",
    "# \"Vinci's\" is composed of two word parts: Vinci- (NNP) and 's (POS) and incorrectly tagged as NN + VBD (verb past tense), \n",
    "    # and when written together as \"todays\", the word is incorrectly tagged as noun plural (NNS)\n",
    "# change the tags of \"Vincis\" to Possesive ending (POS)\n",
    "text1_df_tagged.loc[80,'PoS'] = \"POS\"\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(text1_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28265c27-89f1-4787-bfda-82992cce9389",
   "metadata": {},
   "source": [
    "## Third text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "487b5a86-5bba-4337-9013-4b60129cb647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 107\n",
      "\n",
      "ORGINAL TEXT: \n",
      " The Amazon Rainforest is one of the most important ecosystems in the world. However, it is slowly being destroyed. Areas of the rainforest are being cleared for farms and roads, and much of the wood is also being harvested and sold. There are several compelling reasons to protect this area. First, a significant number of pharmaceuticals are made from plants that have been discovered in the rainforest, and it's quite possible there are still important plants that have not yet been discovered. Secondly, the rainforest provides a significant portion of the world's oxygen and also absorbs great amounts of carbon dioxide. Without rainforests, global warming could accelerate.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " The Amazon Rainforest is one of the most important ecosystems in the world However it is slowly being destroyed Areas of the rainforest are being cleared for farms and roads and much of the wood is also being harvested and sold There are several compelling reasons to protect this area First a significant number of pharmaceuticals are made from plants that have been discovered in the rainforest and its quite possible there are still important plants that have not yet been discovered Secondly the rainforest provides a significant portion of the worlds oxygen and also absorbs great amounts of carbon dioxide Without rainforests global warming could accelerate\n"
     ]
    }
   ],
   "source": [
    "### save the THIRD TEXT out of 12\n",
    "text2 =  texts['text'].iat[2]\n",
    "\n",
    "## remove punctuation from text2:\n",
    "text2_word_count = word_count(text2)\n",
    "text2_remove_punct = remove_punct(text2)\n",
    "print(\"Number of words in this text:\", text2_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text2)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text2_remove_punct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "641cc0b6-1668-4431-9640-7f8481e63fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text2_tokens = nltk.word_tokenize(text2_remove_punct)\n",
    "\n",
    "# print(text2_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd67a18c-7fc4-4282-b5db-a4b698d3361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text2_tagged_tokens = nltk.pos_tag(text2_tokens)\n",
    "\n",
    "# Print the tagged tokens\n",
    "\n",
    "# print(text2_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38edbafc-e2ae-450b-a912-5151b9f291d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text2_df_tagged = pd.DataFrame(text2_tagged_tokens, columns=['ia', 'PoS'])\n",
    "\n",
    "## add the text number (itemid) and the word order number(ianum) to the dataframe\n",
    "text2_df_tagged.insert(loc=0, column='ianum', value=np.arange(len(text2_df_tagged))+1)\n",
    "text2_df_tagged.insert(loc=0, column='itemid', value=3)\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# for it's and world's\n",
    "# \"it's\" is composed of two word parts: it- (PRP) and 's (VBZ)\n",
    "    # and when written together as \"its\", the word is incorrectly tagged as possessive pronoun  (PRP$)\n",
    "# change the tags of \"its\" to verb, present tense, 3rd person singular (VBZ)\n",
    "text2_df_tagged.loc[68,'PoS'] = \"VBZ\"\n",
    "\n",
    "# \"world's\" is composed of two word parts: world- (NN) and 's (POS)\n",
    "    # and when written together as \"worlds\", the word is incorrectly tagged as noun plural (NNS)\n",
    "# change the tags of \"worlds\" to Possesive ending (POS)\n",
    "text2_df_tagged.loc[91,'PoS'] = \"POS\"\n",
    "\n",
    "# for Areas\n",
    "# \"Areas\" is incorrectly tagged as proper noun (NNP), instead of noun plural (NNS)\n",
    "# change the tags of \"Areas\" to noun plural (NNS)\n",
    "text2_df_tagged.loc[19,'PoS'] = \"NNS\"\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(text2_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6958dda-34fb-4612-83ed-d3646dad80a2",
   "metadata": {},
   "source": [
    "## Fourth text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05d44038-6e69-4373-a772-ee433fb93a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 142\n",
      "\n",
      "ORGINAL TEXT: \n",
      " Howard Gardner was a psychologist best known for developing the theory of multiple intelligences. Basically, the theory states that the idea of general intelligence or overall intelligence is somewhat inaccurate. This is because people often show intelligence in different areas. He argued that there are actually different types of intelligence. One type of intelligence that Gardner identified was interpersonal intelligence. People who possess this type of intelligence relate and interact well with others. Intrapersonal intelligence, on the other hand, implies that people are in touch with their own feelings. They enjoy thinking about theories and developing their own thoughts and ideas. People who have linguistic intelligence learn best by taking notes and reading textbooks. These people usually excel in traditional academic environments, as many academic subjects stress these types of activities. The other types of intelligence are kinesthetic, musical, spatial, and logical.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " Howard Gardner was a psychologist best known for developing the theory of multiple intelligences Basically the theory states that the idea of general intelligence or overall intelligence is somewhat inaccurate This is because people often show intelligence in different areas He argued that there are actually different types of intelligence One type of intelligence that Gardner identified was interpersonal intelligence People who possess this type of intelligence relate and interact well with others Intrapersonal intelligence on the other hand implies that people are in touch with their own feelings They enjoy thinking about theories and developing their own thoughts and ideas People who have linguistic intelligence learn best by taking notes and reading textbooks These people usually excel in traditional academic environments as many academic subjects stress these types of activities The other types of intelligence are kinesthetic musical spatial and logical\n"
     ]
    }
   ],
   "source": [
    "### save the FOURTH TEXT out of 12\n",
    "text3 =  texts['text'].iat[3]\n",
    "\n",
    "## remove punctuation from text2:\n",
    "text3_word_count = word_count(text3)\n",
    "text3_remove_punct = remove_punct(text3)\n",
    "print(\"Number of words in this text:\", text3_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text3)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text3_remove_punct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31f38e26-1fc0-4a39-80ee-f9b79b65dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text3_tokens = nltk.word_tokenize(text3_remove_punct)\n",
    "\n",
    "# print(text3_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "028fc094-21d7-40f9-8c8b-3c0b32d22c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text3_tagged_tokens = nltk.pos_tag(text3_tokens)\n",
    "\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text3_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f29b0b0-4324-43bd-8e7c-2966c892799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text3_df_tagged = pd.DataFrame(text3_tagged_tokens, columns=['ia', 'PoS'])\n",
    "\n",
    "## add the text number (itemid) and the word order number(ianum) to the dataframe\n",
    "text3_df_tagged.insert(loc=0, column='ianum', value=np.arange(len(text3_df_tagged))+1)\n",
    "text3_df_tagged.insert(loc=0, column='itemid', value=4)\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# for Intrapersonal and spatial\n",
    "# \"Intrapersonal\" is incorrectly tagged as proper noun (NNP), instead of adjective (JJ)\n",
    "# change the tags of \"Intrapersonal\" to adjective (JJ)\n",
    "text3_df_tagged.loc[73,'PoS'] = \"JJ\"\n",
    "\n",
    "# \"spatial\" is incorrectly tagged as noun (NN), instead of adjective (JJ)\n",
    "# change the tags of \"spatial\" to adjective (JJ)\n",
    "text3_df_tagged.loc[139,'PoS'] = \"JJ\"\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(text3_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44bc08ad-4b95-44fc-a4ce-106cd49c6d22",
   "metadata": {},
   "source": [
    "## Fifth text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67f60824-c351-4328-9607-80d159aec273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 185\n",
      "\n",
      "ORGINAL TEXT: \n",
      " The Internet has made life a whole lot easier for many people, but being online also brings with it very real risks. Hackers can steal personal and financial information. There are several precautions that computer users can take to minimize the level of risk that is involved with being online. One of the most obvious safety precautions is to purchase a good anti-virus and anti-spyware program. Passwords are also a very important part of online security, and several tips can help users create more secure passwords. First, they should be something that can easily be remembered, but they should not be something others can guess easily. Your first or last name, phone number, or the name of your street are all bad choices, as people could learn this information quite easily. Longer passwords are more secure, and those that use a mixture of upper and lower case letters and a combination of letters and numbers are more secure than those that do not. Finally, passwords should be changed often. This can make remembering them more difficult, but the extra effort is worth the added security.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " The Internet has made life a whole lot easier for many people but being online also brings with it very real risks Hackers can steal personal and financial information There are several precautions that computer users can take to minimize the level of risk that is involved with being online One of the most obvious safety precautions is to purchase a good anti- virus and anti- spyware program Passwords are also a very important part of online security and several tips can help users create more secure passwords First they should be something that can easily be remembered but they should not be something others can guess easily Your first or last name phone number or the name of your street are all bad choices as people could learn this information quite easily Longer passwords are more secure and those that use a mixture of upper and lower case letters and a combination of letters and numbers are more secure than those that do not Finally passwords should be changed often This can make remembering them more difficult but the extra effort is worth the added security\n"
     ]
    }
   ],
   "source": [
    "### save the FIFTH TEXT out of 12\n",
    "text4 =  texts['text'].iat[4]\n",
    "\n",
    "## remove punctuation from text2:\n",
    "text4_word_count = word_count(text4)\n",
    "text4_remove_punct = remove_punct(text4)\n",
    "print(\"Number of words in this text:\", text4_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text4)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text4_remove_punct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51cdd7ba-f075-411d-a178-faa75515d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text4_tokens = nltk.word_tokenize(text4_remove_punct)\n",
    "\n",
    "# print(text4_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6001daf6-bf32-4844-9fcc-950cae88a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text4_tagged_tokens = nltk.pos_tag(text4_tokens)\n",
    "\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text4_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e5691ea-6cff-4aa7-8ca6-7bf89a88d61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text4_df_tagged = pd.DataFrame(text4_tagged_tokens, columns=['ia', 'PoS'])\n",
    "\n",
    "## add the text number (itemid) and the word order number(ianum) to the dataframe\n",
    "text4_df_tagged.insert(loc=0, column='ianum', value=np.arange(len(text4_df_tagged))+1)\n",
    "text4_df_tagged.insert(loc=0, column='itemid', value=5)\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# for anti-virus\n",
    "# the adjective has been separated into two word parts: anti- (JJ) and virus (NN), but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"anti-\" and \"virus\" to adjective\n",
    "text4_df_tagged.loc[62:63,'PoS'] = \"JJ\"\n",
    "\n",
    "# for anti-spyware\n",
    "# the adjective has been separated into two word parts: anti- (JJ) and spyware (NN), but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"anti-\" and \"spyware\" to adjective\n",
    "text4_df_tagged.loc[65:66,'PoS'] = \"JJ\"\n",
    "\n",
    "# # \"Longer\" is incorrectly tagged as proper noun (NNP), instead of adjective, comparative (JJR)\n",
    "# # change the tags of \"Longer\" to adjective, comparative (JJR)\n",
    "text4_df_tagged.loc[133,'PoS'] = \"JJR\"\n",
    "\n",
    "# # \"upper\" is incorrectly tagged as adjective (JJ), instead of adjective, comparative (JJR)\n",
    "# # change the tags of \"upper\" to adjective, comparative (JJR)\n",
    "text4_df_tagged.loc[145,'PoS'] = \"JJR\"\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(text4_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3917d92e-b6cc-43be-b636-32b926102cde",
   "metadata": {},
   "source": [
    "## Sixth Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef20debf-59ac-4f93-92a2-e0237085ccef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 147\n",
      "\n",
      "ORGINAL TEXT: \n",
      " Many people fail to realize just how crucial getting a good night's sleep actually is. It is usually suggested that adults get about seven hours of sleep every night, and younger children should get even more. Sleep has several benefits. First, it is believed to improve memory. This is one reason why it is always preferable to sleep the night before a test rather than stay up for the entire night to review the information. On a related note, sleep also improves concentration and mental alertness. Those who get sufficient sleep are able to concentrate on work tasks better and also react faster when they are driving a car, for example. Finally, people who get enough sleep have better immunity against illness. The reason for this is not fully understood, but researchers believe that an increase in the production of growth hormone and melatonin plays a role.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " Many people fail to realize just how crucial getting a good nights sleep actually is It is usually suggested that adults get about seven hours of sleep every night and younger children should get even more Sleep has several benefits First it is believed to improve memory This is one reason why it is always preferable to sleep the night before a test rather than stay up for the entire night to review the information On a related note sleep also improves concentration and mental alertness Those who get sufficient sleep are able to concentrate on work tasks better and also react faster when they are driving a car for example Finally people who get enough sleep have better immunity against illness The reason for this is not fully understood but researchers believe that an increase in the production of growth hormone and melatonin plays a role\n"
     ]
    }
   ],
   "source": [
    "### save the SIXTH TEXT out of 12\n",
    "text5 =  texts['text'].iat[5]\n",
    "\n",
    "## remove punctuation from text5:\n",
    "text5_word_count = word_count(text5)\n",
    "text5_remove_punct = remove_punct(text5)\n",
    "print(\"Number of words in this text:\", text5_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text5)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text5_remove_punct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d03326fb-4072-4ae3-9569-c67e1d39e810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text5_tokens = nltk.word_tokenize(text5_remove_punct)\n",
    "\n",
    "# print(text5_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "713ebd2e-d2ac-4754-9744-d6fa18d8bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text5_tagged_tokens = nltk.pos_tag(text5_tokens)\n",
    "\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text5_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9728ba6b-4909-4114-97bc-c1ea4ccba76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text5_df_tagged = pd.DataFrame(text5_tagged_tokens, columns=['ia', 'PoS'])\n",
    "\n",
    "## add the text number (itemid) and the word order number(ianum) to the dataframe\n",
    "text5_df_tagged.insert(loc=0, column='ianum', value=np.arange(len(text5_df_tagged))+1)\n",
    "text5_df_tagged.insert(loc=0, column='itemid', value=6)\n",
    "\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# # \"Sleep\" is incorrectly tagged as proper noun (NNP), instead of noun (NN)\n",
    "# # change the tags of \"Sleep\" to noun (NN)\n",
    "text5_df_tagged.loc[36,'PoS'] = \"NN\"\n",
    "\n",
    "# # \"First\" is incorrectly tagged as proper noun, singular (NNP), instead of adverb (RB)\n",
    "# # change the tags of \"First\" to adverb (RB)\n",
    "text5_df_tagged.loc[40,'PoS'] = \"RB\"\n",
    "\n",
    "# # \"Finally\" is incorrectly tagged as proper noun, singular (NNP), instead of adverb (RB)\n",
    "# # change the tags of \"Finally\" to adverb (RB)\n",
    "text5_df_tagged.loc[111,'PoS'] = \"RB\"\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(text5_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fd63da6-3503-4db5-847e-0ea0014eca0c",
   "metadata": {},
   "source": [
    "## Seventh text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ffa89a8-95b0-45a5-abf6-1539eeca9314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 173\n",
      "\n",
      "ORGINAL TEXT: \n",
      " A bird's feathers are extremely important, and when they clean and smooth them, it is known as preening. Birds in the wild preen their feathers on a regular basis. This is true of most captive birds as well, but not all. For example, some birds do not preen their feathers at all. This problem is most common in birds that are taken from their mothers at a very young age. Presumably, the absence of preening is due to the fact that they were never shown how to do it properly. A more common problem among captive birds is excessive preening. Some birds may pull out large numbers of their feathers or bite them down to the skin. It should be noted that wild birds never exhibit this kind of behavior. There are several suggestions about how the problem of excessive preening can be solved, such as giving birds baths or placing them in an area that has more activity to prevent boredom. However, these measures are often not sufficient to solve the problem.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " A birds feathers are extremely important and when they clean and smooth them it is known as preening Birds in the wild preen their feathers on a regular basis This is true of most captive birds as well but not all For example some birds do not preen their feathers at all This problem is most common in birds that are taken from their mothers at a very young age Presumably the absence of preening is due to the fact that they were never shown how to do it properly A more common problem among captive birds is excessive preening Some birds may pull out large numbers of their feathers or bite them down to the skin It should be noted that wild birds never exhibit this kind of behavior There are several suggestions about how the problem of excessive preening can be solved such as giving birds baths or placing them in an area that has more activity to prevent boredom However these measures are often not sufficient to solve the problem\n"
     ]
    }
   ],
   "source": [
    "### save the SEVENTH TEXT out of 12\n",
    "text6 =  texts['text'].iat[6]\n",
    "\n",
    "## remove punctuation from text6:\n",
    "text6_word_count = word_count(text6)\n",
    "text6_remove_punct = remove_punct(text6)\n",
    "print(\"Number of words in this text:\", text6_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text6)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text6_remove_punct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22c90b7c-0df2-4b95-abb8-9520cdcae9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text6_tokens = nltk.word_tokenize(text6_remove_punct)\n",
    "\n",
    "# print(text6_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb40d40e-486d-4ffa-a274-04409ccd4c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text6_tagged_tokens = nltk.pos_tag(text6_tokens)\n",
    "\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text6_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "282d115b-0321-416e-8040-a4f423395b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text6_df_tagged = pd.DataFrame(text6_tagged_tokens, columns=['ia', 'PoS'])\n",
    "\n",
    "## add the text number (itemid) and the word order number(ianum) to the dataframe\n",
    "text6_df_tagged.insert(loc=0, column='ianum', value=np.arange(len(text6_df_tagged))+1)\n",
    "text6_df_tagged.insert(loc=0, column='itemid', value=7)\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# # \"Presumably\" is incorrectly tagged as verb past tense (VBD), instead of adverb (RB)\n",
    "# # change the tags of \"Presumably\" to adverb (RB)\n",
    "text6_df_tagged.loc[70,'PoS'] = \"RB\"\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(text6_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30f078d9-9939-461f-95ac-0250ef608aec",
   "metadata": {},
   "source": [
    "## Eighth text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03b3b51d-2f57-453f-a987-0df13438dbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 133\n",
      "\n",
      "ORGINAL TEXT: \n",
      " Hibernation in animals is an extremely fascinating phenomenon, one that biologists are not yet close to understanding fully. However, it is quite easy to understand why animals hibernate during the cold winter months. Usually, it is because their food is quite scarce during this time. Animals that are herbivores will find the winters extremely tough, because all of the vegetation will have died off by the time winter arrives. Hibernation is essentially a way of dealing with this food shortage. Animals like birds rely on seeds and small insects for sustenance. Obviously, these will also be quite scarce in the winter when the ground becomes covered and frozen. Many birds address their upcoming food shortage in quite a different way: they migrate to warmer areas where their sources of food will be plentiful.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " Hibernation in animals is an extremely fascinating phenomenon one that biologists are not yet close to understanding fully However it is quite easy to understand why animals hibernate during the cold winter months Usually it is because their food is quite scarce during this time Animals that are herbivores will find the winters extremely tough because all of the vegetation will have died off by the time winter arrives Hibernation is essentially a way of dealing with this food shortage Animals like birds rely on seeds and small insects for sustenance Obviously these will also be quite scarce in the winter when the ground becomes covered and frozen Many birds address their upcoming food shortage in quite a different way they migrate to warmer areas where their sources of food will be plentiful\n"
     ]
    }
   ],
   "source": [
    "### save the EIGHTH TEXT out of 12\n",
    "text7 =  texts['text'].iat[7]\n",
    "\n",
    "## remove punctuation from text7:\n",
    "text7_word_count = word_count(text7)\n",
    "text7_remove_punct = remove_punct(text7)\n",
    "print(\"Number of words in this text:\", text7_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text7)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text7_remove_punct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5156d2c7-af6e-4ea1-8fe1-22033ecf94aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text7_tokens = nltk.word_tokenize(text7_remove_punct)\n",
    "\n",
    "# print(text7_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51525360-fd3d-42d4-bef0-31c59283bc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text7_tagged_tokens = nltk.pos_tag(text7_tokens)\n",
    "\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text7_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6c52676-161f-4881-8123-aef69a5eae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text7_df_tagged = pd.DataFrame(text7_tagged_tokens, columns=['ia', 'PoS'])\n",
    "\n",
    "## add the text number (itemid) and the word order number(ianum) to the dataframe\n",
    "text7_df_tagged.insert(loc=0, column='ianum', value=np.arange(len(text7_df_tagged))+1)\n",
    "text7_df_tagged.insert(loc=0, column='itemid', value=8)\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# # \"Animals\" is incorrectly tagged as verb, present tense with 3rd person singular (VBZ), instead of noun plural (NNS)\n",
    "# # change the tags of \"Animals\" to noun plural (NNS)\n",
    "text7_df_tagged.loc[45,'PoS'] = \"NNS\"\n",
    "\n",
    "# # \"Hibernation\" is incorrectly tagged as verb past tense (VBD), instead of noun (NN)\n",
    "# # change the tags of \"Hibernation\" to noun (NN)\n",
    "text7_df_tagged.loc[69,'PoS'] = \"NN\"\n",
    "\n",
    "# # \"Obviously\" is incorrectly tagged as proper noun, singular (NNP), instead of adverb (RB)\n",
    "# # change the tags of \"Obviously\" to adverb (RB)\n",
    "text7_df_tagged.loc[91,'PoS'] = \"RB\"\n",
    "\n",
    "# # \"Many\" is incorrectly tagged as proper noun, singular (NNP), instead of adjective (JJ)\n",
    "# # change the tags of \"Many\" to adjective (JJ)\n",
    "text7_df_tagged.loc[108,'PoS'] = \"JJ\"\n",
    "\n",
    "# # \"warmer\" is incorrectly tagged as verb (VB), instead of adjective, comparative (JJR)\n",
    "# # change the tags of \"warmer\" to adjective, comparative (JJR)\n",
    "text7_df_tagged.loc[123,'PoS'] = \"JJR\"\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(text7_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7cab73f6-1adc-49eb-ab9c-6abb85a04ecb",
   "metadata": {},
   "source": [
    "## Ninth text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5b046cd-0c62-4218-844a-2b955a52635d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 115\n",
      "\n",
      "ORGINAL TEXT: \n",
      " At one time, the use of leeches to treat medical problems was quite common. If a person suffered from a snake bite or a bee sting, leeches were believed to be capable of removing the poison from the body if they were placed on top of the wound. They have also been used for blood letting and to stop hemorrhages, although neither of these leech treatments would be considered acceptable by present-day physicians. Today, leeches are still used on a limited basis. Most often, leeches are used to drain blood from clogged veins. This results in little pain for the patient and also ensures the patient's blood will not clot while it is being drained.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " At one time the use of leeches to treat medical problems was quite common If a person suffered from a snake bite or a bee sting leeches were believed to be capable of removing the poison from the body if they were placed on top of the wound They have also been used for blood letting and to stop hemorrhages although neither of these leech treatments would be considered acceptable by present- day physicians Today leeches are still used on a limited basis Most often leeches are used to drain blood from clogged veins This results in little pain for the patient and also ensures the patients blood will not clot while it is being drained\n"
     ]
    }
   ],
   "source": [
    "### save the NINTH TEXT out of 12\n",
    "text8 =  texts['text'].iat[8]\n",
    "\n",
    "## remove punctuation from text8:\n",
    "text8_word_count = word_count(text8)\n",
    "text8_remove_punct = remove_punct(text8)\n",
    "print(\"Number of words in this text:\", text8_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text8)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text8_remove_punct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c60369a-111a-4286-ab56-f17ae12edb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text8_tokens = nltk.word_tokenize(text8_remove_punct)\n",
    "\n",
    "# print(text8_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "170032f4-aa58-49ac-97fd-b75c1c3ede0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text8_tagged_tokens = nltk.pos_tag(text8_tokens)\n",
    "\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text8_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b13b1a17-fcc1-4b46-95db-36530b7be75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text8_df_tagged = pd.DataFrame(text8_tagged_tokens, columns=['ia', 'PoS'])\n",
    "\n",
    "## add the text number (itemid) and the word order number(ianum) to the dataframe\n",
    "text8_df_tagged.insert(loc=0, column='ianum', value=np.arange(len(text8_df_tagged))+1)\n",
    "text8_df_tagged.insert(loc=0, column='itemid', value=9)\n",
    "\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# for present-day\n",
    "# the adjective has been separated into two word parts: present- (JJ) and day (NN), but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"present-\" and \"day\" to adjective\n",
    "text8_df_tagged.loc[72,'PoS'] = \"JJ\"\n",
    "\n",
    "# # \"Today\" is incorrectly tagged as verb, present tense not 3rd person singular (VBP), instead of adverb (RB)\n",
    "# # change the tags of \"Today\" to adverb (RB)\n",
    "text8_df_tagged.loc[74,'PoS'] = \"RB\"\n",
    "\n",
    "# # \"Most\" is incorrectly tagged as proper noun, singular (NNP), instead of adverb (RB)\n",
    "# # change the tags of \"Today\" to adverb (RB)\n",
    "text8_df_tagged.loc[83,'PoS'] = \"RB\"\n",
    "\n",
    "# # \"leeches\" is incorrectly tagged as verb, present tense with 3rd person singular (VBZ), instead of noun plural (NNS)\n",
    "# # change the tags of \"leeches\" to noun plural (NNS)\n",
    "text8_df_tagged.loc[85,'PoS'] = \"NNS\"\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(text8_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8439003e-d3c4-40a4-a5f9-a2d9ee7aebbc",
   "metadata": {},
   "source": [
    "## Tenth text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c35cb711-90bb-4448-95bc-4835d066e3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 123\n",
      "\n",
      "ORGINAL TEXT: \n",
      " When online file-sharing programs emerged, the music industry changed forever. Perhaps the first widely-used music file sharing program was Napster. It allowed users to sign up to use the service at no charge. Then, they could download music files from other users all over the world by simply typing in what song or album they wanted. Obviously, this was bad news for music artists and record labels because they were not making any profits from downloaded music. Eventually, Napster was shut down. While it later reinvented itself as a paying service, other free music-sharing sites cropped up almost immediately. Even though several sites and individual users have been charged, there are still countless individuals who log onto these sites to obtain free music.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " When online file- sharing programs emerged the music industry changed forever Perhaps the first widely- used music file sharing program was Napster It allowed users to sign up to use the service at no charge Then they could download music files from other users all over the world by simply typing in what song or album they wanted Obviously this was bad news for music artists and record labels because they were not making any profits from downloaded music Eventually Napster was shut down While it later reinvented itself as a paying service other free music- sharing sites cropped up almost immediately Even though several sites and individual users have been charged there are still countless individuals who log onto these sites to obtain free music\n"
     ]
    }
   ],
   "source": [
    "### save the TENTH TEXT out of 12\n",
    "text9 =  texts['text'].iat[9]\n",
    "\n",
    "## remove punctuation from text9:\n",
    "text9_word_count = word_count(text9)\n",
    "text9_remove_punct = remove_punct(text9)\n",
    "print(\"Number of words in this text:\", text9_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text9)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text9_remove_punct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "86b2ba25-1c0b-4e9c-864c-c7bbc771ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text9_tokens = nltk.word_tokenize(text9_remove_punct)\n",
    "\n",
    "# print(text9_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7e9455f6-5b80-4f9f-826b-b823dfcdee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text9_tagged_tokens = nltk.pos_tag(text9_tokens)\n",
    "\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text9_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f5abf1a-cfde-4d12-94b7-8cc767156774",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text9_df_tagged = pd.DataFrame(text9_tagged_tokens, columns=['ia', 'PoS'])\n",
    "\n",
    "## add the text number (itemid) and the word order number(ianum) to the dataframe\n",
    "text9_df_tagged.insert(loc=0, column='ianum', value=np.arange(len(text9_df_tagged))+1)\n",
    "text9_df_tagged.insert(loc=0, column='itemid', value=10)\n",
    "\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# for file-sharing\n",
    "# the adjective has been separated into two word parts: file- (JJ) and sharing (NN), but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"file-\" and \"sharing\" to adjective (JJ)\n",
    "text9_df_tagged.loc[3,'PoS'] = \"JJ\"\n",
    "\n",
    "# for widely-used\n",
    "# the adjective has been separated into two word parts: widely- (RB) and used (JJ) and incorrectly tagged as Noun (NN) and verb past participle (VBN)\n",
    "# but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"widely-\" and \"stricken\" to adjective (JJ)\n",
    "text9_df_tagged.loc[14:15,'PoS'] = \"JJ\"\n",
    "\n",
    "# for music-sharing\n",
    "# the adjective has been separated into two word parts: music- (NN) and sharing (VBG) and music incorrectly tagged as noun plural (NNS)\n",
    "# but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"music-\" and \"sharing\" to adjective (JJ)\n",
    "text9_df_tagged.loc[95:96,'PoS'] = \"JJ\"\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(text9_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f24af256-d5bd-4d97-a427-1b657a648921",
   "metadata": {},
   "source": [
    "## Eleventh text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e820845c-3f64-4012-beb7-2953b07554f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 116\n",
      "\n",
      "ORGINAL TEXT: \n",
      " The pencil is a modern-day version of a centuries-old writing implement. Around 1560, an Italian couple designed the modern, wood-encased pencil. Their creation was flatter and more compact than the pencils we use today. Their plan involved hollowing out a stick of wood and inserting a stick of graphite into it. Shortly after, a better technique was discovered: two wooden halves were carved, a graphite stick was inserted, and then the halves were glued together, which is also how pencils are currently made. Although many people refer to the graphite inside pencils as “lead”, they have always been made with graphite; however, the paint on the wood that surrounded the graphite was, at one time, lead-based.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " The pencil is a modern- day version of a centuries- old writing implement Around 1560 an Italian couple designed the modern wood- encased pencil Their creation was flatter and more compact than the pencils we use today Their plan involved hollowing out a stick of wood and inserting a stick of graphite into it Shortly after a better technique was discovered two wooden halves were carved a graphite stick was inserted and then the halves were glued together which is also how pencils are currently made Although many people refer to the graphite inside pencils as lead they have always been made with graphite however the paint on the wood that surrounded the graphite was at one time lead- based\n"
     ]
    }
   ],
   "source": [
    "### save the ELEVENTH TEXT out of 12\n",
    "text10 =  texts['text'].iat[10]\n",
    "\n",
    "## remove punctuation from text10:\n",
    "text10_word_count = word_count(text10)\n",
    "text10_remove_punct = remove_punct(text10)\n",
    "print(\"Number of words in this text:\", text10_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text10)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text10_remove_punct) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a6ec7dc-3ab6-4d7b-bc63-cff9584c0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text10_tokens = nltk.word_tokenize(text10_remove_punct)\n",
    "\n",
    "# print(text10_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86ff72a5-c620-4e98-b8d9-8b8c8687b843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text10_tagged_tokens = nltk.pos_tag(text10_tokens)\n",
    "\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text10_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2d89b00e-cc31-4f92-a8b6-e10aa0386442",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text10_df_tagged = pd.DataFrame(text10_tagged_tokens, columns=['ia', 'PoS'])\n",
    "\n",
    "## add the text number (itemid) and the word order number(ianum) to the dataframe\n",
    "text10_df_tagged.insert(loc=0, column='ianum', value=np.arange(len(text10_df_tagged))+1)\n",
    "text10_df_tagged.insert(loc=0, column='itemid', value=11)\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# for modern-day\n",
    "# the adjective has been separated into two word parts: modern- (JJ) and day (NN), but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"modern-\" and \"day\" to adjective (JJ)\n",
    "text10_df_tagged.loc[5,'PoS'] = \"JJ\"\n",
    "\n",
    "# for wood-encased\n",
    "# the adjective has been separated into two word parts: wood- (JJ) and encased (VBD), but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"wood-\" and \"encased\" to adjective (JJ)\n",
    "text10_df_tagged.loc[21:22,'PoS'] = \"JJ\"\n",
    "\n",
    "# # \"Their\" is incorrectly tagged as proper noun, singular (NNP), instead of possessive pronoun (PRP$)\n",
    "# # change the tags of \"Their\" to possessive pronoun (PRP$)\n",
    "text10_df_tagged.loc[24,'PoS'] = \"PRP$\"\n",
    "\n",
    "# # \"today\" is incorrectly tagged as noun, singular (NN), instead of adverb (RB)\n",
    "# # change the tags of \"today\" to adverb (RB)\n",
    "text10_df_tagged.loc[36,'PoS'] = \"RB\"\n",
    "\n",
    "# for lead-based\n",
    "# the adjective has been separated into two word parts: lead- (NN) and based (VBN), but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"lead-\" and \"based\" to adjective (JJ)\n",
    "text10_df_tagged.loc[118:119,'PoS'] = \"JJ\"\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(text10_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "303d86b5-25fa-4036-9fb4-166026b915b7",
   "metadata": {},
   "source": [
    "## Twelfth text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "382f38de-fd15-4b92-8c0b-a544dce25537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in this text: 146\n",
      "\n",
      "ORGINAL TEXT: \n",
      " Technology is rapidly expanding the scope of capabilities for both professional and personal use; such is the case with smart phones. Professionals now have mobile devices available to them capable of digital media, internet access, phone communication, multi-person scheduling and office tools for documents and presentations. Businesspeople that are often mobile may maximize the use of these critical features on smart phones. Individuals who simply enjoy the luxury of multi-function devices often use these devices for frivolous pursuits such as downloading catchy ring tones, instant messaging about the latest gossip and looking up the world record for most cans crushed on one’s head during the Superbowl. This fusion of capabilities and increased availability of such devices could be a sign of a growing blend in society between work and personal life, or individuals could simply be taking a luxurious approach to their connectivity in personal lives.\n",
      "\n",
      "TEXT WITH MODIFIED PUNCTUATION: \n",
      " Technology is rapidly expanding the scope of capabilities for both professional and personal use such is the case with smart phones Professionals now have mobile devices available to them capable of digital media internet access phone communication multi- person scheduling and office tools for documents and presentations Businesspeople that are often mobile may maximize the use of these critical features on smart phones Individuals who simply enjoy the luxury of multi- function devices often use these devices for frivolous pursuits such as downloading catchy ring tones instant messaging about the latest gossip and looking up the world record for most cans crushed on ones head during the Superbowl This fusion of capabilities and increased availability of such devices could be a sign of a growing blend in society between work and personal life or individuals could simply be taking a luxurious approach to their connectivity in personal lives\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "### save the TWELFTH TEXT out of 12\n",
    "text11 =  texts['text'].iat[11]\n",
    "\n",
    "## remove punctuation from text11:\n",
    "text11_word_count = word_count(text11)\n",
    "text11_remove_punct = remove_punct(text11)\n",
    "print(\"Number of words in this text:\", text11_word_count)\n",
    "print()\n",
    "print(\"ORGINAL TEXT: \\n\", text11)\n",
    "print()\n",
    "print(\"TEXT WITH MODIFIED PUNCTUATION: \\n\", text11_remove_punct) \n",
    "print(word_count(text11_remove_punct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d5af56c-0a91-4ae9-8468-c6bc67a74aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "text11_tokens = nltk.word_tokenize(text11_remove_punct)\n",
    "\n",
    "# print(text11_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b61314af-01fb-4c86-b7d1-797e61186c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging on the tokens\n",
    "text11_tagged_tokens = nltk.pos_tag(text11_tokens)\n",
    "\n",
    "\n",
    "# Print the tagged tokens\n",
    "# print(text11_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e5556e85-32f1-404a-9993-1affa090bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process the word and their PoS tags\n",
    "\n",
    "## Create a dataframe of the word and its PoS tag\n",
    "text11_df_tagged = pd.DataFrame(text11_tagged_tokens, columns=['ia', 'PoS'])\n",
    "\n",
    "## add the text number (itemid) and the word order number(ianum) to the dataframe\n",
    "text11_df_tagged.insert(loc=0, column='ianum', value=np.arange(len(text11_df_tagged))+1)\n",
    "text11_df_tagged.insert(loc=0, column='itemid', value=12)\n",
    "\n",
    "\n",
    "### Edit the the data frame and the PoS tags\n",
    "## Modify the inapporpiate PoS tags\n",
    "\n",
    "# for multi-person\n",
    "# the adjective has been separated into two word parts: multi- (JJ) and person (NN), but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"multi-\" and \"person\" to adjective (JJ)\n",
    "text11_df_tagged.loc[38,'PoS'] = \"JJ\"\n",
    "\n",
    "# # \"Businesspeople\" is incorrectly tagged as proper noun, singular (NNP), instead of noun plural (NNS)\n",
    "# # change the tags of \"Businesspeople\" to noun plural (NNS)\n",
    "text11_df_tagged.loc[47,'PoS'] = \"NNS\"\n",
    "\n",
    "# for multi-function\n",
    "# the adjective has been separated into two word parts: multi- (JJ) and function (NN), but together they form a single adjective unit (JJ)\n",
    "# change the tags of \"multi-\" and \"function\" to adjective (JJ)\n",
    "text11_df_tagged.loc[71,'PoS'] = \"JJ\"\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(text11_df_tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb2b3bdb-aafd-4759-b496-19bc1ee8fcca",
   "metadata": {},
   "source": [
    "## Load the eyetracking data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8e2d19b-7401-480a-a217-23e7f27410e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading the eye tracking csv file \n",
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4d318d6e-3053-47f1-9be6-3d2c8061aa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set the viewing parameters of pandas\n",
    "# pd.set_option('display.max_columns', 20)\n",
    "# pd.set_option('display.max_rows', 2000)\n",
    "\n",
    "## list of the PoS tagged texts data sets\n",
    "list_of_tagged_texts = [text0_df_tagged,text1_df_tagged,text2_df_tagged,text3_df_tagged,text4_df_tagged,text5_df_tagged,text6_df_tagged,text7_df_tagged,text8_df_tagged,\n",
    "                        text9_df_tagged,text10_df_tagged,text11_df_tagged]\n",
    "\n",
    "## concatenate the PoS tags of texts into a single dataframe\n",
    "base = pd.concat(list_of_tagged_texts, ignore_index = True)\n",
    "\n",
    "## remove the words column (\"ia\") from the PoS tagged dataset before merging the dataframes\n",
    "base = base.drop(columns=[\"ia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "86ad8b82-290f-42d8-87ea-e23021449bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge the PoS dataframe to the eyetracking dataset based on their common columns: text number and word order\n",
    "merged_df = pd.merge(df, base, on=[\"itemid\", \"ianum\"])\n",
    "\n",
    "## sort the data frame by the pariticiant id(subid), text number(itemid), and word sequence number(ianum) in the text\n",
    "merged_df.sort_values(['subid', 'itemid', 'ianum'], ascending=[True, True, True], inplace=True)\n",
    "\n",
    "## reset the index number of the data frame\n",
    "merged_df = merged_df.reset_index(drop=True)\n",
    "\n",
    "## print the entire merged_dataframe\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4dd01f10-82a4-488e-bd8c-da4cf49f702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## rename the \"Unnamed\" column. the column represents the indexation of each data point in the eyetracking dataframe\n",
    "merged_df.rename(columns = {'Unnamed: 0':'index.data'}, inplace = True)\n",
    "\n",
    "## list the columns of the data set\n",
    "list_of_columns = list(merged_df.columns)\n",
    "\n",
    "## move the PoS column next to the word column(ia)\n",
    "new_columns = list_of_columns[:9] + ['PoS'] +  list_of_columns[9:-1]\n",
    "merged_df = merged_df[new_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "37758a13-20a9-44fe-9775-037a6d5df7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the merged dataframe as a csv file\n",
    "merged_df.to_csv(\"merged_data.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ee11185",
   "metadata": {},
   "source": [
    "## Load the comprehension data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4610b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading the texts comprehension csv file \n",
    "comp_df = pd.read_csv(\"joint_comp_l2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c89689ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create an empty dataframe for stroring the subjects that scored above 60% accuracy score on the comprehension test (at least 15/24 questions)\n",
    "better_comp_subjects = pd.DataFrame()\n",
    "\n",
    "## ## create an empty dataframe for stroring the above 60% accuracy score datapoints (may or may not beuseful later)\n",
    "better_comp_df = pd.DataFrame()\n",
    "list_subject = []\n",
    "list_correct_answer = []\n",
    "list_accuracy = []\n",
    "list_lang = []\n",
    "\n",
    "for entry in range(len(comp_df)):\n",
    "    if comp_df.iloc[entry]['correct_answer'] >= 15:\n",
    "        list_subject.append(comp_df.iloc[entry]['subject'])\n",
    "        list_correct_answer.append(comp_df.iloc[entry]['correct_answer'])\n",
    "        list_accuracy.append(comp_df.iloc[entry]['accuracy'])\n",
    "        list_lang.append(comp_df.iloc[entry]['lang'])\n",
    "\n",
    "\n",
    "## append the lists as columns to the empty data frames\n",
    "better_comp_subjects['subid'] = list_subject\n",
    "better_comp_df['subject'] = list_subject\n",
    "better_comp_df['correct_answer'] = list_correct_answer\n",
    "better_comp_df['accuracy'] = list_accuracy\n",
    "better_comp_df['lang'] = list_lang\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "57eb7863",
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge the higher comprehension subjects dataframe to the dataframe that contains also the PoS tags \n",
    "## based on their common column: subid (id of the participant)\n",
    "## the resulting data frame shall contain only the datapoints of the subjects that scored higher than 60% on the comprehension test\n",
    "merged_comp_df = pd.merge(merged_df, better_comp_subjects, how = \"inner\",on=[\"subid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4ab59688",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the merged dataframe as a csv file\n",
    "merged_comp_df.to_csv(\"merged_comp_data.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43fd6198",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
